

Question 1 of 11

A data engineer is tasked with gathering raw, unprocessed data for a project analyzing the effects of social media usage on mental health.

Which of the following data sources would be a primary source of data in this scenario?

    a book discussing the correlation between social media usage and mental health

    a blog post summarizing the findings of various research studies on social media and mental health

    a meta-analysis of multiple studies on social media and mental health

    data obtained through a social media platform's API
    I don't know yet

How would you rate this assessment question?
Question 1 of 11
Back to Domain Score
Previous Question
Next Question
Explanation

Correct answer

The correct answer is option 4: data obtained through a social media platform's API. This is because primary data sources directly provide raw, firsthand data. In the context of studying the effects of social media on mental health, data obtained directly from a social media platform via its API consists of original, unprocessed information such as user interactions, posts, and behavioral data. This type of data is most suitable for an analysis that aims to explore new insights and conduct an original research study, as it has not been filtered or interpreted through secondary analysis like the other options listed.



Question 2 of 11

Which of the following statements is TRUE about the use of moving averages in time-series analysis?

    Moving averages can be used to detect changes in the trend of time-series data.

    Moving averages can be used to estimate the trend of time-series data.

    Moving averages can be used to remove trend and seasonality from time-series data.

    Moving averages can be used to model the seasonal component of time-series data.
    I don't know yet

How would you rate this assessment question?
Question 2 of 11
Back to Domain Score
Previous Question
Next Question
Explanation

What you selected

You selected "I don't know yet" or didn't select an option.

Correct answer

Moving averages are primarily used to estimate the trend of time-series data. This means that they help smooth out short-term fluctuations and highlight longer-term patterns or trends, making it easier to see the underlying direction of the data over time. This is why option 2 is correct. Options 1 and 3 are somewhat related but don’t capture the main purpose of moving averages, which is trend estimation, while option 4 is incorrect because moving averages are not typically used to model seasonal components.



Accessibility Screen-Reader Guide, Feedback, and Issue Reporting

Workera Logo
Data Science Processes

Question 3 of 11

A retail company that wants to analyze the sales of different products. The following table shows the sales data for three products for the first quarter of the year.


Month
	

Product A Sales
	

Product B Sales
	

Product C Sales

Jan
	

1000
	

800
	

1200

Feb
	

900
	

700
	

1300

Mar
	

1100
	

900
	

1400


Which of the following summary statistics BEST describes the variability of sales for product A?

    Range

    Skewness

    Kurtosis

    Variance

    Mean
    I don't know yet

How would you rate this assessment question?
Question 3 of 11
Back to Domain Score
Previous Question
Next Question
Explanation

Correct answer

The correct answer is Variance, which you selected. Variance is a statistical measure that describes the spread or variability of a data set. It calculates the average of the squared differences from the Mean, providing a clear picture of how much the sales values deviate from their average over the period. This is particularly useful in understanding the consistency or fluctuations in sales of product A from month to month. Other options like Range, Skewness, Kurtosis, and Mean, do not specifically address this aspect of variability in the same comprehensive way that Variance does.


Accessibility Screen-Reader Guide, Feedback, and Issue Reporting

Workera Logo
Data Science Processes

Question 4 of 11

A company launches a social media campaign to increase brand awareness for its new product. Which of the following is the BEST KPI for measuring the success of the campaign?

     cost per click (CPC)

    click-through rate (CTR)

    conversion rate

    engagement rate
    I don't know yet

How would you rate this assessment question?
Question 4 of 11
Back to Domain Score
Previous Question
Next Question
Explanation

What you selected

The option you selected, click-through rate (CTR), primarily measures how often people click on the link provided in the campaign relative to the number of times the ad is shown. Although CTR is important for understanding how appealing or effective the ad is at generating clicks, it does not directly measure the level of user interaction or engagement with the content, which is more relevant to brand awareness goals. CTR is more aligned with initial interest rather than deeper engagement metrics.

Correct answer

The correct answer, engagement rate, is the best KPI for measuring the success of a social media campaign aimed at increasing brand awareness. Engagement rate includes metrics such as likes, shares, comments, and other interactions that indicate how actively involved the audience is with the content. This level of interaction is a direct indicator of how much the audience resonates with the message, which is crucial for building brand awareness. By analyzing engagement, the company can better understand how effectively the campaign is capturing and holding the audience's attention.



Accessibility Screen-Reader Guide, Feedback, and Issue Reporting

Workera Logo
Data Science Processes

Question 5 of 11

A data science team is working on a project to analyze sales data from stores A and B. Both stores have their datasets in CSV format, each containing columns for Product ID, Category, and Sales Amount. The team must merge the two datasets while ensuring that each product's sales amounts are combined across both stores.

Which set operation should they apply to merge the datasets effectively?

    Merge datasets using left join on Product ID and Category.

    Apply a full outer join on Product ID with a condition to aggregate Sales Amount.

    Perform an inner join on Product ID and Category.

    Use a union operation on both datasets.
    I don't know yet

How would you rate this assessment question?
Question 5 of 11
Back to Domain Score
Previous Question
Next Question
Explanation

What you selected

Your selection of using a union operation on both datasets is incorrect. A union operation combines all the records from both datasets and removes duplicates. However, it doesn't combine the 'Sales Amount' for the same 'Product ID', which is the requirement in this case. The options of merging datasets using left join on 'Product ID' and 'Category' or performing an inner join on 'Product ID' and 'Category' would also not meet the requirement. A left join includes all records from the left dataset and matching records from the right dataset, while an inner join only includes records that have matching values in both datasets. Neither operation aggregates the 'Sales Amount' for the same 'Product ID'.

Correct answer

The correct option is to apply a full outer join on 'Product ID' with a condition to aggregate 'Sales Amount'. This operation would include all records from both datasets, and for those records with the same 'Product ID', the 'Sales Amounts' from both stores would be combined. When it comes to merging datasets and combining specific column values, a full outer join with an aggregation condition is the most appropriate set operation. Remember, it's crucial to consider the specific requirements of the data manipulation task to choose the right operation.



Accessibility Screen-Reader Guide, Feedback, and Issue Reporting

Workera Logo
Data Science Processes

Question 6 of 11

A data analyst is working on a multi-class classification problem for a medical diagnosis system. The dataset is imbalanced, with some classes having significantly fewer samples. The analyst wants to evaluate the model's performance using cross-validation.

Which of the following cross-validation techniques is MOST appropriate for this scenario?

    K-Fold

    Stratified K-Fold

    Leave-One-Out

    Group K-Fold
    I don't know yet

How would you rate this assessment question?
Question 6 of 11
Back to Domain Score
Previous Question
Next Question
Explanation

Correct answer

The choice of Stratified K-Fold cross-validation is indeed the most appropriate for your scenario involving an imbalanced multi-class dataset. The advantage of Stratified K-Fold is that it ensures each fold of the dataset contains approximately the same percentage of samples of each class as the complete set. This is particularly important in your case because it helps in maintaining a representative mix of the classes, thereby providing a more accurate measure of the model's performance on unseen data. It prevents the model from being biased towards the majority class and improves the reliability of the evaluation, especially in medical diagnosis systems where the balance of sensitivity among classes can be crucial.



Accessibility Screen-Reader Guide, Feedback, and Issue Reporting

Workera Logo
Data Science Processes

Question 7 of 11

Which of the following is an example of concept drift in a credit scoring model?

    A new feature related to employment status is added to the model.

    The definition of bad loans changes.

    The distribution of age in the dataset changes over time.

    A new credit bureau is added to the data sources.
    I don't know yet

How would you rate this assessment question?
Question 7 of 11
Back to Domain Score
Previous Question
Next Question
Explanation

What you selected

The selection you made, "The distribution of age in the dataset changes over time," refers to a change in the population characteristics rather than a fundamental shift in the underlying concept that the model was initially designed to predict. While changing demographics can affect model performance, concept drift specifically relates to changes in the relationships between input features and the target variable, not just changes in the features themselves.

Correct answer

The correct answer, "The definition of bad loans changes," is an example of concept drift because it indicates a shift in the criteria used to define the outcome variable the model is predicting. When the definition of what constitutes a bad loan changes, the historical data the model was trained on no longer represents the same target concept, leading to potential decreases in model accuracy and effectiveness until the model is retrained or adjusted to reflect this new definition.




Accessibility Screen-Reader Guide, Feedback, and Issue Reporting

Workera Logo
Data Science Processes

Question 8 of 11

A data scientist is working on a large-scale machine learning project for a major industry. The data scientist have collected a massive dataset with millions of records to train their model. After performing an initial analysis, the data scientist discovers that the dataset contains a considerable number of potential outliers. The primary objective is to improve the model's accuracy by identifying and eliminating these outliers.

Which of the following methods would be MOST appropriate for achieving this goal?

    discarding all data points that have a high correlation with the target variable to reduce the risk of overfitting the model

    utilizing a fixed threshold to classify data points as outliers based on their standard deviation from the mean value

    employing unsupervised machine learning algorithms like DBSCAN or LOF to cluster the data and identify outlier data points

    replacing all potential outliers with the median value of the respective feature, without considering any further analysis
    I don't know yet

How would you rate this assessment question?
Question 8 of 11
Back to Domain Score
Previous Question
Next Question
Explanation

What you selected

The approach of using a fixed threshold based on standard deviation from the mean to classify outliers, as mentioned in your selection, can be too rigid for complex datasets. This method assumes that data follows a normal distribution, which might not be the case in many real-world scenarios. It also doesn't account for the possibility that what appears to be outliers could be valid extreme values, significant for the analysis. Hence, this method could lead to incorrect exclusion of important data or failure to detect actual outliers in non-normal distributions.

Correct answer

The correct method involves using unsupervised machine learning algorithms like DBSCAN or LOF to identify outliers. These algorithms are effective because they do not rely on assumptions about the data distribution and can adapt to the data's actual structure. DBSCAN, for example, clusters data points based on density, effectively isolating sparse points as outliers. LOF measures the local deviation of a given data point with respect to its neighbors, which helps in identifying points that substantially deviate from typical data patterns. This flexibility makes them ideal for handling complex and large datasets with potential outliers.


Accessibility Screen-Reader Guide, Feedback, and Issue Reporting

Workera Logo
Data Science Processes

Question 9 of 11

A data analyst fits a linear regression model to predict sales revenue based on advertising spend, and the p-value for the advertising spend variable is 0.05. Which of the following statements is CORRECT?

    The model has a poor fit.

    The advertising spend variable is a significant predictor of sales revenue.

    The advertising spend variable is not a significant predictor of sales revenue.

    The model has a good fit.
    I don't know yet

How would you rate this assessment question?
Question 9 of 11
Back to Domain Score
Previous Question
Next Question
Explanation

Correct answer

The advertising spend variable is considered a significant predictor of sales revenue because the p-value is 0.05. In hypothesis testing, a p-value of 0.05 or less typically indicates that the null hypothesis can be rejected, suggesting that there is a statistically significant relationship between the predictor (advertising spend) and the outcome (sales revenue). This means that changes in advertising spend are likely to be associated with changes in sales revenue, making it an important variable in the model.



Accessibility Screen-Reader Guide, Feedback, and Issue Reporting

Workera Logo
Data Science Processes

Question 10 of 11

The mean weight of 81 apples at a particular farm is 150 grams with a standard deviation of 10 grams. Considering the z-value for the 95% confidence level is 1.96, what is the confidence interval for the mean weight of apples at the farm?

    [134.12, 165.87]

    [149.01, 150.99]

    [148.75, 151.24]

    [147.82, 152.18]
    I don't know yet

How would you rate this assessment question?
Question 10 of 11
Back to Domain Score
Previous Question
Next Question
Explanation

What you selected

You selected "I don't know yet" or didn't select an option.

Correct answer

To find the confidence interval for the mean weight of apples, we use the formula: mean ± (z-value * (standard deviation / sqrt(sample size))). Here, the mean is 150 grams, the z-value is 1.96, the standard deviation is 10 grams, and the sample size is 81. Plugging in these values gives us 150 ± (1.96 * (10 / sqrt(81))), which simplifies to 150 ± (1.96 * 1.11). This calculation results in the interval 150 ± 2.18, or [147.82, 152.18], which matches option 4. This interval is where we expect the true mean weight of the apples to lie with 95% confidence.



Accessibility Screen-Reader Guide, Feedback, and Issue Reporting

Workera Logo
Data Science Processes

Question 11 of 11

A data analyst is examining a large dataset containing information on car accidents in a city over the past 5 years. The dataset contains variables such as accident_id, date, time, location, number_of_vehicles_involved, weather_conditions, and injury_severity. The data analyst wants to understand the relationship between two categorical variables: weather_conditions and injury_severity without using graphical methods.

Which of the following methods should the data analyst use to better understand the relationship?

    Compute the correlation coefficient between weather_conditions and injury_severity.

    Perform a t-test to compare the means of weather_conditions and injury_severity.

    Use a linear regression model to predict injury_severity based on weather_conditions.

     Create a contingency table for weather_conditions and injury_severity.
    I don't know yet

How would you rate this assessment question?
Question 11 of 11
Back to Domain Score
Previous Question
Next Question
Explanation

What you selected

The option to compute the correlation coefficient between weather conditions and injury severity is incorrect because the correlation coefficient is typically used for measuring the strength of a linear relationship between two continuous variables. Here, both weather conditions and injury severity are likely categorical variables (e.g., weather conditions might be labeled as 'rainy', 'sunny', etc., and injury severity as 'low', 'medium', 'high'). The correlation coefficient is not suitable for analyzing relationships between categorical variables.

Correct answer

Creating a contingency table for weather conditions and injury severity is the correct choice because it allows you to examine the frequency distribution of injury severity across different weather conditions. This method is particularly useful for categorical variables, enabling an analysis of how these categories interact or are associated with each other. By observing this table, patterns or trends in injury severity relative to different weather conditions can be identified, which is helpful for understanding their relationship without resorting to graphical methods.


