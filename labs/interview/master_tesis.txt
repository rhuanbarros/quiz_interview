4 METODOLOGIA


          A presente pesquisa adotou a metodologia CRISP-DM Guide 1.0 (CHAPMAN
et al., 2000) para validação experimental, assim, considerou-se interessante apresentar
a seguir os pontos-chave dessa metodologia. Além disso, devido à utilização de testes
estatísticos em alguns experimentos, também se considerou interessante apresentar os
pontos-chave da metodologia adotada apresentada no trabalho de Snijders (2002).



4.1 Processo de descoberta de conhecimento em base de dados


          Este trabalho segue a abordagem metodológica descrita em CRISP-DM Guide 1.0
(CHAPMAN et al., 2000) para a descoberta de conhecimento em base de dados que é
utilizada para extrair conhecimento útil de grandes coleções de dados. Essa metodologia
apresenta um processo iterativo composto de diversas fases, que compõe desde a compre-
ensão e as necessidades de negócio até a modelagem dos dados e sua aplicação, as quais
são descritas em mais detalhes nas seções seguintes. A Figura 4.1 apresenta o ciclo do
processo.



Figura 4.1: Ciclo de desenvolvimento do processo metodológico CRISP-DM Guide 1.0.




Adaptado de Chapman et al. (2000)
46


4.1.1 Compreensão do Negócio


        Essa fase consiste em compreender o valor do conhecimento a ser gerado pela
perspectiva do negócio, de modo a alinhar o projeto com os objetivos estratégicos da
organização. Assim, esse estágio compreende a análise do contexto em que o negócio
se encontra inserido de modo a compreender o que o cliente realmente necessita e seu
objetivo principal. Essa análise vai guiar todas as fases do processo de descoberta de
conhecimento, pois são definidos pontos fundamentais, como, por exemplo, o objetivo de
mineração. Esse estágio é essencial pois uma possível definição incorreta dos problemas
de negócio levaria a pesquisa invariavelmente a trazer resultados inúteis. A seguir são
apresentados os principais elementos que compõem essa fase:


     • Objetivos de negócio: compreensão do contexto em relação ao mercado em que o
       negócio se encontra; definição dos objetivos do negócio em relação ao projeto de
       descoberta de conhecimento em base de dados; definição de critérios de sucesso do
       projeto.
     • Recursos do projeto: inclui inventário de recursos disponíveis para a realização do
       projeto; listagem de requisitos e restrições que podem haver, como, por exemplo,
       data limite para realização, níveis de qualidade, segurança e disposições legais em
       relação aos dados; além de análise da relação custo-benefício esperado obter com o
       projeto.
     • Objetivo de mineração: definição clara do objetivo de mineração é um passo fun-
       damental no processo que permite a execução satisfatória da pesquisa, além dos
       critérios de sucesso os quais vão permitir a verificação da eficiência dos modelos
       desenvolvidos.
     • Planejamento do Projeto: inclui a listagem dos passos necessários para alcançar os
       objetivos, como também lista de ferramentas necessárias para a execução e prazos
       de execução.



4.1.2 Compreensão dos dados


        Inicia com a coleta dos dados e com a exploração inicial, o que permite a iden-
tificação de problemas de qualidade e a aferição de conhecimentos estatísticos sobre a
massa de dados. Essa fase pode identificar se realmente os dados podem responder às
                                                                                         47


perguntas do negócio e identificar as variáveis significativas. A seguir são apresentados
os principais elementos que compõem essa fase:




   • Coleta de dados: inclui a extração de dados iniciais ao projeto e a sua descrição
      de modo que seja especificada sua localização, técnica utilizada para extração e
      resolução de problemas encontrados.
   • Descrição dos dados: inclui análise dos dados de maneira a especificar os tipos de
      dados disponíveis, seu formato e quantidade. Também permite inferir se os dados
      disponíveis satisfazem aos requisitos especificados.
   • Exploração dos dados: análise da maneira como os dados estão distribuídos no
      banco de dados e de seus relacionamentos por meio da apresentação de gráficos e
      relatórios.
   • Qualidade: verificação da qualidade dos dados extraídos por meio da verificação de
      possíveis erros na extração, além verificação se há valores que estejam faltando em
      determinados campos.



4.1.3 Preparação dos dados


       O objetivo é o pré-processamento dos dados para torná-los relevantes e consisten-
tes com respeito à tarefa de busca de conhecimento. Essa fase é extremamente necessá-
ria, pois os dados muitas vezes podem estar incompletos, inconsistentes ou podem, até
mesmo, conter erros. A seguir são apresentados os principais elementos que compõem
essa fase:




   • Seleção e integração dos dados: se os dados estiverem distribuídos em diversas
      bases, será necessário realizar procedimentos para uni-los de modo a permitir pos-
      teriormente a seleção das melhores observações coletadas para análise e processa-
      mento.
   • Limpeza dos dados: realizar o tratamento dos dados de modo a remover dados ou
      caracteres que podem reduzir os níveis de acurácia de certos modelos utilizados.
   • Construção e formatação dos dados: certas técnicas de modelagem exigem que os
      dados estejam em determinado formato para a sua correta utilização.
48


4.1.4 Modelagem


         Consiste na tarefa de escolha de métodos e parametrização para a extração de
padrões, classificação, segmentação, regressão ou associação de itens, os quais gerarão
novos conhecimentos sobre a importância de cada uma das variáveis em função do re-
sultado esperado. A seguir são apresentados os principais elementos que compõem essa
fase:




     • Escolha da técnica de modelagem: Análise e escolha da melhor técnica de modela-
        gem que se aplique ao caso.
     • Testes: desenvolver uma técnica que permita a realização da avaliação do modelo
        após a sua construção. Muitas vezes, é construída uma base de dados anotada no
        estágio anterior de modo que seja possível separar uma parte para testes.
     • Construção do modelo: referente ao desenvolvimento do modelo por meio de técni-
        cas de treinamento por aprendizado de máquina, por exemplo, incluindo a escolha
        de parâmetros.
     • Avaliação técnica: consiste em analisar o modelo construído em função de diversos
        parâmetros em busca da melhor combinação possível.



4.1.5 Avaliação


         Fase em que os padrões reconhecidos, regras de associação e todo conhecimento
gerado é analisado para verificação da sua real utilidade. Podem ser utilizadas medidas
estatísticas, como também visualizações, para ajudar a perceber a utilidade dos dados. A
seguir são apresentados os principais elementos que compõem essa fase:




     • Análise de resultados: diferentemente da avaliação técnica do modelo, neste caso
        o importante é avaliar se o modelo atende aos requisitos de negócio, desse modo, é
        possível testar o modelo em um protótipo de aplicação real com usuários finais, por
        exemplo.
     • Revisão e próximos passos: análise de todas as atividades realizadas e sua eficácia,
        além de descrever futuras ações.
                                                                                         49


4.1.6 Aplicação


       Consiste na consolidação de todo processo na forma de relatório e publicação do
conhecimento ou na incorporação da modelagem a um sistema computacional. A seguir
são apresentados os principais elementos que compõem essa fase:


   • Plano de implementação: certos casos exigem que os dados sejam transformados
      antes de serem processados por um modelo, assim, todo o processo precisa ser
      documentado.
   • Plano de monitoramento: pode ser necessário a verificação da qualidade dos dados
      recebidos em um fluxo de processamento para alimentação de um modelo de dados.
   • Relatório final e revisão: sumário de todo o projeto incluindo uma apresentação
      final para os clientes.



4.2 Teste de hipótese estatística


       A presente pesquisa busca realizar análise quantitativa em relação à proporção
de acórdãos julgados favoravelmente para as partes empregado e empresa de modo a
responder à hipótese levantada na Seção 6.1.1. Assim, de modo a aferir se realmente
existe diferença estatística entre as proporções obtidas, julga-se necessária a aplicação de
testes estatísticos, como também o cálculo do nível de força e efeito.
       O teste de hipótese estatística desenvolvido neste trabalho segue a proposta de me-
todologia descrita por SNIJDERS no trabalho Snijders (2002). De modo geral, o pesqui-
sador define uma questão de pesquisa cuja resposta tem por base a análise de propriedades
de um conjunto de observações obtidas a partir de um processo estocástico representado
por meio de uma distribuição estatística, ou seja, dados quantitativos. Assim, dados são
coletadas e resumidos de acordo com as propriedades sendo analisadas, que podem ser,
por exemplo, valores médios para distribuições contínuas ou proporções para distribui-
ções binomiais. Após, a questão de pesquisa é reescrita de forma a considerar a existên-
cia ou não de um efeito que pode ser observado considerando a propriedade medida por
meio da comparação desse valor com outro valor específico ou com a mesma propriedade
observada de outro grupo estatístico.
       Desse modo, é definida a hipótese nula a qual verifica a inexistência de efeito, ou
seja, que não há diferença nas observações em relação às propriedades em análise. Já em
50


relação à comparação entre dois grupos, a hipótese nula pode implicar a verificação da
igualdade da propriedade entre dois grupos. Além disso, também é definida a hipótese
alternativa a qual define a existência de algum efeito ou define a existência de diferença
entre grupos em relação a propriedade sendo analisada. Ao mesmo tempo, é necessário
definir o nível de significância que deve ser usado para comparar com o resultado do teste
estatístico aplicado, normalmente definido como 5%.
        Assim, o teste estatístico a ser escolhido computa os dados e apresenta a estatística
do teste e o P-value. A estatística do teste apresenta o quanto os dados diferem da hipótese
nula de acordo com a distribuição normal. Já o P-value apresenta a probabilidade de obter
os dados analisados se a hipótese nula é na verdade verdadeira na população. A fins de
interpretação de resultados, optou-se por usar o P-value nesta pesquisa em vista da sua
objetividade, pois a interpretação depende da comparação do P-value com o nível de
significância definido previamente. Se o P-value for menor que o nível de significância,
rejeita-se a hipótese nula. Se o P-value for maior, há falha em rejeitar a hipótese nula.
        Ademais, o teste estatístico a ser aplicado varia de acordo com o tipo de distribui-
ção de dados e do tipo de propriedade da distribuição sendo analisada. Testes conhecidos
como paramétricos basicamente assumem que a distribuição dos dados segue padrões de
normalidade. Já os testes conhecidos como não-paramétricos não assumem que os dados
seguem padrões de normalidade. Em relação aos testes paramétricos, existem testes de
correlação que verificam o relacionamento entre variáveis sem a noção de causa e efeito,
testes de regressão que verificam o relacionamento entre variáveis incluindo a noção de
causa e efeito e testes de comparação que verificam a diferença entre médias e proporções.
        Após a escolha do teste estatístico, é necessário verificar se as condições de vali-
dade do teste estão satisfeitas em relação aos dados da amostra. Assim, por exemplo, o
teste estatístico que realiza a comparação entre proporções de duas distribuições binomi-
ais necessita que as seguintes suposições estejam satisfeitas:


     • Amostra deve conter observações extraídas aleatoriamente com probabilidades
       iguais.
     • As observações devem ser independentes.
     • n1 ∗ p1 ≥ 5 e n1 ∗ (1 − p1) ≥ 5, sendo n1 = quantidade de observações no grupo
       1, p1 = proporção no grupo 1.


        Por fim, o teste estatístico é aplicado e o P-value é comparado com o nível de
significância definido previamente. Além disso, é necessário apresentar a conclusão do
                                                                                     51


teste informando a rejeição da hipótese nula ou falha da sua rejeição, como também, a
interpretação dos resultados em relação aos objetivos de negócio estabelecidos.



4.3 Resumo do Capítulo


       Neste capítulo, iniciou-se apresentando a contextualização metodológica da pes-
quisa. Após, foi apresentada a metodologia base utilizada para desenvolvimento de todo o
processo de validação experimental. Em função do carácter eminentemente prático do es-
tudo, optou-se pela metodologia CRISP-DM Guide 1.0 (CHAPMAN et al., 2000), a qual
apresenta-se amplamente difundida na área profissional. Por outro lado, em vista de que
a validação experimental inclui análise quantitativa de dados e análise de proporções de
distribuições, optou-se por utilizar também metodologia de pesquisa estatística Snijders
(2002) para esta fase dos experimentos.
52


5 MATERIAIS E MÉTODOS


       Neste capítulo é apresentada visão geral da pesquisa por meio da classificação
taxonômica e também por meio da descrição do método de validação experimental.



5.1 Classificação da pesquisa


       A seguir é realizada a classificação da presente pesquisa de acordo com a taxono-
mia descrita em Wazlawick (2017). Por se tratar de um tema recente e seus resultados
dependerem da aplicação prática de técnicas de mineração de texto no contexto de do-
cumentos jurídicos, este trabalho pode ser classificado como uma pesquisa de natureza
aplicada, pois busca desenvolver conhecimento que pode ser utilizado para aprimorar
processo de tomada de decisões em empresas e em escritórios de advocacia.
       Os objetivos do trabalho o caracterizam como uma pesquisa descritiva, uma vez
que os documentos jurídicos são classificados para realização de análise quantitativa.
       Em relação aos procedimentos técnicos, foi adotada a pesquisa experimental para
alcançar o propósito do trabalho, coletando dados de fontes públicas de sites governamen-
tais e desenvolvimento de modelos de aprendizado de máquina. Quanto à abordagem, foi
realizada pesquisa quantitativa em relação aos dados classificados por meio dos modelos
de Aprendizado de Máquina.
       A avaliação dos resultados da pesquisa quantitativa foi feita por meio de testes
estatísticos de significância que permitem a avaliação dos resultados.
       Na Tabela 5.1 é possível observar resumo da classificação da pesquisa desenvol-
vida com base na taxonomia descrita em Wazlawick (2017).




             Tabela 5.1: Resumo da classificação metodológica da pesquisa.
     Tipo        Classificação                                   Justificativa
 Natureza        Aplicada        Aprimoramento do processo de tomada de decisões.
 Objetivos       Descritiva      Descrição de tendência estatística de julgamento.
 Procedimentos   Experimental    Coleta de dados, classificação, análise e resposta à hipótese estatística.
 Abordagem       Quantitativa    Classificação dos dados por meio de modelo de Aprendizado de Máquina.
                                                                                          53


5.2 Método de Validação Experimental


       A execução dos experimentos foi realizada utilizando a metodologia descrita em
CRISP-DM Guide 1.0 (CHAPMAN et al., 2000) a qual apresenta um método iterativo
composto de diversas fases cujo objetivo é alinhar o processo de Mineração de Dados às
expectativas do negócio. Por outro lado, essa mesma metodologia prevê o retorno a fases
iniciais de modo a alinhar os requisitos e objetivos de pesquisa de acordo com conheci-
mento novo obtido nas fases de execução de experimentos. Isso se deve principalmente
à natureza da pesquisa de Mineração de Dados que busca extrair conhecimento oculto de
uma base de documentos. Desse modo, a seguir será apresentado o resumo do método se-
quencial de execução da validação experimental após a execução iterativa da metodologia
descrita no Capítulo 4.
       Assim, primeiramente foi definida a questão de pesquisa como Seria possível que
os tribunais avaliados e suas turmas recursais julguem favoravelmente proporção
significativamente maior de recursos para uma das partes do que para outra em mé-
dia? A seguir, foi definido que seria utilizado teste estatístico para verificação da questão
de pesquisa. Então, foi definido como hipótese estatística o seguinte: Os tribunais ava-
liados e suas turmas recursais julgam favoravelmente proporção significativamente
maior de recursos para uma das partes do que para outra em média. Assim, definiu-
se como Pa a proporção de recursos de empregados deferidos e Pb a proporção de recursos
de empresas deferidos. Então, foi definida como hipótese nula H0 Pa = Pb. Já a hipótese
alternativa como Pa 6= Pb. A seguir, é apresentado resumo do teste de hipótese estatística:


   • Pa = proporção de recursos de empregados deferidos.
   • Pb = proporção de recursos de empresas deferidos.
   • H0: Pa = Pb.
   • Ha: Pa 6= Pb.


       De modo a realizar a análise quantitativa das proporções de julgados favoráveis às
partes empregados e empresas era necessário obter instâncias de observações contendo es-
sas informações. Assim, procedeu-se ao desenvolvimento da base de dados pela utilização
de técnicas de Mineração de Dados. Portanto, foi definido como objetivo de Mineração de
Dados classificar automaticamente acórdãos judiciais em relação ao deferimento ou
não e classificar automaticamente o requerente do recurso em relação a ser empresa
ou a ser empregado. Além disso, classificar com os modelos desenvolvidos quanti-
54


dade significante de decisões judiciais e apresentar relatórios contendo as proporções
de julgados positivamente para cada uma das partes.
             A seguir, passou a execução do processo de Mineração de Dados o qual compre-
ende as seguintes fases: Coleta de Dados, que inclui a extração dos documentos da inter-
net; Preparação dos Dados, que inclui a limpeza dos dados, a anotação manual e anotação
automática das bases de dados extraídas; Modelagem que inclui o desenvolvimento de
modelos de Aprendizado de Máquina para a classificação automática das instâncias pre-
paradas na fase anterior; Aplicação que inclui a efetiva classificação das instâncias, análise
quantitativa, aplicação de testes estatísticos e desenvolvimento de gráficos. A Figura 5.1
apresenta ilustração explicativa do pipeline da Validação Experimental da pesquisa. Nas
seções seguintes são apresentados pontos-chave das fases do processo de Mineração de
Dados. Além disso, foi disponibilizado também por meio do repositório1 o código-fonte
de todo processamento da pesquisa, que pode ser usado para consulta dos detalhes de
implementação e reprodução dos experimentos.



5.2.1 Coleta dos Dados


             Os documentos judiciais que contém a informação sobre o julgamento de deter-
minado processo judicial são chamados de acórdãos, o quais são disponibilizados via in-
ternet. Esses documentos contêm informação quanto ao vencedor da causa. Assim, esses
documentos são as instâncias que precisam ser coletadas e processadas na fase seguinte
da Mineração de Dados. Assim, foi definido que seriam analisados quantitativamente
acórdãos de dois tribunais diferentes, a saber Tribunal Regional do Trabalho da 3a Região
e Tribunal Regional do Trabalho da 4a Região.
             Os documentos do TRT da 3a Região foram extraídos a partir do site <http:
//lexml.gov.br/> por meio dos arquivos sitemap.xml na raiz do site. Quanto ao site
<http://trt4.jus.br/>, foi utilizada a página de busca disponibilizada que permite a filtra-
gem de documentos por meio de palavras-chave. Assim, foram desenvolvidos robôs de
extração de dados utilizando a linguagem Python e a biblioteca Scrapy2 . Na época da exe-
cução dos experimentos estavam disponibilizados nas páginas os montantes de acórdãos
descritos na Tabela 6.2, essa tabela também apresenta a quantidade extraída efetivamente
pelos robôs de extração. Diversas requisições HTTP foram negadas pelos servidores o

     1
         <https://github.com/rhuanbarros/jurimetria_justica_do_trabalho>
     2
         <https://scrapy.org/>
                                                                                       55


Figura 5.1: Ilustração explicativa do pipeline da Validação Experimental da pesquisa in-
cluindo visão geral do processo.




que resultou na impossibilidade de extração de alguns documentos.



5.2.2 Preparação dos Dados


           A Preparação dos Dados consiste em realizar ajustes para a utilização dos dados
por algoritmos de Aprendizado de Máquina. Assim, primeiramente é realizada uma lim-
peza para a remoção de instâncias que apresentem mensagens de erro ou que contenham
caracteres truncados. Portanto foi aplicado um filtro que removeu todas as instâncias com
menos de 150 palavras. Importante salientar que a tokenização foi realizada utilizando
algoritmo que processa características específicas da língua portuguesa disponibilizado
no repositório da pesquisa3 .
           Após a limpeza, passou-se a transformação dos dados. Primeiramente foram ex-
traídos dados dos documentos por meio de expressões regulares o quais foram inseridos
   3
       <https://github.com/rhuanbarros/jurimetria_justica_do_trabalho>
56


na base de dados como metadados. O código-fonte Python e Regex pode ser encontrado
no repositório da pesquisa. Também foi realizada a extração de uma seção dos docu-
mentos de texto chamada Dispositivo. Essa seção contém informação suficiente para que
os algoritmos de Aprendizado de Máquina extraiam features e classifiquem corretamente
as instâncias. Além disso, todos os documentos mais de um recorrente também foram
removidos. Nesse ponto dos experimentos, a base de dados contém os metadados extraí-
dos juntamente com o dispositivo dos acórdãos e apenas decisões onde houve apenas um
recorrente, resultando o total de 22.946 instâncias.
       A seguir, prosseguiu-se a criação das bases de dados anotadas para utilização com
os algoritmos de Aprendizado de Máquina. Como o objetivo de Mineração de Dados
exige a realização de dois tipos de classificações, são necessárias duas bases de treina-
mento, uma que viabilize a classificação em relação ao tipo de recorrente e outra em
relação ao deferimento ou não da causa judicial.
       A criação da base de dados para classificação em relação ao tipo de recorrente foi
realizada por meio da extração aleatória de 270 instâncias de cada um dos tribunais em
formato CSV, totalizando 540 observações. Essas anotações foram realizadas exclusiva-
mente pelo próprio autor apenas, pois tal tarefa não exige nenhum conhecimento especí-
fico relacionado ao Direito. Os rótulos aplicados foram os seguintes: RECLAMANTE ou
RECLAMADA.
       Após, passou-se a criação de uma base de dados padrão-ouro utilizada para classi-
ficação em relação ao deferimento ou não da causa. Essa base foi utilizada para realização
de experimentos de modelagem de Algoritmo de Aprendizado de Máquina como também
foi utilizada para testes de eficácia dos modelos desenvolvidos. Essa fase foi desenvol-
vida seguindo critérios rigorosos de qualidade de acordo com a metodologia descrita em
(PUSTEJOVSKY; STUBBS, 2012). Foram selecionadas aleatoriamente 1.000 instân-
cias da base de dados preparada anteriormente que foram anotadas pelo próprio autor da
pesquisa, o qual detém conhecimentos jurídicos suficientes para esta tarefa. Além disso,
dessas 1.000, 500 foram anotadas também por uma pessoa bacharel em Direito e as outras
500 também foram anotadas por uma pessoa bacharel em Direito. Resultando assim, em
1.000 instâncias anotadas por duas pessoas. Importante considerar que foram utilizadas
para anotação apenas a parte do Dispositivo dos acórdãos. Os rótulos aplicados foram os
seguintes: DEFERIMENTO, INDEFERIMENTO ou SEM_ANALISE_MERITO.
       Também foi realizada a anotação automática da base de documentos por meio de
técnica de Supervisão Fraca utilizando o Framework Snorkel. Foram desenvolvidas 13
                                                                                       57


Funções de Rotulação que apenas verificam a existência de uma palavra na instância e
aplicam um rótulo específico, sendo possível verificar detalhes na Tabela 6.10. Então, o
algoritmo do Snorkel foi aplicado a totalidade de instâncias disponíveis de 22.946, re-
sultando, assim, numa base de treinamento criada programaticamente totalizando 22.471
instâncias. Por outro lado, observou-se que a base de dados criada programaticamente
apresentava grande desbalanceamento. Então procedeu-se ao tratamento dessa questão
por meio de Under-sampling criando-se assim outra base de treinamento, mas nesse caso
contendo o total de 1.644 instâncias, sendo 548 instâncias para cada classe.
       Enfim, na fase de Preparação dos Dados foram criadas 4 bases de treinamento.
Uma base para o treinamento em relação ao tipo de recorrente, contendo 540 instâncias.
Três bases para o treinamento em relação ao deferimento ou não da causa. Sendo uma
delas a base padrão-ouro anotada por especialistas, contendo 1.000 instâncias e duas delas
criadas programaticamente contendo 22.471 instâncias e 1.644 instâncias, mas nesse caso
balanceada.



5.2.3 Modelagem


       A seguir prosseguiu-se a fase de modelagem utilizando as bases de dados criadas
nas fases anteriores. Todos os experimentos nessa fase foram desenvolvidos de acordo
com o seguinte fluxo de pré-processamento: as instâncias são tokenizadas com algoritmo
específico que trata detalhes da língua portuguesa, em seguida é extraída a raiz de cada
palavra usando a biblioteca Spacy, após é realizada a vetorização por meio de TF-IDF e
por fim é realizada a modelagem com algoritmos de Aprendizado de Máquina, conforme
ilustrado na Figura 5.2. Além disso todos os experimentos foram modelados utilizando
os seguintes algoritmos da biblioteca Scikit Learn: Rocchio classifier, Gradient Boosting
Classifier, Naive Bayes Classifier, K-nearest Neighbor, Support Vector Machine (SVM),
Decision Tree, Random Forest. Também foi definido como padrão a utilização da métrica
F1 como parâmetro de avaliação.
       Primeiramente foi desenvolvido um experimento para classificação do tipo de re-
querente como empregado ou empresa sendo utilizado 70% da base para treinamento e
30% para testes. Enfim, o algoritmo Support Vector Machine (SVM) atingiu a métrica
mais alta de 96,91%.
       O desenvolvimento do modelo necessário para classificar as decisões em relação
ao deferimento ou não da causa judicial foi realizado por meio de três experimentos. Um
58


Figura 5.2: Ilustração explicativa do fluxo de pré-processamento para modelagem por
algoritmos de Aprendizado de Máquina.




utilizando a base de dados padrão-ouro, outro utilizando a base criada programaticamente
balanceada e outro utilizando a base de dados criada programaticamente com todas as
instâncias.
       O experimento utilizando a base de dados padrão-ouro foi realizado utilizando
30% da base para testes e 70% para treinamento. Sendo que também foi realizada a
validação-cruzada em 7 camadas com as instâncias de treinamento. Já quanto aos dois
experimentos utilizando as bases de dados criadas programaticamente, sendo uma balan-
ceada e a outra contendo a totalidade de instâncias, não houve a separação em 70/30.
Nesse caso, foi utilizada a totalidade de cada base criada programaticamente para trei-
namento e usada a totalidade da base padrão-ouro para testes. Assim, foi selecionado o
algoritmo Gradient Boosting pois foi o que atingiu a maior média na métrica F1 sendo de
                                                                                         59


92,48%.



5.2.4 Aplicação


         Nessa fase foi realizada a aplicação dos dois modelos de Aprendizado de Máquina
selecionados a totalidade de 22.946 instâncias extraídas e processadas nas fases anteriores.
Nesse ponto, foi realizada a filtragem e remoção de todos os documentos que continham o
rótulo SEM_ANALISE_MERITO em virtude de que os objetivos de negócio exigem ape-
nas a verificação das instâncias rotuladas com DEFERIMENTO ou INDEFERIMENTO.
A seguir foi realizado cálculo de proporções de julgamentos deferidos e indeferidos e apli-
cados testes estatísticos de proporção utilizando a biblioteca Python Statsmodel. Por fim,
foram desenvolvidos gráficos que apresentam as proporções de julgamentos de maneira
visualmente interessante.



5.3 Resumo do Capítulo


         Este capítulo apresentou resumo do método de validação experimental executado
na presente pesquisa e detalhado no Capítulo 6. Assim, primeiramente é realizada a clas-
sificação da pesquisa de modo a nortear o leitor sobre o tipo de estudo realizado. Na
sequência é salientada o tipo de metodologia utilizada para execução do trabalho e como
ela foi executada neste trabalho. Após é descrito método de execução da Validação Ex-
perimental de modo a permitir a fácil reprodução da pesquisa. Também é disponibilizado
link para acesso ao código-fonte do projeto o que permite verificar detalhes de implemen-
tação.
60


6 VALIDAÇÃO EXPERIMENTAL


       A validação experimental da presente pesquisa segue metodologia CRISP-DM
Guide 1.0 (CHAPMAN et al., 2000) conforme descrito no Capítulo 4. Desse modo,
considerou-se conveniente apresentar os resultados em seções com mesmos nomes das
fases da metodologia proposta. Assim, o Capítulo Validação Experimental está subdivi-
dido nas seguintes Seções: Compreensão do negócio, Preparação dos dados, Modelagem,
Avaliação de resultados e Aplicação. Também foi incluída ao final do capítulo a Seção
Limitações que trata detalhadamente das limitações dos experimentos.



6.1 Compreensão do negócio


       Tradicionalmente, pesquisas jurisprudenciais são realizadas para a verificação de
como as decisões judiciais são feitas, dos motivos que levam um magistrado a decidir
de determinada forma em cada caso, além dos argumentos em questão utilizados como
também as consequências dessas decisões em relação a cada assunto. Com tais pesquisas
busca-se diminuir a insegurança e conhecer os caminhos que os processos judiciais po-
dem tomar de acordo com o entendimento dominante de um tribunal, turma recursal ou
magistrado.
       Entretanto, devido ao distanciamento do Direito de outras ciências (GABARDO;
MORETTINI, 2013), como a Ciência da Computação, tais pesquisas eram realizadas sem
a utilização de recursos automáticos, aliás, eram realizadas manualmente (SALAMA et
al., 2011) com uma pequena amostra selecionada. Com a evolução das tecnologias de
Big Data e mineração de texto, podemos processar e analisar a grande maioria dos docu-
mentos judiciais em busca de padrões desconhecidos, confirmando ou negando hipóteses
supostas devido ao conhecimento geral adquirido na experiência de trabalho, e indo além,
desenvolvendo sistemas preditivos baseados em uma grande gama de dados.
       Além disso, o conhecimento da tendência de julgamento de uma turma recursal
da Justiça do Trabalho em relação à determinada matéria pode ser um fator de vantagem
no momento de realizar um acordo entre as partes, por exemplo. Especificamente nesse
ramo do Judiciário brasileiro, o acordo entre as partes é incentivado em todos os níveis
de jurisdição (TRT4, 2020) de forma que as partes entrem em consenso sozinhas em
relação a um valor justo que leve o processo ao fim. Além disso, é importante notar
que um processo judicial que tenha um acordo homologado por magistrado não tem mais
                                                                                       61


direito a recursos, dando, assim, fim definitivo ao caso, o que acarreta grande economia
processual a Justiça. Então, quando um processo é dirigido a nível de segundo grau a
uma turma recursal, o advogado que estiver mais bem informado sobre as tendências
de opinião daquele órgão julgador, será mais capaz de tomar uma decisão de aceitar ou
oferecer um acordo judicial que pode chegar a milhões de reais (TRT4, 2017).



6.1.1 Objetivo de negócio


       De acordo com Salama, Carlotti e Yeung (2018), o conhecimento popular e a ex-
periência de anos de operadores do Direito parecem encaminhar para a consolidação de
um senso comum de que existem certos magistrados ou turmas recursais na Justiça do
Trabalho inclinadas a proteger mais empregados do que empresas e vice versa. Isso le-
vanta questionamentos éticos quanto à parcialidade dos magistrados, conforme abordado
no Capítulo 2.1.3. Entretanto, essa situação é perfeitamente possível considerando que
a legislação brasileira deixa muitos aspectos em aberto permitindo a discricionariedade
dos magistrados em relação a que lado tomar para determinados assuntos a serem decidi-
dos. É importante considerar também que a dinâmica do Direito permite aos magistrados
tomarem posições diferentes em relação a mesma matéria e a argumentar de acordo. En-
tretanto, o ponto interessante para os advogados e empresas na prática jurídica é conhecer
quem são os magistrados ou turmas recursais mais inclinados para empresas ou empre-
gados. Assim, deseja-se confirmar por meio de técnicas computacionais e estatísticas se
a seguinte questão de pesquisa estabelecida se configura verdadeira: Seria possível que
os tribunais avaliados e suas turmas recursais julguem favoravelmente proporção
significativamente maior de recursos para uma das partes do que para outra em
média?


6.1.1.1 Teste estatístico

       A hipótese foi definida como Os tribunais avaliados e suas turmas recursais jul-
gam favoravelmente proporção significativamente maior de recursos para uma das
partes do que para outra em média. Assim a hipótese a ser validada exige a compara-
ção de duas proporções em relação à existência de diferença estatística. Assim, definiu-se
como Pa a proporção de recursos de empregados deferidos e Pb a proporção de recursos
de empresas deferidos. Então, foi definida como hipótese nula H0 Pa = Pb. Já a hipótese
62


alternativa como Pa 6= Pb. A seguir, é apresentado resumo do teste de hipótese estatística:


     • Pa = proporção de recursos de empregados deferidos.
     • Pb = proporção de recursos de empresas deferidos.
     • H0: Pa = Pb.
     • Ha: Pa 6= Pb.


6.1.1.2 Critério de sucesso do objetivo de negócio

        Foi definido como critério de sucesso do projeto o processamento e análise de de-
cisões judiciais por meio de testes estatísticos e o desenvolvimento de relatório contendo a
proporção de decisões para cada uma das partes em cada dos tribunais e turmas recursais
estudados, incluindo também dados dos testes estatísticos, como o nível de efeito e nível
de força estatística.



6.1.2 Requisitos e restrições


        O processamento e análise dos dados precisa ser realizado utilizando amostra ex-
traída significante para representar o total de decisões disponibilizadas publicamente.
Além disso, é necessário manter o sigilo quanto a qualquer informação de nomes das
partes que sejam citados nos processos judiciais. Por outro lado, a extração automatizada
de dados de páginas de internet pode ser proibida, ou até mesmo, o processo pode causar
certos danos aos servidores. Assim, foi definido também que seria respeitada qualquer li-
mitação imposta pelos sites a robôs de busca e que a extração dos dados seria realizada da
maneira mais preservada possível. Considerou-se necessário também a análise quantita-
tiva de ao menos dois tribunais diferentes para permitir a verificação da performance dos
modelos de Aprendizado de Máquina em documentos de origens diversas, como também
permitir a comparação das proporções de julgados entre tribunais diferentes.



6.1.3 Custo-benefício


        Grandes escritórios de advocacia lidam diariamente com milhares de processos
trabalhistas de uma única empresa. De acordo com Salama, Carlotti e Yeung (2019),
a condenação média no Tribunal Regional do Trabalho da 2a Região está em torno de
                                                                                     63


R$28.493,54 e o tempo médio de execução de dívida trabalhista de 4 anos e 10 me-
ses. Considerando o caso de um processo judicial hipotético nessa média de valor de
condenação, valeria a pena para a empresa efetivar acordo no valor até R$21.340,00 e
para empregado, acordo acima desse valor. Isso porque uma empresa poderia aplicar o
dinheiro durante os 4 anos e 10 meses a uma taxa média de 1% ao mês e no final a aplica-
ção poderia ter rendido R$38,006,00. Quanto ao empregado, ele poderia aplicar o mesmo
valor a uma taxa de 0,5% ao mês e ainda sair lucrando. Entretanto, o advogado que tiver
posse de relatório contendo as tendências médias estatísticas de julgamento em relação
a empregado e a empregador da turma recursal que recebeu o processo para julgamento
pode tomar decisão diversa baseado nesses dados. Além disso, deve ser considerado
que a turma recursal pode aumentar o valor de condenação (o que seria negativo para a
empresa), ou diminuir o valor de condenação (o que seria negativo para o empregado).
Assim, um empregado que receba oferta de acordo pouco abaixo do valor ótimo, poderia
escolher aceitar considerando que a turma recursal julgando o processo tenha tendência
de favorecer empresas e vice-versa.



6.1.4 Objetivo de mineração de dados


       O objetivo de Mineração de Dados é classificar automaticamente acórdãos ju-
diciais em relação ao deferimento ou não e classificar automaticamente o requerente
do recurso em relação a ser empresa ou a ser empregado. Além disso, classificar
com os modelos desenvolvidos quantidade significante de decisões judiciais e apre-
sentar relatórios contendo as proporções de julgados positivamente para cada uma
das partes.



6.2 Compreensão dos dados


       Primeiramente, procurou-se reunir a matéria prima da pesquisa, os acórdãos judi-
ciais. Nesse caso, os acórdãos são os documentos judiciais que publicam a decisão dos
magistrados indicando o deferimento ou não dos pedidos dos empregados e empregado-
res. Assim, esses documentos extraídos da internet vão compor a amostra para a execução
da presente pesquisa. Ou seja, cada instância de observação da amostra é na verdade um
acórdão judicial.
64


Tabela 6.1: Dados do Justiça em Números (CNJ, 2020) que apresentam a quantidade de
casos novos ajuizados no ano de 2019.
                         Quantidade de casos novos em 2019
                         TRT 4a Região             267.036
                         TJ RS                   1.413.893




         Tais documentos são disponibilizados publicamente por todos os tribunais brasi-
leiros em suas páginas de internet por meio de site de pesquisa em que os usuários podem
informar palavras-chave para busca. Assim, por meio dessas páginas de busca, foi reali-
zada uma exploração prévia da base de dados para reunir conhecimento sobre que tipos
de documentos estão disponibilizados, qual a frequência e quantidade de publicação dos
Tribunais, como os documentos são redigidos, que tipos de palavras são utilizadas, que
tipos de metadados são disponibilizados em conjunto. Durante essa fase de exploração
inicial, foram analisadas decisões judiciais da Justiça do Trabalho e da Justiça Comum
do Rio Grande do Sul. Durante essa avaliação, foram considerados diversos fatores como
a legibilidade dos documentos, quantidade de assuntos tratados nas decisões, estruturas
comuns aos documentos, padrões seguidos pelos magistrados, além do conhecimento do
pesquisador nas matérias do domínio do Direito analisadas.
         Desse modo, decidiu-se por realizar a pesquisa utilizando documentos da Justiça
do Trabalho. Tal decisão se baseia principalmente na experiência adquirida pelo pesqui-
sador após anos de trabalho como servidor público da Justiça do Trabalho. Por outro lado,
a Justiça do Trabalho trata de processos de causas estritamente trabalhistas, por ser uma
Justiça especializada nesse tipo de causa, ao contrário do que ocorre na Justiça Comum,
que trata de uma gama muito ampla de assuntos, desde cíveis até mesmo penais. Desse
modo, supôs-se que os documentos criados abrangem uma gama menor de assuntos e
que assim permitiriam uma análise mais acessível, objetiva e especializada. Apenas para
título de comparação, podemos observar que a Justiça do Trabalho é muito menor que
a Justiça Comum averiguando os dados de abertura de processos novos disponibilizados
pela CNJ no relatório Justiça em Números (CNJ, 2020) e verificando a Tabela 6.1 com
as informações resumidas. A partir desses dados, é possível verificar que a quantidade de
processos abertos na Justiça do Estado do Rio Grande do Sul é aproximadamente 5 vezes
maior.
                                                                                         65


6.2.1 Coleta de dados


        Após a decisão de qual Justiça seria foco na pesquisa, passou-se a análise de quais
páginas de internet seriam utilizadas para realizar a extração dos dados. Como os dados
precisariam ser extraídos automaticamente, foram avaliados diversos sites para escolher
os que não implementassem nenhum tipo de bloqueio a robôs de busca. Assim, foram
escolhidos dois sites para extração de dados, o <http://lexml.gov.br/> e o <http://trt4.jus.
br/>.
        Por outro lado, de modo a realizar a extração de dados para evitar qualquer pre-
juízo aos órgãos públicos e seus domínios na internet, foram implementados métodos
para a redução de qualquer possível dano gerado. Assim, foi colocado como diretriz da
pesquisa o respeito a qualquer limitação imposta pelos próprios sites a robôs de busca.
Tais limitações geralmente são encontradas nos termos de uso dos sites e em um arquivo
chamado robots.txt na raiz do domínio. Além disso, não foram encontrados outros tipos
de limitações, como por exemplo, a necessidade de o usuário provar que não é um robô
pela leitura de caracteres em uma imagem, ou resolução de um problema de lógica que
apenas um ser humano conseguiria resolver.
        Ademais, nenhum dos sites apresenta qualquer documento jurídico indicando os
termos de uso, tampouco apresentavam, à época da realização da atividade, qualquer
limitação a robôs de busca de escanearem todos os documentos públicos dos sites. Havia
apenas bloqueios em relação a acessos às áreas privadas, como, por exemplo, páginas de
intranet. Por outro lado, todos os documentos disponibilizados nos sites são de acesso
público, sem nem a necessidade de utilizar login.
        Além disso, todos os dados pessoais que possam identificar as partes não são publi-
cados em nenhuma parte da presente pesquisa. Desse modo, manteve-se a anonimização
das partes. Isso porque o mais importante para a pesquisa é analisar a massa de dados
agregada, e não os indivíduos em si. Ademais, foi obtido por e-mail autorização para a
utilização de decisões judiciais para a realização de pesquisa quantitativa com técnicas de
inteligência artificial e jurimetria.
        Enfim, o site do Tribunal Regional do Trabalho da 4a Região foi escolhido por se
tratar da Justiça do Trabalho com jurisdição em todo o território do Estado do Rio Grande
do Sul o qual se torna mais interessante para a comunidade acadêmica da nossa Universi-
dade como também para os cidadãos que usufruem das pesquisas realizadas na UFRGS.
Por outro lado, foi decidido realizar a pesquisa também em outro Estado para permitir a
66


comparação e avaliação das possíveis diferenças nos dados estatísticos produzidos, como
também observar possíveis diferenças de escritas nos documentos que poderiam afetar a
performance de algoritmos desenvolvidos. Assim, as decisões do TRT da 4a Região fo-
ram extraídas de seu próprio site e do site LexML foram extraídas as decisões do Tribunal
Regional do Trabalho da 3a Região. Tal Tribunal foi escolhido por ser o tribunal com
mais decisões da Justiça do Trabalho disponibilizadas no site. Para ambos os tribunais
optou-se por realizar a extração de decisões publicadas a partir do ano de 2017 até 2019.


6.2.1.1 Métodos de extração

             Os robôs de extração de dados foram desenvolvidos utilizando a linguagem Python
e a biblioteca Scrapy1 . Quanto ao site <lexml.gov.br>, eram disponibilizados diversos
arquivos sitemap.xml na raiz do site para facilitar a extração de dados. Tais arquivos
continham uma URL para cada documento disponibilizado. Além disso, por meio de
cada URL era possível saber do que o documento tratava, permitindo assim a seleção de
todos os documentos necessários a serem extraídos diretamente pelas URLs. Então, o
conteúdo completo das decisões era disponibilizado em páginas HTML, as quais foram
acessadas diretamente pelos robôs de extração de dados. Quanto ao site <trt4.jus.br>, há
uma página de busca que permite a filtragem de documentos por meio de palavras-chave.
Cada resultado é apresentado na mesma página com um link para o documento HTML
contendo a decisão completa. Assim, foi desenvolvido um robô de extração de dados para
simular um humano realizando a pesquisa no site, filtrar os resultados de acordo com os
critérios necessários e acessar os links contendo os acórdãos judiciais completos.


6.2.1.2 Tamanho da amostra

             A hipótese analisada exige a comparação da proporção de recursos de empregados
deferidos com a proporção de recursos de empresas deferidos, conforme a Seção 6.1.1.1.
Por outro lado, utilizou-se a biblioteca Statsmodels2 para realização do teste estatístico,
para cálculo das propriedades de efeito e força estatística, como também para cálculo do
tamanho da amostra. Desse modo, o cálculo do tamanho da amostra exige como variáveis
o tamanho das proporções sendo avaliadas, o tamanho da diferença entre as proporções
que se deseja verificar, o nível de força estatística e o nível de confiança desejados. En-
tretanto, os valores dessas variáveis não são conhecidos antes da efetiva verificação dos
     1
         <https://scrapy.org/>
     2
         <https://www.statsmodels.org/stable/index.html>
                                                                                      67


Tabela 6.2: Quantidade de decisões disponibilizadas e a quantidade da amostra inicial
extraída para cada tribunal.
                             Tribunal    População Amostra
                        TRT da 3a Região   268.691      26.634
                                 a
                        TRT da 4 Região    140.545      29.894


dados.
         Assim, buscou-se realizar a extração de decisões judiciais em certa quantidade
que permitisse o processamento inicial e sua análise exploratória para permitir a verifi-
cação aproximada das variáveis necessárias. Por outro lado, importante considerar que o
objetivo de negócio exige a realização de teste estatístico em relação às proporções em
função de cada tribunal como também em relação a cada turma recursal. Desse modo,
existe também a necessidade de se definir as quantidades mínimas de observações neces-
sárias em relação a cada turma recursal, o que impõe outra dificuldade, pois não se tem
conhecimento prévio das quantidades de processos deferidos para cada uma das partes
em cada turma recursal. Enfim, a Tabela 6.2 apresenta o tamanho das amostras extraídas
para análise inicial dos dados.


6.2.1.3 Dificuldades encontradas

         Os robôs de extração de dados desenvolvidos não conseguiram extrair a totalidade
dos documentos disponíveis em virtude de que houve problemas de requisições HTTP
não respondidas pelos servidores, como também certa quantidade dos documentos foram
disponibilizadas apenas em formato PDF. Enfim, foi possível extrair diretamente o texto
puro da maioria dos arquivos, entretanto, os arquivos PDF precisaram ser processados em
uma segunda etapa na fase de coleta.



6.2.2 Descrição dos dados


         A fase de coleta dos dados resultou na compilação de 2 arquivos CSV em relação
ao TRT da 3a Região e 1 arquivo em relação ao TRT da 4a Região, conforme Tabela 6.3.
No caso do TRT da 3a Região, foram gerados dois arquivos em virtude de dificuldades
técnicas de processamento da carga de dados no momento da extração. Os arquivos CSV
são compostos de um campo com o nome INTEIRO_TEOR contendo o texto puro dos
acórdãos judiciais. Foi utilizada a biblioteca Pandas para manipulação dos arquivos nesse
formato em virtude da facilidade de uso.
68


 Tabela 6.3: Relação dos arquivos gerados a partir da extração dos dados dos tribunais.
                                                                    Quantidade de amostras
   Tribunal                        Nome do arquivo                  efetivamente extraídas   Tamanho
TRT da 3a Região   TRT3_inteiro_teor_2017_2018_2019_amostra_1.csv                   17.846   245MB
TRT da 3a Região   TRT3_inteiro_teor_2017_2018_2019_amostra_2.csv                    8.788   120MB
TRT da 4a Região   TRT4_inteiro_teor_2017_2018_2019_amostra.csv                     29.894   541MB


Tabela 6.4: Descrição da base de dados extraída do TRT da 3a Região em relação à
quantidade de palavras.
                                                Palavras
                          Quantidade média        2.093
                          Desvio padrão           1.936
                          Quantidade mínima            1
                          25% percentil             810
                          50% percentil           1.457
                          75% percentil           2.690
                          Quantidade máxima      23.625


6.2.3 Exploração dos dados


       As bases de dados foram analisadas separadamente, assim, o conjunto do TRT
da 3a Região apresentou o total de 26.634 instâncias, já o TRT da 4a Região apresen-
tou 29.894. A descrição da quantidade de palavras contidas nos documentos pode ser
observada nas Tabelas 6.4 e 6.5. Os Gráficos contendo as distribuições dos unigramas,
bigramas e trigramas é apresentada no Apêndice na Seção A.3.



6.2.4 Qualidade dos dados coletados


       A qualidade das instâncias extraídas a partir dos arquivos HTML foi satisfatória na
maioria dos casos, entretanto, houve algumas instâncias que continham apenas mensagens
de erros com servidores, assim, tais documentos foram removidos na fase de Preparação


Tabela 6.5: Descrição da base de dados extraída do TRT da 4a Região em relação à
quantidade de palavras.
                                                Palavras
                          Quantidade média        2.738
                          Desvio padrão           2.357
                          Quantidade mínima            0
                          25% percentil           1.051
                          50% percentil           2.065
                          75% percentil           3.654
                          Quantidade máxima      23.391
                                                                                      69


dos Dados. Já em relação aos arquivos PDF, não foi possível utilizar nenhuma dessas
instâncias. A extração do texto puro foi realizada por meio do aplicativo gratuito Xpd-
fReader 3 , entretanto o processamento gerou arquivos com caracteres inseridos em partes
incorretas do texto, especialmente caracteres referentes a cabeçalhos e rodapés.



6.3 Preparação dos dados


         Nesta fase da pesquisa são realizados diversos processamentos com os documen-
tos para prepará-los para serem usados na fase seguinte de modelagem de dados. Assim,
são realizadas limpeza dos dados como também transformações para extrair e ressaltar
as features mais importantes para a tarefa de classificação. Além disso, também é rea-
lizada a construção da base padrão-ouro, a qual é utilizada para os testes dos modelos
desenvolvidos.



6.3.1 Limpeza dos dados


         A limpeza dos documentos de texto foi realizada para garantir a qualidade mí-
nima das instâncias para serem utilizadas nas fases subsequentes de transformação de
dados e modelagem. Conforme as Tabelas 6.4 e 6.5, é possível observar que há instân-
cias contendo nenhuma ou apenas uma palavra. Assim, foi realizada a análise visual das
instâncias contendo menos de 150 palavras e verificou-se que havia muitas mensagens
de erros nos documentos. Algumas instâncias continham palavras irreconhecíveis. En-
fim, considerou-se prudente remover todas as instâncias que continham menos de 150
palavras.



6.3.2 Transformação dos dados


         Essa fase tem por objetivo extrair e ressaltar as features mais importantes para
os algoritmos de modelagem de dados. Assim, são adicionados metadados às decisões,
como também são removidos documentos e partes dos documentos que não são relevantes
à pesquisa.


  3
      <https://www.xpdfreader.com/pdftotext-man.html>
70


6.3.2.1 Enriquecimento com metadados das decisões judiciais

             Os documentos coletados continham de maneira não estruturada em seu conteúdo
de texto informações úteis importantes para a realização de agregações e análises em fases
posteriores. Assim, foram extraídos por meio de expressões regulares os seguintes dados:
data de publicação, nome do relator, órgão julgador, nome dos recorrentes, dispositivo do
acórdão e a quantidade de recorrentes. Esses dados foram extraídos por meio da utilização
de palavras-chave e strings Regex. O código-fonte Python e Regex pode ser encontrado
no repositório da pesquisa4 .
             Entretanto houve dificuldades na aplicação dessa técnica pois certos documentos
utilizavam um padrão para escrever essas informações e outros documentos usavam outro
padrão. Assim, procurou-se criar expressões regulares que abrangessem o maior número
de casos possíveis. Infelizmente, um pequeno número de instâncias não teve esses dados
extraídos devido a um modo de escrita diverso e acabaram por ser removidas da base
de dados. Enfim, todas as amostras em que as expressões regulares foram efetivas na
extração foram enriquecidas com esses dados inseridos como colunas adjacentes.


6.3.2.2 Extração do dispositivo da sentença

             De acordo com a Seção 2.1, as decisões proferidas pelos magistrados brasileiros
devem ser redigidas seguindo certos padrões e conter determinados elementos. Um des-
ses elementos é chamado de dispositivo da sentença, o qual é de caráter obrigatório e deve
conter em todas as decisões e acórdãos publicados. Essa parte do texto deve conter parti-
cularmente a informação sobre se o recorrente teve seu pedido deferido ou não em poucos
parágrafos, direto e objetivamente. Assim, essa parte do texto foi extraída, pois é nesse
trecho que está a informação necessária a ser modelada pelo algoritmo de Aprendizado
de Máquina a ser desenvolvido.


6.3.2.3 Remoção de documentos com mais de um recorrente

             Muitos dos acórdãos publicados pelos tribunais dizem respeito a mais de um re-
curso impetrado, nesses casos, ambas as partes recorreram da decisão. Assim, o acórdão
trata dos pedidos de recurso de ambos os recorrentes e o dispositivo da decisão precisa
ser objetivo e dar uma resposta a cada um dos recursos.
             Assim, esse tipo de documento, em que ambas as partes recorreram, exigiria uma
     4
         <https://github.com/rhuanbarros/jurimetria_justica_do_trabalho>
                                                                                       71


anotação diferenciada para ser possível abranger por completo a semântica necessária
para alcançar o objetivo de mineração. Nesse caso, seria necessário anotar individual-
mente os tokens do documento para ser possível identificar os elementos distintivos que
representam cada uma das partes e o seu deferimento ou não.
       Entretanto, construir um modelo que consiga identificar a resposta dos magis-
trados em relação a cada um dos recursos aumentaria o grau de dificuldade do modelo
proposto a ser construído pois necessitaria da aplicação de demasiadas técnicas de apren-
dizado de máquina e processamento de linguagem natural. Assim, para não aumentar o
nível de complexidade da pesquisa num primeiro momento, decidiu-se por não proces-
sar tais documentos. Além disso, o objetivo de negócio não exige especificamente que
esse tipo de documento seja analisado pelo algoritmo, tornando, assim, fora do escopo do
projeto analisar recursos com mais de um recorrente.
       Desse modo, os documentos foram processados em busca de todos que continham
mais de um recorrente por meio de análise do texto do campo Recorrente dos documentos
contendo uma vírgula ou um e. Se houvesse, tal documento se tratava de mais de um
recorrente e foram removidos do da base. Enfim, após todo o processamento e remoção
de instâncias desnecessárias, a base de documentos do Tribunal Regional do Trabalho da
3a Região restou com o total de 10.875 instâncias, já o Tribunal Regional do Trabalho da
4a Região com 12.071. Foram removidas 33.582 instâncias.
       A remoção dessas instâncias da base de dados pode ter enfraquecido o nível de
força do teste estatístico aplicado nas fases finais da pesquisa em vista de que houve
diminuição considerável de documentos disponíveis para análise. Entretanto, neste ponto
da pesquisa não é possível estimar o impacto visto que só é possível calcular o nível de
força do teste estatístico após a realização do teste num momento em que a base de dados
já foi totalmente processada em relação às proporções de julgados favoráveis a cada parte.



6.3.3 Anotação manual da base de documentos


       Os documentos extraídos e processados nos capítulos anteriores foram salvos em
formato CSV em ordem aleatória e analisados diretamente em aplicativo editor de planilha
de texto. A anotação manual da base de documentos foi desenvolvida seguindo a meto-
dologia apresentada no Capítulo 2.4 a qual inicia pela fase de modelagem do metamodelo
de rótulos a serem aplicados. Assim, foi necessário que cada documento contivesse uma
marcação em relação a se o requerente é empresa ou empregado e também outra marcação
72


indicando se o recurso foi deferido ou não.


6.3.3.1 Anotação para desenvolvimento do modelo de classificação do tipo de recorrente

       Foram modelados dois rótulos utilizando a nomenclatura própria do Direito do
Trabalho, conforme exposto na Seção 2.1.1: RECLAMANTE, que indica que a parte é
empregado, e RECLAMADA, que indica que a parte é empresa. O modelo consiste de um
vocabulário de termos T, do relacionamento entre esses termos R, e da interpretação I,
conforme demonstrado abaixo.


     • T = {Tipo_documento, RECLAMANTE, RECLAMADA}
     • R = {Tipo_documento ::= RECLAMANTE | RECLAMADA}
     • I = {RECLAMANTE = Parte recorrente é empregado, RECLAMADA = Parte
      recorrente é empresa}


6.3.3.2 Execução do processo de anotação manual em relação ao tipo de recorrente

       A anotação dos documentos em relação ao tipo de recorrente foi realizada pelo
próprio autor apenas, pois tal tarefa não exige nenhum conhecimento específico do Di-
reito. A rotulação consistiu apenas na verificação do nome do recorrente ser nome de
pessoa física ou jurídica. Assim, foi extraído aleatoriamente 270 instâncias de cada um
dos tribunais em formato CSV, totalizando 540 observações. Essa quantidade foi definida
arbitrariamente pelo autor após verificação da performance em testes de modelagem.


6.3.3.3 Anotação para desenvolvimento do modelo de classificação em relação ao deferi-
        mento ou indeferimento da decisão

       A princípio foram modelados brevemente dois rótulos: DEFERIMENTO para in-
dicar uma decisão que houve julgamento favorável e INDEFERIMENTO para indicar uma
decisão que não houve julgamento favorável. Após, foi iniciada a fase de anotação pelo
próprio autor, o qual observou que seria necessária a criação de outro rótulo pois havia
documentos que não se encaixavam em nenhum dos casos. Assim, foi criado o rótulo
SEM ANÁLISE DE MÉRITO.
       Foi necessária a criação desse rótulo pois há acórdãos em que não há análise
quanto aos pedidos contidos no recurso devido a algum elemento que prejudique sua
apreciação pelos magistrados, conforme esclarecido no Capítulo 2.1.2. Entretanto, es-
                                                                                         73


ses acórdãos sem julgamento de mérito ocorrem em uma minoria de casos. Enfim, foi
inevitável o retorno à fase de modelagem para adequação do modelo com o novo rótulo.
       Além disso, considerou-se importante a criação do rótulo SEM ANÁLISE DE MÉ-
RITO para ser possível verificar o tamanho da distribuição desse tipo de documento na
base de dados. Em fases finais de análise quantitativa e cálculo de proporções de julgados
deferidos e indeferidos, poderia haver a dúvida em relação a qual classe esse tipo de do-
cumento haveria sido classificada, em virtude de não haver sido treinado o classificador
com esse tipo de documento previamente. Assim, poderia ser levantado o questionamento
se esse tipo de documento não estaria inflando umas das proporções de deferidos ou in-
deferidos. Enfim, abaixo é apresentado o modelo criado para essa tarefa de anotação.


   • T        =      {Tipo_documento,         DEFERIMENTO,            INDEFERIMENTO,
      SEM_ANALISE_MERITO}
   • R    =       {Tipo_documento    ::=   DEFERIMENTO          |   INDEFERIMENTO          |
      SEM_ANALISE_MERITO}
   • I = {DEFERIMENTO = Julgamento favorável ao recorrente, INDEFERIMENTO
      = Julgamento desfavorável ao recorrente, SEM_ANALISE_MERITO = Julga-
      mento não é favorável nem desfavorável ao recorrente}


6.3.3.4 Execução do processo de anotação manual em relação ao deferimento ou indefe-
       rimento da decisão

       A rotulação dos documentos foi realizada por três pessoas, sendo o autor e dois
voluntários bacharéis em Direito. Assim, foram elaboradas planilhas online no aplicativo
Google Suite com as decisões para anotação. Constaram uma coluna com as decisões e
outra para inserir o rótulo em cada linha respectivamente. A Figura A.8 apresenta foto da
tela da planilha com algumas decisões de exemplo. Assim, foram criadas duas planilhas,
uma para cada anotador. Em cada planilha foi inserido 250 acórdãos do TRT da 3a Região
e 250 acórdãos do TRT da 4a Região. Ou seja, cada voluntário realizou a anotação de 500
documentos. Além disso, foi feita cópia de ambas as planilhas para serem anotadas pelo
autor da pesquisa. Enfim, houve o total de 1000 documentos anotados por duas pessoas.
Cada um dos documentos foi anotado por um dos anotadores voluntários e pelo autor
da pesquisa. Cabe salientar que o autor da pesquisa detém conhecimentos jurídicos de
nível técnico e mais de 10 anos de experiência profissional na Justiça brasileira, incluindo
tempo de trabalho especificamente em varas do trabalho.
74


       Vale ressaltar que a amostra selecionada para a tarefa de anotação inclui apenas
decisões em que houve apenas um recorrente, o que tornou a tarefa de anotação mais
simples porque havia apenas um recurso para ser apreciado, ou seja, apenas um recurso
para ser deferido ou indeferido. Além disso, o processamento final da base de documentos
para estimar a tendência de opinião dos magistrados também foi realizado com decisões
em que houve apenas um recorrente, conforme exposto na Seção 6.3.2.3.
       Por outro lado, houve a preocupação de criar a planilha para os anotadores de
modo a facilitar a correta edição do documento. Assim, as áreas do documento que con-
tinham as decisões foram bloqueadas para edição, deixando livre para edição apenas a
coluna Rótulo. Também houve a aplicação de cores alternadas para o fundo das linhas
para facilitar a leitura, visualização e edição.
       A seguir foi realizado o desenvolvimento das diretrizes de anotação a qual contém
orientações gerais aos anotadores. Tal documento contém uma seção de introdução que
expõe resumidamente o objetivo da pesquisa e como funciona o trabalho de anotação de
documentos por anotadores voluntários. Após, são apresentados os rótulos com a devida
explicação detalhada de como cada um deve ser usado. Além disso, são apresentados
exemplos de decisões e o respectivo rótulo considerado correto pelo autor da pesquisa.
Por fim, é apresentada uma lista de pontos importantes a serem observados pelos anota-
dores. A Figura 6.1 apresenta trecho do documento que pode ser encontrado completo no
Apêndice A.4.

Figura 6.1: Trecho do documento Diretrizes para anotação manual de documentos jurídi-
cos para pesquisa de mestrado de Rhuan Barros




6.3.3.5 Avaliação da tarefa de anotação e criação do padrão-ouro

       Conforme exposto na Seção 2.4.1, foi realizada a avaliação do nível de concordân-
cia entre os rótulos aplicados pelos anotadores. Assim, a Tabela 6.6 apresenta a matriz
                                                                                     75


              Tabela 6.6: Matriz de confusão em relação aos rótulos aplicados
                                 P2              P2                 P2
                            DEFERIMENTO    INDEFERIMENTO    SEM_ANALISE_MERITO   TOTAL
P1      DEFERIMENTO         435            6                1                    442
P1     INDEFERIMENTO        4              534              1                    539
P1   SEM_ANALISE_MERITO     1              6                12                   19
           TOTAL            440            546              14                   1000




Tabela 6.7: Balanceamento das classes da base de dados anotada em relação ao tipo de
requerente.
                           CLASSE          QUANTIDADE
                        RECLAMANTE                      312
                        RECLAMADA                       226




de confusão em relação aos rótulos aplicados. Aplicando a fórmula Cohen’s Kappa é ob-
tido o valor de 0,963 que é considerado alto nível de concordância. Após, foi realizada
a adjudicação da base de dados em que o próprio autor resolveu as discordâncias, sendo
possível observar algumas instâncias de exemplo no Apêndice A.5.



6.3.4 Exploração das bases de dados anotadas manualmente


       Nesta fase da pesquisa é realizada novamente uma exploração da base de docu-
mentos, entretanto, neste caso é possível obter informações essenciais para as fases se-
guintes, pois os documentos receberam anotações. Assim, é possível analisar a frequência
das palavras correlacionadas a cada categoria.


6.3.4.1 Base de dados anotada manualmente quanto ao tipo de requerente

       O processamento da base de dados anotada manualmente quanto ao tipo de re-
querente gerou análises quanto ao balanceamento das classes e também em relação às
palavras mais comuns. Assim, na Tabela 6.7 e na Figura 6.2 é possível observar o balan-
ceamento das classes, sendo que a classe RECLAMADA contém pouco menos instâncias
anotadas. Quanto à análise dos unigramas mais comuns em cada classe, é possível ve-
rificar que, para a classe RECLAMANTE, sobrenomes comuns no Brasil, como Silva e
Santos figuram como mais frequentes. Já para a classe RECLAMADA, as palavras Ltda,
Brasil e SA ficam respectivamente em primeiro, segundo e terceiro lugar na lista de mais
frequentes.
76


Figura 6.2: Histograma apresentando o balanceamento das classes da base de dados ano-
tada em relação ao tipo de reclamante.




Tabela 6.8: Balanceamento das classes da base de dados anotada em relação ao deferi-
mento ou não da decisão.
                           CLASSE               QUANTIDADE
                   INDEFERIMENTO                            539
                   DEFERIMENTO                              441
                   SEM_ANALISE_MERITO                        20


6.3.4.2 Base de dados anotada manualmente quanto ao deferimento ou não da decisão

       Foi realizado o processamento e análise da base de dados anotada manualmente
para explorar o balanceamento das classes e as palavras mais comuns usadas no campo
Dispositivo em função do rótulo recebido separadamente para cada tribunal. Assim,
na Tabela 6.8 e na Figura 6.3 é possível verificar que há desbalanceamento da classe
SEM_ANALISE_MERITO, a qual contém apenas 20 instâncias de um total de 1000.
Quanto ao texto do campo Dispositivo, foi verificado que a maioria das instâncias contém
até 250 palavras nesse campo, conforme Figura 6.4. Além disso, é possível observar na
Tabela 6.9 que magistrados escrevem menos quando indeferem um recurso em compara-
ção com os recursos deferidos.
       Por outro lado, também foi elaborada análise de termos e suas associações em re-
lação a cada classe anotada por meio da biblioteca Python Scattertext (KESSLER, 2017).
Assim, é possível observar os termos mais associados com cada uma das classes anotadas
para ambos os tribunais na Figura 6.5 e nas listas abaixo os termos mais associados para
cada uma das classes. Os termos foram selecionados por meio de tokenização realizada
utilizando expressões regulares que abrangem características da língua portuguesa.
                                                                                   77


Figura 6.3: Histograma apresentando o balanceamento das classes da base de dados ano-
tada em relação ao deferimento ou não da decisão.




       Figura 6.4: Histograma quantidade de palavras no dispositivo por tribunal




   • Termos mais associados com os acórdãos anotados como DEFERIMENTO.

        – ’deu lhe’,
        – ’dar provimento’,
        – ’divergência deu’,
        – ’dar’,
        – ’unanimidade dar’,
        – ’à condenação’,
        – ’parcial’,
        – ’condenar’,
78


Tabela 6.9: Descrição da base de dados anotada manualmente em função da quantidade
de palavras no campo Dispositivo em relação a cada rótulo aplicado em cada tribunal.
                                                                     Palavras
Tribunal           Rótulo           Contagem de instâncias   Média    Mínimo     25%    50%    75%    Máximo
               DEFERIMENTO                            197     248           75    133    161    219     2540
 TRT3         INDEFERIMENTO                           288     182           43     98    112    133     2743
            SEM_ANALISE_MERITO                         15     290           95    103    123    154     1572
               DEFERIMENTO                            244     124           34     83    113    149      494
 TRT4         INDEFERIMENTO                           251      53           35     44     47     50      995
            SEM_ANALISE_MERITO                           5     84           64     69     84     90      117



            – ’reflexos’,
            – ’provimento para’

     • Termos mais associados com os acórdãos anotados como INDEFERIMENTO.

            – ’divergência negou’,
            – ’negou lhe’,
            – ’negou’,
            – ’negar’,
            – ’negar provimento’,
            – ’unanimidade negar’,
            – ’embargos de’,
            – ’de declaração’,
            – ’embargos’,
            – ’declaração’

     • Termos          mais    associados       com          os      acórdãos           anotados       como
       SEM_ANALISE_MERITO.

            – ’ação de’,
            – ’de cobrança’,
            – ’cobrança de’,
            – ’cobrança’,
            – ’comum’,
            – ’competência’,
            – ’não conheceu’,
            – ’estadual’,
            – ’justiça comum’,
            – ’rel’,


           A partir da anotação manual dos documentos e também de sua exploração por
                                                                                      79


Figura 6.5: Gráfico que apresenta os termos mais associados com cada uma das classes
anotadas. Mais próximas do canto superior esquerdo encontram-se palavras mais asso-
ciadas com o rótulo Deferimento. Já próximas do canto inferior direito encontram-se
palavras mais associadas com o rótulo Indeferimento.




meio de técnicas de mineração de texto, foi possível observar diversos padrões de escrita
dos magistrados particulares a sua área de domínio. Especialmente em relação aos recur-
sos negados, é comum os magistrados utilizarem as mesmas palavras, como, por exemplo,
“negar” e suas variações. Por outro lado, é possível observar que os magistrados têm o
hábito de utilizar a palavra “dar” e suas variações para representar o deferimento de um
recurso.



6.3.5 Anotação automática da base de documentos por meio de Supervisão Fraca


       A anotação automática de documentos por meio de Supervisão Fraca permite o
desenvolvimento rápido de bases de dados para a utilização em algoritmos de classifi-
cação de documentos por meio de Aprendizagem de Máquina Supervisionada, além de
que a técnica permite a anotação de grande quantidade de instâncias diretamente. Assim,
supôs-se que tal técnica poderia ajudar a mitigar ponto negativo da pesquisa em relação
a pequena base de documentos anotada manualmente na Seção 6.3.3. Além disso, a ins-
piração para utilização dessa técnica foi obtida em vista de que o autor percebeu durante
a fase de anotação manual que muitos termos se repetiam e que isso poderia ser usado
a favo da pesquisa. Desse modo, optou-se por avaliar a performance dessa técnica em
documentos jurídicos. Enfim, foi utilizado o Snorkel Framework (RATNER et al., 2017)
para execução dessa etapa.
80


Tabela 6.10: Lista de funções de rotulação criadas para aplicação automática de rótulos à
base de dados.
     Função de Rotulação            Palavra-chave                Classificação
   lf_negar_provimento          negar provimento          INDEFERIMENTO
   lf_rejeitar                  rejeitar                  INDEFERIMENTO
   lf_nao_acolher               não acolher               INDEFERIMENTO
   lf_manter_decisao            manter decisão            INDEFERIMENTO
   lf_julgou_improcedente       julgou improcedente       INDEFERIMENTO
   lf_dar_provimento            dar provimento            DEFERIMENTO
   lf_dar_parcial_provimento dar parcial provimento DEFERIMENTO
   lf_proveu                    proveu                    DEFERIMENTO
   lf_parcialmente_proveu       parcialmente proveu       DEFERIMENTO
   lf_nulidade_sentenca         nulidade sentença         SEM_ANALISE_MERITO
   lf_nao_conhecer              não conhecer              SEM_ANALISE_MERITO
   lf_deixar_conhecer           deixar conhecer           SEM_ANALISE_MERITO
   lf_prejudicada               prejudicada               SEM_ANALISE_MERITO


             Assim, prosseguiu-se com a análise dos termos mais associados às classes anota-
das em relação ao deferimento do acórdão na Seção 6.3.4. Desse modo, foi possível ob-
servar que existem certos padrões na redação dos documentos pelos magistrados, os quais
podem ser explorados por meio da criação de Label Functions do Snorkel. Dessa maneira,
a análise dessas informações gerou o desenvolvimento de heurísticas que processam por
meio de Regex a presença ou não de certas palavras identificadoras do deferimento ou
não do recurso pelo magistrado, conforme pode ser observado pela Tabela 6.10. Impor-
tante ressaltar que as palavras-chave são testadas utilizando o seu lemma processadas por
meio da biblioteca Spacy 5 . Além disso, há a remoção de stopwords que incluem prono-
mes oblíquos átonos os quais muitas vezes se encontram no meio de locuções verbais e
poderiam interferir na localização das palavras-chave.
             Em vista de que foram desenvolvidas diversas Funções de Rotulação para reali-
zar a tarefa de classificação dos documentos, houve a sobreposição de classificação em
diversas instâncias, como é possível observar pela coluna Sobreposições da Tabela 6.12,
entretanto a maioria delas obteve porcentagens abaixo de 10% o que indica baixa sobre-
posição. Além disso, podemos observar que houve aproximadamente 10% de rotulações
conflitantes em relação às classes INDEFERIMENTO e DEFERIMENTO, e menos de
5% em relação à classe SEM_ANALISE_MERITO, ou seja, nesses casos houve uma
anotação indicando ao menos duas classes diferentes. Importante ressaltar que as instân-
cias que receberam o rótulo ABSTAIN não entram na contagem de conflitantes. O rótulo
ABSTAIN é aplicado quando a função de rotulação não tem conhecimento suficiente para
     5
         <https://spacy.io/>
                                                                                        81


aplicar um rótulo, conforme explicado na Seção 2.6.5. Por outro lado, é possível observar
pela Figura 6.6 que aproximadamente 80% das instâncias receberam um rótulo e que em
torno de 15% receberam dois ou mais rótulos.
       Após, foi utilizado o algoritmo LabelModel do Snorkel para realizar o processa-
mento da matriz contendo todas as classificações pelas Funções de Rotulação de modo
gerar um modelo probabilístico a fim de ser usado para processar a base de dados com-
pleta e finalmente assinalar um rótulo final a cada instância. Cabe salientar que esse
modelo probabilístico desenvolvido não tem capacidade de generalização ao realizar o
processamento de instâncias que as Funções de Rotulação também não tiveram capaci-
dade de aplicar um rótulo, em vista disso, instâncias que receberam o rótulo ABSTAIN,
continuaram recebendo esse rótulo nessa fase de processamento.
       Desse modo, o modelo treinado foi aplicado à totalidade 22.946 instâncias da base
de documentos disponível, tendo efetivamente aplicado rótulo de INDEFERIMENTO,
DEFERIMENTO ou SEM_ANALISE_MERITO a 97,91%, como é possível verificar
pela Figura 6.7. Também é possível observar que aproximadamente 2% das instâncias
receberam o rótulo ABSTAIN, ou seja, o modelo não aplicou nenhum rótulo. Portanto,
a tarefa de anotação automática de documentos por meio de técnica de Supervisão Fraca
gerou uma nova base de dados contendo o total de 22.471 instâncias.
       Importante considerar que os tribunais avaliados disponibilizam centenas de mi-
lhares de decisões online de dezenas de anos passados. Entretanto, por dificuldades téc-
nicas, não foram possíveis de serem extraídos. Dessa maneira, em trabalhos futuros, essa
totalidade de documentos poderiam ser extraídos e processados por meio do Snorkel Fra-
mework o que tenderia a aumentar o nível de acurácia alcançado.
       Além disso, é possível observar que o modelo generativo do Snorkel Framework
não contém capacidade de generalização o que se traduz na sua incapacidade de rotular
instâncias que as Funções de Rotulação não continham conhecimento de domínio sufici-
ente para aplicar um rótulo correto e por fim aplicaram o rótulo ABSTAIN, nesse caso,
em 2% das instâncias disponíveis. Entretanto, a capacidade de generalização é uma ca-
racterística desejada em aplicações prática de modo que o modelo tenha habilidade de se
adaptar e rotular instâncias previamente não vistas e oriundas da mesma distribuição.
       Assim, essa incapacidade de generalização impede a utilização do modelo ge-
nerativo do Snorkel Framework para a classificação final da base de dados da presente
pesquisa. Desse modo, na Seção 6.4, foram realizados experimentos para o desenvol-
vimento de modelo de Aprendizado de Máquina utilizando algoritmos que contenham a
82


Tabela 6.11: Quadro resumo contendo as bases de dados criadas na presente pesquisa
incluindo as quantidades de instâncias por classe.
                                                            Quantidade por classe
            Base de dados             INDEFERIMENTO     DEFERIMENTO SEM_ANALISE_MERITO     Total
 Padrão-ouro                                      539              441               20    1.000
 Anotada automaticamente                       12.000           9.923              548    22.471
 Anotada automaticamente balanceada               548              548             548     1.644



capacidade de generalização. E por fim, na Seção 6.5 foi aplicado o modelo desenvolvido
selecionado a totalidade de 22.946 instâncias. O que permitiu a anotação da totalidade de
documentos disponíveis.
        Ademais, da mesma maneira que ocorreu com a base de dados anotada manu-
almente, houve grande desbalanceamento da classe SEM_ANALISE_MERITO. Desse
modo, foi aplicada técnica de Under-samplig a fim de serem removidas aleatoriamente
instâncias das classes INDEFERIMENTO e DEFERIMENTO para conterem finalmente
a mesma quantidade que a classe SEM_ANALISE_MERITO, totalizando 548 instâncias
para cada classe. Portanto, a base de dados final balanceada criada programaticamente
foi gerada contendo o total de 1.644 instâncias. Enfim, por meio da Tabela 6.11, é pos-
sível observar a comparação entre todas as bases de dados criadas na presente pesquisa
incluindo as quantidades de instâncias por classe.
        A checagem dos documentos anotados automaticamente foi realizada pelo próprio
autor pela simples observação de algumas instâncias de modo a verificar erros grotescos.
Por outro lado, seria inviável realizar a checagem total, além disso, não faz parte da técnica
de Supervisão fraca a realização dessa checagem visto que o objetivo é construir a base
automaticamente de maneira menos dispendiosa possível em relação ao tempo necessário
e em relação ao custo financeiro. Além disso, a checagem é, de certo modo, realizada ao
final da pesquisa por meio do treinamento do modelo utilizando a base de dados criada
programaticamente e por fim aplicação desse modelo a base de dados padrão-ouro.



6.4 Modelagem


        Para a atender ao objetivo de mineração de dados contido na Seção 6.1.4, primei-
ramente foi desenvolvido um modelo para classificação dos documentos em relação ao
tipo de recorrente. Após, foi desenvolvido um modelo para classificação quanto ao defe-
rimento ou indeferimento do dispositivo do acórdão. Em ambos os casos foram utilizadas
as respectivas bases de documentos anotadas manualmente conforme exposto na Seção
6.3.3. Além disso, para o segundo modelo, foi utilizada também base de documentos
                                                                                      83


Tabela 6.12: Apresenta lista com as Funções de Rotulação aplicadas à base de dados e
respectivos dados de cobertura, sobreposições e conflitos.
    Função de rotulação           Polaridade       Cobertura   Sobreposições   Conflitos
 lf_negar_provimento           INDEFERIMENTO        0,489410       0,090125    0,063192
 lf_rejeitar                   INDEFERIMENTO        0,072823       0,055173    0,033078
 lf_nao_acolher                INDEFERIMENTO        0,016691       0,000959    0,000567
 lf_manter_decisao             INDEFERIMENTO        0,007060       0,006755    0,002876
 lf_julgou_improcedente        INDEFERIMENTO        0,013902       0,011418    0,010198
 lf_dar_provimento              DEFERIMENTO         0,307548       0,073651    0,068160
 lf_dar_parcial_provimento      DEFERIMENTO         0,168483       0,037741    0,033819
 lf_proveu                      DEFERIMENTO         0,019873       0,018260    0,014512
 lf_parcialmente_proveu         DEFERIMENTO         0,001700       0,001700    0,001525
 lf_nulidade_sentenca        SEM_ANALISE_MERITO     0,007757       0,007104    0,006406
 lf_nao_conhecer             SEM_ANALISE_MERITO     0,047372       0,030114    0,029766
 lf_deixar_conhecer          SEM_ANALISE_MERITO     0,003486       0,002310    0,002048
 lf_prejudicada              SEM_ANALISE_MERITO     0,020047       0,017999    0,017214

Figura 6.6: Gráfico de histograma que apresenta as porcentagens dos rótulos aplicados
pela Funções de Rotulação.




anotada programaticamente conforme Seção 6.3.5.



6.4.1 Modelo: classificação do tipo de requerente como empregado ou empresa


       A fase de preparação e exploração dos dados das seções anteriores resultou em
uma lista contendo nomes de partes recorrentes a qual foi anotada manualmente com um
rótulo indicando se a parte é empregado ou empresa. Assim, nesta seção são realizados
experimentos para avaliar algoritmos de classificação de texto utilizando a base anotada
construída.
       A fase de avaliação técnica dos modelos desenvolvidos em relação aos níveis dos
resultados apresentados foi realizada por meio das bases de dados desenvolvidas na fase
84


Figura 6.7: Gráfico de histograma que apresenta as porcentagens dos rótulos finais apli-
cados pelo modelo desenvolvido.




de anotação manual. Assim, a base de dados foi dividida em 2 partes, 30% para testes
e 70% para treinamento dos modelos. Já essa parte de 70% dos dados foi utilizada para
treinamento utilizando técnica de Validação Cruzada em 7 camadas, conforme Figura
6.8. As bases de documentos do TRT da 3a e 4a Região foram utilizadas em conjunto para
treinamento e testes. Além disso, foram escolhidas as métricas acurácia, F1, revocação e
precisão para comparação dos resultados.
       O treinamento do modelo necessário para classificar o tipo de requerente sendo
empregado ou empresa foi desenvolvido a partir de experimentos realizados utilizando
os algoritmos de classificação da biblioteca Scikit Learn. Foram testados os seguintes
algoritmos: Rocchio classifier, Gradient Boosting Classifier, Naive Bayes Classifier, K-
nearest Neighbor, Support Vector Machine (SVM), Decision Tree, Random Forest.
       Não foram utilizados algoritmos de Redes Neurais em vista de que esses algorit-
mos necessitam de bases de dados contendo uma grande quantidade de instâncias e muita
diversidade de features, o que não seria o caso desta base de treinamento. Por outro lado,
de modo a garantir a diversidade de métodos de processamento, foram selecionados al-
goritmos que utilizam técnicas probabilísticas, técnicas de distância no espaço vetorial e
técnicas de ensemble de árvores de decisões.
       Desse modo, os experimentos foram realizados utilizando os dados de requeren-
tes anotados manualmente de ambos os tribunais de maneira conjunta, ou seja, a lista de
requerentes anotada de ambos os tribunais foi unida em uma estrutura de dados única e
preparada para o treinamento. Em relação à extração de features foi utilizada a classe
CountVectorizer da biblioteca Scikit Learn para realizar a transformação de todas as pa-
                                                                                      85


Figura 6.8: Ilustração do projeto de teste do classificador de tipo de requerente infor-
mando as quantidades específicas de instâncias da base de dados.




lavras para minúsculas e também o algoritmo padrão dessa classe para realização de to-
kenização o qual extrai todas as palavras com dois ou mais caracteres, além de tratar
caracteres de pontuação como separadores de palavras.
       Após, foi aplicada a classe TfidfTransformer a qual gera uma matriz contendo a
representação TF-IDF. Não houve a aplicação de nenhuma técnica de redução de dimen-
sionalidade específica, tampouco foi realizado tratamento de stop-words ou extração de
Lemma das palavras. Quanto aos algoritmos de classificação, foram utilizados os parâme-
tros padrão. Essa configuração mostrou-se satisfatória na fase de avaliação de resultados
e por isso foi mantida.
       Durante a fase de desenvolvimento, foi utilizada apenas a base reservada de 70%
dos dados para a realização de experimentos. Assim, foi utilizada técnica de Validação
Cruzada em 7 camadas, sendo calculada a média das sete execuções para avaliar a perfor-
mance dos algoritmos. Importante ressaltar que também foram utilizadas as matrizes de
confusão para verificação de desempenho.
       Após o desenvolvimento, foi utilizada a base de 30% para verificação final de
desempenho dos algoritmos. Assim, foi selecionado o algoritmo com melhor valor de
86


F1 para a construção do modelo final a ser utilizado na Seção 6.5 para realização de
processamento da base de documentos a fim de se atingir o objetivo de negócio e de
mineração de texto. Além disso, a construção desse modelo foi realizada utilizando a
totalidade da base de documentos anotada manualmente de modo a utilizar a integralidade
de instâncias e de features disponíveis.
             A avaliação técnica dos modelos desenvolvidos foi realizada conforme o projeto
de teste. Na Tabela 6.13 e na Figura 6.9 são apresentados os valores de acurácia, F1,
revocação e precisão, sendo possível observar que o algoritmo Support Vector Machine
(SVM) obteve o maior valor de F1 com 96,91%, seguido pelo algoritmo Naive Bayes com
95,48%. A Tabela 6.14 apresenta a lista de parâmetros escolhidos para o modelo treinado
com o algoritmo Support Vector Machine (SVM). A descrição completa dos parâmetros
pode ser encontrada no site oficial 6 .

Figura 6.9: Métricas calculadas utilizando a base de 30% reservada previamente para
testes do modelo de classificação do tipo de requerente.




6.4.2 Modelo: classificar a decisão em deferimento ou indeferimento


             A fase de preparação e exploração dos dados das seções anteriores resultou em
uma base de documentos contendo milhares de decisões judiciais. Assim, foi realizada a
anotação manual de 1.000 instâncias desses documentos para compor a base padrão-ouro.
Assim, nesta seção são realizados experimentos para avaliar algoritmos de classificação de
     6
         https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html
                                                                                 87




Tabela 6.13: Métricas calculadas utilizando a base de 30% reservada previamente para
testes do modelo de classificação do tipo de requerente.
            Classificador               Acurácia        F1   Precisão Revocação
  Rocchio                                 93,83% 94,95%       93,07%       96,91%
  Gradient Boosting                       87,65% 90,29%       85,32%       95,88%
  Naive Bayes                             94,44% 95,48%       93,14%       97,94%
  K-nearest Neighbor                      90,74% 92,15%       93,62%       90,72%
  Support Vector Machine (SVM)            96,30% 96,91% 96,91%             96,91%
  Decision Tree                           85,80% 87,43%       93,02%       82,47%
  Random Forest                           91,36% 93,07%       89,52%       96,91%




Tabela 6.14: Parâmetros e argumentos do modelo de aprendizado de máquina treinado
utilizando o algoritmo SVM LinearSVC da biblioteca Scikit Learning.
                              Parâmetro      Argumento
                          C                      1.0
                          class_weight          None
                          dual                  True
                          fit_intercept         True
                          intercept_scaling        1
                          loss              squared_hinge
                          max_iter              1000
                          multi_class            ovr
                          penalty                 l2
                          random_state          None
                          tol                      1
                          verbose                  0
88


texto utilizando a base anotada construída. Também foi construída base de documentos
anotada automaticamente para avaliação de técnica de Supervisão Fraca, de técnica de
balanceamento de classes e de algoritmos de classificação.


6.4.2.1 Experimento com base de dados criada manualmente padrão-ouro

       Inicialmente são realizados experimentos de modelagem de dados utilizando a
base padrão-ouro.     Assim é utilizada a base contendo 1.000 instâncias, sendo des-
tas 539 da classe INDEFERIMENTO, 441 da classe DEFERIMENTO e 20 da classe
SEM_ANALISE_MERITO. Desse modo, é possível observar que há grande desbalance-
amento das classes.
       A avaliação técnica dos modelos desenvolvidos em relação aos níveis dos resul-
tados apresentados foi realizada por meio da base de dados padrão-ouro desenvolvida
conforme exposto na Seção 6.3.3. Assim, a base de dados foi dividida em 2 partes, 30%
para testes e 70% para treinamento dos modelos. Já essa parte de 70% dos dados foi
utilizada para treinamento utilizando técnica de Validação Cruzada em 7 camadas, con-
forme Figura 6.10. As bases de documentos do TRT da 3a e 4a Região foram utilizadas
em conjunto para treinamento e testes. Além disso, foram escolhidas as métricas acu-
rácia, f1, revocação e precisão para comparação dos resultados, sendo que, para as três
últimas, foram calculas suas métricas macro e micro por tratar-se de uma tarefa com três
classes. Importante ressaltar que também foram utilizadas as matrizes de confusão para
verificação de desempenho.
       O treinamento dos modelos necessários para classificar o dispositivo da decisão foi
desenvolvido a partir de experimentos realizados utilizando os algoritmos de classificação
da biblioteca Scikit Learn. Foram testados os seguintes algoritmos: Rocchio classifier,
Gradient Boosting Classifier, Naive Bayes Classifier, K-nearest Neighbor, Support Vector
Machine (SVM), Decision Tree, Random Forest.
       Não foram utilizados algoritmos de Redes Neurais em vista de que esses algorit-
mos necessitam de bases de dados contendo uma grande quantidade de instâncias e muita
diversidade de features, o que não seria o caso desta base de treinamento. Por outro lado,
de modo a garantir a diversidade de métodos de processamento, foram selecionados al-
goritmos que utilizam técnicas probabilísticas, técnicas de distância no espaço vetorial e
técnicas de ensemble de árvores de decisões.
       Desse modo, os experimentos foram realizados utilizando os dados da base
padrão-ouro de ambos os tribunais de maneira conjunta, ou seja, a lista de decisões ano-
                                                                                       89


Figura 6.10: Ilustração do projeto de teste do classificador de tipo de requerente infor-
mando as quantidades específicas de instâncias da base de dados.




tada de ambos os tribunais foi unida em uma estrutura de dados única e preparada para o
treinamento. Em relação à extração de features foi utilizada a classe CountVectorizer da
biblioteca Scikit Learn para gerar a matriz de termos e documentos. Em conjunto a essa
classe, foi utilizada a biblioteca Spacy7 para processamento do lemma dos termos. Tam-
bém foi utilizado código Regex de tokenização personalizado para a língua portuguesa
que abrangesse palavras com traços, além da remoção de stop-words.
           Após, foi aplicada a classe TfidfTransformer a qual gera uma matriz contendo
a representação TF-IDF. Não houve a aplicação de nenhuma técnica de redução de di-
mensionalidade específica. Quanto aos algoritmos de classificação, foram utilizados os
parâmetros padrão. Essa configuração mostrou-se satisfatória na fase de avaliação de
resultados e por isso foi mantida.
           Durante a fase de desenvolvimento, foi utilizada apenas a base reservada de 70%
dos dados para a realização de experimentos. Assim, foi utilizada técnica de Validação
Cruzada em 7 camadas, sendo calculada a média das sete execuções para avaliar a perfor-
mance dos algoritmos. Importante ressaltar que também foram utilizadas as matrizes de
   7
       <https://spacy.io/>
90


Tabela 6.15: Modelos treinados com base padrão-ouro e métricas calculadas utilizando a
base de 30% reservada previamente para testes do modelo de classificação do deferimento
ou não da decisão.
                                            Precisão   Revocação              Precisão   Revocação
     Classificador    Acurácia   F1 macro                          F1 micro
                                             macro      macro                  micro       micro
      Rocchio          82,33%     61,68%     62,55%       77,23%    82,33%     82,33%       82,33%
 Gradient Boosting     98,33%     90,73%     85,96%      98,84%     98,33%     98,33%      98,33%
    Naive Bayes        78,67%     51,56%     55,91%       51,57%    78,67%     78,67%       78,67%
 K-nearest Neighbor    74,67%     48,33%     53,65%       48,66%    74,67%     74,67%       74,67%
       SVM             94,00%     62,97%     62,78%       63,19%    94,00%     94,00%       94,00%
   Decision Tree       95,00%     74,82%     74,96%       74,71%    95,00%     95,00%       95,00%
   Random Forest       94,67%     63,43%     63,08%       63,79%    94,67%     94,67%       94,67%


confusão para verificação de desempenho. Após o desenvolvimento, foi utilizada a base
de 30% para verificação final de desempenho dos algoritmos.
         Os modelos desenvolvidos foram avaliados conforme o projeto de teste. É possível
observar por meio da Tabela 6.15 e da Figura 6.11 que há grande discrepância entre os
valores macro e micro. Por outro lado, verificando as matrizes de confusão apresentadas
na Seção A.6, é visto que a maioria das instâncias da classe SEM_ANALISE_MERITO
não foram classificadas corretamente pelos algoritmos que tiveram as piores performances
em relação às métricas macro. Isso se deve ao fato do grande desbalanceamento dessa
classe, conforme Figura 6.3.

Figura 6.11: Modelos treinados com base padrão-ouro e métricas calculadas utilizando a
base de 30% reservada previamente para testes do modelo de classificação do deferimento
ou não da decisão.
                                                                                        91


6.4.2.2 Experimento com base de dados criada programaticamente balanceada

          Primeiramente é realizada a modelagem dos dados utilizando a base de dados
criada automaticamente balanceada. Nesse caso, a base contém 1.644 instâncias, sendo
destas 548 da classe INDEFERIMENTO, 548 da classe DEFERIMENTO e 548 da classe
SEM_ANALISE_MERITO, estando assim, as classes totalmente niveladas.
          A avaliação técnica dos modelos desenvolvidos em relação aos níveis dos resul-
tados apresentados foi realizada por meio da base de dados padrão-ouro desenvolvida
conforme exposto na Seção 6.3.3. Desse modo, houve o treinamento com a base de da-
dos balanceada criada programaticamente e realizado o teste cruzado com a base anotada
manualmente. Da mesma maneira, neste caso foram escolhidas as métricas acurácia, f1,
revocação e precisão para comparação dos resultados, sendo que, para as três últimas, fo-
ram calculadas suas métricas macro e micro por tratar-se de uma tarefa com três classes.
Importante ressaltar que também foram utilizadas as matrizes de confusão para verifica-
ção de desempenho.
          O treinamento dos modelos foi realizado utilizando os algoritmos de classificação
da biblioteca Scikit Learn. Foram testados os seguintes algoritmos: Rocchio classifier,
Gradient Boosting Classifier, Naive Bayes Classifier, K-nearest Neighbor, Support Vector
Machine (SVM), Decision Tree, Random Forest.
          Não foram utilizados algoritmos de Redes Neurais em vista de que esses algorit-
mos necessitam de bases de dados contendo uma grande quantidade de instâncias e muita
diversidade de features, o que não seria o caso desta base de treinamento. Por outro lado,
de modo a garantir a diversidade de métodos de processamento, foram selecionados al-
goritmos que utilizam técnicas probabilísticas, técnicas de distância no espaço vetorial e
técnicas de ensemble de árvores de decisões.
          Desse modo, os experimentos foram realizados utilizando a base de dados balan-
ceada criada programaticamente, conforme Seção 6.3.5, incluindo os dados de ambos os
tribunais de maneira conjunta, ou seja, a lista de decisões anotada de ambos os tribunais
foi unida em uma estrutura de dados única e preparada para o treinamento. Em relação à
extração de features foi utilizada a classe CountVectorizer da biblioteca Scikit Learn para
gerar a matriz de termos e documentos. Em conjunto a essa classe, foi utilizada a bibli-
                 8
oteca Spacy          para processamento do lemma dos termos. Também foi utilizado código
Regex de tokenização personalizado para a língua portuguesa que abrangesse palavras
com traços, além da remoção de stop-words. Após, foi aplicada a classe TfidfTransfor-
  8
      <https://spacy.io/>
92


Tabela 6.16: Modelos treinados utilizando base criada programaticamente balanceada
e métricas calculadas utilizando a base de dados padrão-ouro para testes do modelo de
classificação do deferimento ou não da decisão.
        Classificador           Acurácia   F1 macro    Precisão macro    Revocação macro    F1 micro   Precisão micro   Revocação micro
      Rocchio classifier           0,689      0,5658            0,6361             0,7606      0,689            0,689             0,689
 Gradient Boosting Classifier      0,946      0,8475            0,8049             0,9446      0,946            0,946             0,946
         Naive Bayes               0,748      0,6009            0,6401             0,7957      0,748            0,748             0,748
     K-nearest Neighbor            0,741      0,5826            0,5963             0,6705      0,741            0,741             0,741
Support Vector Machine (SVM)       0,942      0,8179             0,776             0,9271      0,942            0,942             0,942
        Decision Tree              0,944      0,8441            0,7977             0,9599      0,944            0,944             0,944
       Random Forest               0,956      0,8684            0,8201             0,9692      0,956            0,956             0,956




mer a qual gera uma matriz contendo a representação TF-IDF. Não houve a aplicação de
nenhuma técnica de redução de dimensionalidade específica. Quanto aos algoritmos de
classificação, foram utilizados os parâmetros padrão.
          Os modelos desenvolvidos foram avaliados conforme o projeto de teste. Desse
modo, os modelos foram treinados utilizando toda a base de dados criada programati-
camente balanceada e foram usados para classificar toda a base padrão-ouro. A Tabela
6.16 e a Figura 6.12 apresentam as métricas de avaliação. É possível verificar que a
performance máxima dos modelos em relação a métrica f1 macro foi inferior ao valor
reportado na Seção 6.4.2.1 tendo nenhum classificador alcançado valor maior que 90%.
Por outro lado, houve a concentração de algoritmos com média f1 macro entre 80% e
90%. Além disso, avaliando as matrizes de confusão presentes na Seção A.7 é possí-
vel verificar que todos os algoritmos tiveram classificações corretas em relação à classe
SEM_ANALISE_MERITO, diferente do que ocorreu no experimento da Seção 6.4.2.1,
o que pode ser considerado um efeito positivo da base de dados balanceada com número
maior de instâncias.


6.4.2.3 Experimento com base de dados criada programaticamente completa

          Neste experimento foi realizada a modelagem dos dados utilizando a base de da-
dos criada automaticamente completa. Assim, foi utilizada a base anotada automatica-
mente completa contendo 22.471 instâncias, sendo destas 12.000 da classe INDEFERI-
MENTO, 9.923 da classe DEFERIMENTO e 548 da classe SEM_ANALISE_MERITO.
Desse modo, é possível observar que também há grande desbalanceamento das classes.
          Os experimentos realizados para desenvolvimento do modelo para classificar o
dispositivo da decisão foram realizados utilizando os algoritmos de classificação da bibli-
oteca Scikit Learn. Foram testados os seguintes algoritmos: Rocchio classifier, Gradient
Boosting Classifier, Naive Bayes Classifier, K-nearest Neighbor, Support Vector Machine
(SVM), Decision Tree, Random Forest.
                                                                                        93


Figura 6.12: Modelos treinados utilizando base criada programaticamente balanceada e
métricas calculadas utilizando a base de dados padrão-ouro para testes do modelo de
classificação do deferimento ou não da decisão.




          Não foram utilizados algoritmos de Redes Neurais em vista de que esses algorit-
mos necessitam de bases de dados contendo uma grande quantidade de instâncias e muita
diversidade de features, o que não seria o caso desta base de treinamento. Por outro lado,
de modo a garantir a diversidade de métodos de processamento, foram selecionados al-
goritmos que utilizam técnicas probabilísticas, técnicas de distância no espaço vetorial e
técnicas de ensemble de árvores de decisões.
          Desse modo, os experimentos foram realizados utilizando a base de dados com-
pleta criada programaticamente, conforme Seção 6.3.5, incluindo os dados de ambos os
tribunais de maneira conjunta, ou seja, a lista de decisões anotada de ambos os tribunais
foi unida em uma estrutura de dados única e preparada para o treinamento. Em relação a
extração de features foi utilizada a classe CountVectorizer da biblioteca Scikit Learn para
gerar a matriz de termos e documentos. Em conjunto a essa classe, foi utilizada a bibli-
                 9
oteca Spacy          para processamento do lemma dos termos. Também foi utilizado código
Regex de tokenização personalizado para a língua portuguesa que abrangesse palavras
com traços, além da remoção de stop-words.
          Após, foi aplicada a classe TfidfTransformer a qual gera uma matriz contendo

  9
      <https://spacy.io/>
94


Tabela 6.17: Modelos treinados utilizando base criada programaticamente completa e
métricas calculadas utilizando a base de dados padrão-ouro para testes do modelo de
classificação do deferimento ou não da decisão.
        Classificador           Acurácia   F1 macro    Precisão macro    Revocação macro    F1 micro   Precisão micro   Revocação micro
      Rocchio classifier           0,721       0,584            0,6306             0,7813      0,721            0,721             0,721
 Gradient Boosting Classifier      0,954      0,9248            0,9053             0,9504      0,954            0,954             0,954
         Naive Bayes               0,846      0,5673            0,5721             0,5696      0,846            0,846             0,846
     K-nearest Neighbor            0,806      0,5648            0,7378              0,552      0,806            0,806             0,806
Support Vector Machine (SVM)       0,961      0,9157            0,9237             0,9083      0,961            0,961             0,961
        Decision Tree              0,951      0,9168            0,8936             0,9484      0,951            0,951             0,951
        Random Forest               0,96      0,9179            0,9137             0,9231       0,96             0,96              0,96




a representação TF-IDF. Não houve a aplicação de nenhuma técnica de redução de di-
mensionalidade específica. Quanto aos algoritmos de classificação, foram utilizados os
parâmetros padrão. Essa configuração mostrou-se satisfatória na fase de avaliação de
resultados e por isso foi mantida.
           Os modelos desenvolvidos foram avaliados conforme o projeto de teste. Desse
modo, os modelos foram treinados utilizando toda a base de dados criada programatica-
mente e foram usados para classificar toda a base padrão-ouro. A Tabela 6.17 e a Figura
6.13 apresentam as métricas de avaliação. É possível verificar que houve quatro modelos
que obtiveram performance máxima em relação a métrica f1 macro superiores aos valores
reportados na Seção 6.4.2.1 e na Seção 6.4.2.2.
           Além disso, avaliando as matrizes de confusão presentes na Seção 6.4.2.1 é pos-
sível verificar que alguns algoritmos não obtiveram classificações em relação à classe
SEM_ANALISE_MERITO o que resultou em métricas f1 macro em torno de 60%. En-
fim, o modelo que obteve a melhor média f1 macro, a saber, Gradient Boosting, foi se-
lecionado para realizar a classificação final de toda a base de documentos para análise
na Seção 6.5. A Tabela 6.18 apresenta a lista de parâmetros escolhidos para o modelo
treinado com o algoritmo Gradient Boosting. A descrição completa dos parâmetros pode
ser encontrada no site oficial 10 .



6.5 Avaliação de resultados


           O processo de mineração de dados textuais de decisões judiciais elaborado resul-
tou no desenvolvimento de dois modelos baseados em aprendizado de máquina super-
visionado e na sua utilização para o processamento de 22.946 decisões judiciais, sendo
12.071 do TRT da 4a Região e 10.875 do TRT da 3a Região. Com a utilização desses mo-
delos, os objetivos de mineração foram atingidos que eram classificar automaticamente

  10
       https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html
                                                                                       95


Figura 6.13: Modelos treinados utilizando base criada programaticamente completa e
métricas calculadas utilizando a base de dados padrão-ouro para testes do modelo de
classificação do deferimento ou não da decisão.




os acórdãos judiciais em relação ao deferimento ou não e classificar automaticamente o
requerente do recurso em relação a ser empresa ou a ser empregado. Cabe salientar que,
após a aplicação dos modelos de classificação, todas as instâncias que receberam o ró-
tulo SEM_ANALISE_MERITO foram removidas da análise, pois não interessavam aos
objetivos de negócio e de mineração de texto.
       Desse modo, foi possível atender também ao objetivo de negócio para verificar a
validade da hipótese por meio de teste estatístico se seria possível que os tribunais ava-
liados e suas turmas recursais julguem favoravelmente proporção maior de recursos para
uma das partes do que para outra. Assim, também são apresentadas a conclusão e a inter-
pretação dos testes estatísticos de proporção, força e efeito. Após, foram desenvolvidos
relatórios com gráficos para apresentar os resultados obtidos com o processamento dos
documentos.
96


Tabela 6.18: Parâmetros e argumentos do modelo de aprendizado de máquina treinado
utilizando o algoritmo Gradient Boosting da biblioteca Scikit Learning.
                               Parâmetro            Argumento
                       ccp_alpha                         0.0
                       criterion                   friedman_mse
                       init                             None
                       learning_rate                     0.1
                       loss                           deviance
                       max_depth                          3
                       max_features                     None
                       max_leaf_nodes                   None
                       min_impurity_decrease             0.0
                       min_samples_leaf                   1
                       min_samples_split                  2
                       min_weight_fraction_leaf          0.0
                       n_estimators                      100
                       n_iter_no_change                 None
                       random_state                      1.0
                       subsample                       0.0001
                       tol                               0.1
                       validation_fraction               0.1
                       verbose                            0
                       warm_start                       False



6.5.1 TRT da 4a Região - avaliação geral


       Na Figura 6.14 é possível observar a porcentagem da quantidade de recursos de-
feridos e indeferidos no TRT da 4a Região em relação ao recorrente ser empresa ou em-
pregado. Assim, é possível verificar que 50% dos recursos impetrados pelos empregados
foram deferidos ou parcialmente deferidos. Além disso, também é possível verificar que,
dos recursos impetrados pelas empresas, 39% foram julgados deferidos ou parcialmente
deferidos. Por outro lado, fica evidente a diferença de 12% na quantidade de recursos
deferidos ou parcialmente deferidos quando o recorrente são os empregados. Importante
frisar que essa média leva em consideração amostra dos acórdãos proferidos por todas as
Turmas Recursais do tribunal em conjunto.
       Nessa amostra foram processados 11.351 acórdãos, sendo 9.398 recursos da parte
empregado e 1.953 recursos da parte empresa. A parte empresa recorreu aproximada-
mente 4 vezes menos do que a parte empregado. Além disso, em relação aos testes esta-
tísticos aplicados, foi obtido P-value de 0%, ou seja, há grande confiança de que existe
diferença estatística entre a proporção de deferimentos para empregado e para empresa.
                                                                                                             97


Figura 6.14: Porcentagem de deferimento de recursos em relação ao recorrente ser em-
presa e empregado no Tribunal Regional do Trabalho da 4a Região.




Tabela 6.19: Porcentagem de deferimento de recursos em relação ao recorrente ser em-
presa e empregado das Turmas Recursais do Tribunal Regional do Trabalho da 4a Região.
             TURMA        TOTAL DE                 PVALUE                   POWER                    EFFECT
TRIBUNAL                             PVALUE                      POWER                  EFFECT
            RECURSAL     PROCESSOS                 INTERP.                  INTERP.                  INTERP.
   TRT4       1a Turma      1.639    0,7172   NÃO HÁ DIFERENÇA   0,0863   INACEITÁVEL   0,0217   INSIGNIFICANTE
   TRT4       2a Turma      1.704       0       HÁ DIFERENÇA        1      ACEITÁVEL    0,5267        MÉDIA
   TRT4       3a Turma      1.832       0       HÁ DIFERENÇA        1      ACEITÁVEL    0,4853      PEQUENA
   TRT4       4a Turma      1.800    0,0343     HÁ DIFERENÇA     0,9575    ACEITÁVEL    0,1343   INSIGNIFICANTE
   TRT4       5a Turma      1.504    0,0003     HÁ DIFERENÇA     0,9999    ACEITÁVEL    0,2355      PEQUENA
   TRT4       6a Turma      1.171    0,1741   NÃO HÁ DIFERENÇA    0,638   INACEITÁVEL   0,1051   INSIGNIFICANTE
   TRT4       7a Turma       825     0,1687   NÃO HÁ DIFERENÇA   0,6817   INACEITÁVEL   0,1307   INSIGNIFICANTE
   TRT4       8a Turma       448     0,0032     HÁ DIFERENÇA     0,9988    ACEITÁVEL     0,366      PEQUENA
   TRT4       9a Turma       131     0,1106   NÃO HÁ DIFERENÇA   0,8029    ACEITÁVEL    0,3813      PEQUENA
   TRT4      10a Turma       115     0,0752   NÃO HÁ DIFERENÇA   0,7266   INACEITÁVEL   0,3892      PEQUENA
   TRT4      11a Turma       182     0,3001   NÃO HÁ DIFERENÇA   0,4141   INACEITÁVEL   0,2038      PEQUENA




Em relação ao nível de efeito estatístico em função da tabela Cohen’s, foi obtido o índice
de 22,11%, ou seja, o nível de efeito estatístico da diferença de proporções é pequeno.
Quanto à força do teste estatístico, foi obtido o 100%, ou seja, foi alcançado nível aceitá-
vel de força estatística e há risco baixo de não haver diferença entre as proporções.



6.5.2 TRT da 4a Região - avaliação das Turmas Recursais


          Em relação a dados individuais de cada uma das Turmas Recursais do TRT da 4a
Região, Figura 6.15, é possível verificar que as Turmas Recursais 2a , 3a , 5a , 8a , 9a e 11a
apresentaram proporção parecida com a do tribunal para empregados. Por outro lado, a
Figura 6.16 apresenta a distribuição das proporções de deferimentos das turmas recursais.
Além disso, na Tabela 6.19 são apresentados os dados em relação aos testes estatísticos
aplicados, como o P-Value, Power e Effect. Assim, é possível verificar que há diversas
turmas recursais que o Power está abaixo de 0,8, o que ocorre devido à pouca quantidade
de dados para análise, entretanto é possível superar essa limitação pela ingestão de mais
observações em trabalhos futuros.
98


Figura 6.15: Porcentagem de deferimento de recursos em relação ao recorrente ser em-
presa e empregado das Turmas Recursais do Tribunal Regional do Trabalho da 4a Região.




6.5.3 TRT da 3a Região - avaliação geral


       Na Figura 6.17 é possível observar a porcentagem da quantidade de recursos defe-
ridos e indeferidos no TRT da 3a Região em relação ao recorrente ser empresa ou empre-
gado. Assim, é possível verificar que 41,31% dos recursos impetrados pelos empregados
foram deferidos ou parcialmente deferidos. Além disso, também é possível verificar que,
dos recursos impetrados pelas empresas, 39,07% foram julgados deferidos ou parcial-
mente deferidos. Fica evidente a diferença de 2,24% na quantidade de recursos deferidos
ou parcialmente deferidos quando o recorrente são os empregados. Importante frisar que
essa média leva em consideração amostra dos acórdãos proferidos por todas as Turmas
Recursais do tribunal em conjunto.
       Nessa amostra foram processados 10.477 acórdãos, sendo 7.349 recursos da parte
                                                                                        99


Figura 6.16: Distribuição da porcentagem de deferimento de recursos em relação ao recor-
rente ser empresa e empregado das Turmas Recursais do Tribunal Regional do Trabalho
da 4a Região.




Figura 6.17: Porcentagem de deferimento de recursos em relação ao recorrente ser em-
presa e empregado no Tribunal Regional do Trabalho da 3a Região.




empregado e 3.128 recursos da parte empresa. Nessa amostra a parte empresa recorreu
aproximadamente 2 vezes menos do que a parte empregado. Além disso, em relação aos
testes estatísticos aplicados, foi obtido P-value de 3,19%, ou seja, há grande confiança
de que existe diferença estatística entre a proporção de deferimentos para empregado e
para empresa. Em relação ao nível de efeito estatístico em função da tabela Cohen’s, foi
obtido o índice de 4,58%, ou seja, o nível de efeito estatístico da diferença de proporções
é insignificante. Quanto à força do teste estatístico, foi obtido o 79,28%, ou seja, foi
alcançado nível abaixo do aceitável de força estatística e há risco de não haver diferença
100


Tabela 6.20: Porcentagem de deferimento de recursos em relação ao recorrente ser em-
presa e empregado das Turmas Recursais do Tribunal Regional do Trabalho da 3a Região.
            TURMA        TOTAL DE                 PVALUE                     POWER                     EFFECT
TRIBUNAL                            PVALUE                      POWER                    EFFECT
           RECURSAL     PROCESSOS             INTERPRETACAO              INTERPRETAÇÃO            INTERPRETACAO
  TRT3       1a Turma      1058        0       HÁ DIFERENÇA        1        ACEITÁVEL    0,3749       PEQUENA
  TRT3       2a Turma       906     0,4009   NÃO HÁ DIFERENÇA   0,1789     INACEITÁVEL   0,0591    INSIGNIFICANTE
  TRT3       3a Turma       938     0,1047   NÃO HÁ DIFERENÇA   0,5978     INACEITÁVEL   0,1193    INSIGNIFICANTE
  TRT3       4a Turma       931     0,0014     HÁ DIFERENÇA     0,9803      ACEITÁVEL    0,2245       PEQUENA
  TRT3       5a Turma       889     0,3495   NÃO HÁ DIFERENÇA   0,2372     INACEITÁVEL   0,0692    INSIGNIFICANTE
  TRT3       6a Turma       973     0,0116     HÁ DIFERENÇA     0,9142      ACEITÁVEL    0,1788    INSIGNIFICANTE
  TRT3       7a Turma      1025        0       HÁ DIFERENÇA        1        ACEITÁVEL    0,4839       PEQUENA
  TRT3       8a Turma       850     0,0762   NÃO HÁ DIFERENÇA   0,6205     INACEITÁVEL   0,1321    INSIGNIFICANTE
  TRT3       9a Turma      1016        0       HÁ DIFERENÇA        1        ACEITÁVEL    0,5803         MÉDIA
  TRT3      10a Turma       957     0,0394     HÁ DIFERENÇA      0,747     INACEITÁVEL   0,1443    INSIGNIFICANTE
  TRT3      11a Turma       934        0       HÁ DIFERENÇA        1        ACEITÁVEL    0,3518       PEQUENA




entre as proporções. A saber, o nível de força estatística considerado aceitável é de 80%.



6.5.4 TRT da 3a Região - avaliação das Turmas Recursais


         Em relação a dados individuais de cada uma das Turmas Recursais do TRT da
3a Região, Figura 6.18, é possível verificar que as Turmas Recursais 1a , 4a , 7a , 8a e 11a
apresentaram proporção de deferimentos maior para empregados. Por outro lado, 6 das
11 Turmas Recursais apresentaram proporção de deferimentos maior para empresas. A
Figura 6.19 apresenta a distribuição das proporções de deferimentos das turmas recursais.
Além disso, na Tabela 6.20 são apresentados os dados em relação aos testes estatísticos
aplicados, como o P-Value, Power e Effect. Assim, é possível verificar que há diversas
turmas recursais que o Power está abaixo de 0,8, o que ocorre devido à pouca quantidade
de dados para análise, entretanto é possível superar essa limitação pela ingestão de mais
observações em trabalhos futuros.



6.6 Aplicação


         A presente pesquisa não necessita da realização de deployment dos modelos de-
senvolvidos em nenhuma infraestrutura de processamento de dados para serem utilizados.
Entretanto, é importante ressaltar algumas considerações em relação a futuras utilizações
dos modelos desenvolvidos. Assim, ambos os modelos desenvolvidos assumem que os
documentos estejam redigidos em língua portuguesa formal, ou seja, sem erros comuns
de digitação. Além disso, seria interessante o monitoramento dos textos das decisões de
modo à manutenção da qualidade das previsões, pois os níveis de acurácia dos modelos
desenvolvidos dependem necessariamente de que os dados ingeridos estejam em níveis
                                                                                    101


Figura 6.18: Porcentagem de deferimento de recursos em relação ao recorrente ser em-
presa e empregado das Turmas Recursais do Tribunal Regional do Trabalho da 3a Região.




de qualidade previstos.



6.7 Limitações


       Os experimentos da presente pesquisam apresentaram certas limitações, como por
exemplo, a utilização do formato de redação dos documentos processados. Assim, o
algoritmo de aprendizado de máquina desenvolvido levou em consideração padrões de
formatação e redação específicos ao corpus jurídico dos Tribunais avaliados. Além disso,
não é possível afirmar com certeza que outros tribunais sigam os mesmos padrões, pois
não foi realizado experimento de análise de documentos dos demais tribunais brasileiros.
Entretanto, essas informações contextuais dos documentos podem ser consideradas úteis
102


Figura 6.19: Distribuição da porcentagem de deferimento de recursos em relação ao recor-
rente ser empresa e empregado das Turmas Recursais do Tribunal Regional do Trabalho
da 3a Região.




para os algoritmos, pois elas mimicam a forma como os usuários, advogados e praticantes
da atividade jurídica, leem os documentos.
       Entretanto, não era objetivo da pesquisa, em um primeiro momento, o desenvolvi-
mento de um algoritmo que processasse documentos de diversos formatos de redação de
diversos tribunais diferentes. Desse modo, a padronização de redação dos documentos foi
explorada a fim de se alcançar maior otimização do algoritmo. Por outro lado, mesmo em
áreas devidamente estabelecidas, como a mineração de sentimentos, é possível encontrar
algoritmos desenvolvidos especificamente para certos nichos, como é o caso dos micro-
blogs, como o Twitter, que implicam desafios particulares devido a especificidades dos
documentos encontrados (LIPPI; TORRONI, 2016).
       Além disso, foi realizado o processamento de acórdãos judiciais em que houve
apenas uma das partes recorrente. Desse modo, todos os documentos em que havia a
apreciação de mais de um recurso foram removidos da base de dados. Entretanto, foi
considerado que tal filtragem não apresentou prejuízos aos experimentos, visto que havia
grande quantidade de documentos disponíveis para análise de acordo com técnicas de
definição de amostra estatística, conforme Seção 6.2.1.2.
       Outro fator que pode ser considerado uma limitação da pesquisa é o tamanho da
                                                                                       103


base de dados padrão-ouro desenvolvido na Seção 6.3.3. Entretanto, essa questão foi
mitiga por meio da aplicação de técnica de Supervisão Fraca a qual permitiu explorar a
grande quantidade de documentos disponíveis para o treinamento dos modelos desenvol-
vidos na pesquisa, conforme Seção 6.3.5. Cabe salientar também as limitações impostas
pelas próprias técnicas de Aprendizado de Máquinas utilizadas na pesquisa, como, por
exemplo, o viés ou a tendência inserida pelo algoritmo, que, para desenvolver um mo-
delo, precisa realizar suposições e generalizações.



6.8 Resumo do Capítulo


       Neste capítulo é apresentada a validação experimental completa da pesquisa de
acordo com as metodologias propostas. Assim, iniciou-se pela elucidação dos elementos
fundamentais do estudo que nortearam todas as fases seguintes por meio da Seção Com-
preensão do negócio. Nessa seção foram definidos os objetivos principais da validação
experimental no contexto de negócio e de mineração de dados.
       Após, na Seção Compreensão dos dados, iniciou-se a execução prática da pesquisa
por meio da coleta dos dados da internet e da exploração inicial dos documentos obti-
dos. Essa fase trouxe resultados positivos para a pesquisa pois permitiu aferir a qualidade
dos dados como também permitiu analisar o conteúdo dos documentos. Essa análise do
conteúdo proporcionou inspiração positiva para o desenvolvimento de uma técnica para
reduzir o tamanho dos documentos, a qual foi implementada na fase seguinte da pesquisa.
       Já na fase da Seção Preparação dos dados houve a impressão de grande esforço
para a preparação da melhor maneira possível de toda base de documentos para ser utili-
zada na fase de modelagem de dados. Assim, primeiramente foi realizada a devida lim-
peza de caracteres e documentos que não atingiam a qualidade mínima para a pesquisa.
Após, foram aplicadas as transformações nos documentos idealizadas na fase anterior da
pesquisa. Assim, foram extraídos apenas os dispositivos das decisões judiciais. É nos
dispositivos do documento que contém as features necessárias para que os algoritmos de
modelagem possam classificar corretamente as instâncias.
       Ainda na fase de preparação dos dados, na Seção 6.3.3, houve a criação da base de
documentos padrão-ouro, a qual foi desenvolvida não apenas com esforço do autor, como
também de duas pessoas bacharéis em Direito. Dessa maneira, a base foi utilizada para a
realização de testes dos modelos de Aprendizado de Máquina Supervisionado desenvol-
vidos, como também para análise exploratório dos documentos, mas neste caso, fazendo
104


a análise cruzada com os rótulos das instâncias. Essa análise permitiu-se inferir featu-
res que viabilizaram a criação de Funções de Rotulação utilizando o Snorkel Framework
para aplicação de técnica de Supervisão Fraca, para criar uma base de documentos para
treinamento muito maior do que a base padrão-ouro.
       Na sequência, a Seção Modelagem apresenta a execução de quatro experimentos
de modelagem de dados por meio de algoritmos de Aprendizado de Máquina Supervisio-
nado. Assim, primeiramente foram avaliados diversos algoritmos para o desenvolvimento
de um modelo para realizar a classificação dos documentos em relação ao tipo de parte
requerente no processo, sendo ela empregado ou empresa. Nesse caso, o algoritmo que
apresentou a melhor performance e foi escolhido foi o Support Vector Machine (SVM).
Em relação aos outros três experimentos realizados nessa seção, em ambos foram avalia-
dos diversos algoritmos para o desenvolvimento de um modelo para realizar a classifica-
ção dos documentos em relação ao deferimento ou não do recurso impetrado. Entretanto,
o que diferencia é a base de documentos utilizada. Desse modo, no segundo experimento
os algoritmos foram treinados utilizando a base de dados padrão-ouro a qual continha
1.000 instâncias para treinamento, mas as suas classes estavam muito desbalanceadas.
No terceiro experimento foi avaliado o treinamento dos mesmos algoritmos utilizando a
base de documentos criada automaticamente contendo 1.644 instâncias, mas nesse caso
totalmente balanceada. Por último, foi realizado experimento de treinamento utilizando
a base de documentos criada automaticamente contendo a totalidade das instâncias ano-
tadas de 22.471, mas nesse caso muito desbalanceada para uma das classes. Enfim, foi
realizada a avaliação técnica dos modelos desenvolvidos e selecionado o modelo criado
com o algoritmo Gradient Boosting para a classificação efetiva dos documentos.
       Por fim, na Seção Avaliação de resultados, foi realizada a classificação de 22.946
documentos com os modelos desenvolvidos, foram aplicados os testes estatísticos de
acordo com a metodologia escolhida e por fim foram gerados diversos gráficos demons-
trando as proporções de julgamentos encontrados na amostra selecionada. Enfim, foi
possível identificar diferença estatística em ambos os tribunais com proporção maior de
julgamentos para empregados, por outro lado, também foi observado que há turmas recur-
sais que divergem da média geral de cada tribunal apresentando, assim, proporção maior
de julgamentos para empresas. Também é possível verificar na Seção 6.7 o conjunto de
limitações encontradas para a presente pesquisa de maneira detalhada.
                                                                                       105


7 DISCUSSÃO DE RESULTADOS


       A presente pesquisa desenvolveu processo de Ciência de Dados para a classifica-
ção automática de decisões judiciais em relação ao beneficiário do julgamento ser em-
pregado ou empresa de modo a quantificar a proporção de julgamentos favorável a cada
parte. Assim, foi possível responder a questão de pesquisa: Seria possível que os tri-
bunais avaliados e suas turmas recursais julguem favoravelmente proporção signifi-
cativamente maior de recursos para uma das partes do que para outra em média?
Enfim, foi possível verificar diferença de proporção estatística significante em relação ao
Tribunal Regional do Trabalho da 3 e 4a Região. Cabe ressaltar que a diferença de pro-
porção encontrada nos dados do TRT da 4a Região foi de 12% a mais para empregados e,
nos dados do TRT da 3a Região, a diferença foi de 2% a mais para empregados.
       Por outro lado, os dados sugerem haver também diferenças estatísticas de propor-
ção se forem analisadas individualmente as Turmas Recursais que compõem cada tribu-
nal. Em relação ao TRT da 4a Região, é possível verificar que 6 das 11 Turmas Recursais
acompanham a média geral do tribunal tendo maior proporção de julgados favoráveis a
empregados, sendo que a 2a , 3a e 8a Turmas Recursais apresentam mais de 2 desvios pa-
drão de diferença. Por outro lado, em relação ao TRT da 3a Região, também é possível
verificar diferenças estatísticas de proporção. Entretanto, neste caso, menos da metade
das Turmas Recursais acompanharam a média geral do tribunal. Assim, 5 das 11 Turmas
Recursais apresentaram proporção de deferimentos maior para empregados, tendo 3 delas
diferença maior que 2 desvios-padrão. Em contrapartida, 6 das 11 Turmas Recursais apre-
sentaram proporção de deferimentos maior para empresas, tendo apenas 1 delas diferença
maior que 3 desvios-padrão.
       Enfim, as médias gerais dos tribunais analisados e também as médias especificas
de diversas Turmas Recursais contribuíram para suportar a hipótese levantada de que há
órgãos judiciais que julgam proporção consideravelmente maior para uma das partes do
que para outra. Desse modo, a quantidade de dados extraídos em relação aos tribunais
como um todo se mostrou satisfatória para alcançar o nível de força desejado de 80%.
Entretanto, em relação às Turmas Recursais individualmente, menos da metade das aná-
lises obtiveram nível de força abaixo de 80%, como é possível ser observado pela Tabela
6.19 e 6.20, constando, assim, como uma limitação da presente pesquisa.
       Além da análise quantitativa das decisões judiciais processadas automaticamente,
também foi realizado experimento para avaliar a efetividade de técnica de Supervisão
106


Fraca de modo a aumentar a quantidade de documentos anotados utilizados no treina-
mento dos modelos de Aprendizado de Máquina. Assim, a técnica se mostrou satisfató-
ria, pois permitiu a anotação automática de mais de 22 mil documentos, ou seja, aumen-
tando a base de treinamento em mais de 22 vezes. O presente resultado foi alcançado
considerando que os magistrados empregam no dia-a-dia estilo de escrita padronizado e
preferencialmente as mesmas palavras-chave em certos trechos dos documentos, ou, até
mesmo, reutilizam modelos de documentos alterando apenas nomes de pessoas sendo pro-
cessadas por exemplo. Por um lado, essa característica específica da base de documentos
processada pode ser considerada positiva, pois permitiu a construção rápida de funções
de rotulação as quais possibilitaram a anotação automática da base de documentos para
treinamento. Entretanto, por outro lado, essa característica de padronização dos docu-
mentos pode imprimir desafios, pois muitas das instâncias anotadas automaticamente não
apresentam grande variação de features o que pode impactar determinados algoritmos.
                                                                                     107


8 CONCLUSÕES


       Esta pesquisa teve por objetivo principal utilizar métodos computacionais automá-
ticos para responder a questão de pesquisa se Seria possível que os tribunais avaliados e
suas turmas recursais julguem favoravelmente proporção significativamente maior
de recursos para uma das partes do que para outra em média? Assim, foi executada
pesquisa de descoberta de conhecimento em base de dados de acordo com a metodologia
Crisp-dm (CHAPMAN et al., 2000) que incluiu o processamento por meio de Algoritmo
de Aprendizado de Máquina e PLN de mais de 20 mil decisões judiciais de modo a re-
alizar estudo quantitativo e estatístico da base de decisões. Os resultados indicaram que
realmente há tribunais e turmas recursais que apresentam diferença significante de pro-
porção de julgamentos favorável para empregados e empresas e vice-versa.
       Além disso, também foram atingidos os objetivos específicos que constituíam na
análise exploratória dos documentos coletadas na Web, o que resultou em conhecimento
sobre a frequência das palavras utilizadas pelos magistrados, como também no conheci-
mento sobre a padronização dos documentos. Igualmente foi desenvolvida base padrão-
ouro para treinamento de algoritmos de Aprendizado de Máquina o que pode ser consi-
derado um dos produtos da pesquisa.
       Por outro lado, foi realizada também a experimentação da utilização de técnica de
Supervisão Fraca para o desenvolvimento de base de treinamento criada automaticamente
por meio da expansão dos dados, a qual apresentou resultados satisfatórios. Além disso,
como trabalho futuro poderia ser considerada a elaboração de funções de rotulação que
sejam mais flexíveis as palavras-chave utilizadas para classificar os documentos. Nesse
caso, poderiam ser utilizadas Embeddings de modo a localizar expressões semelhantes
às utilizadas na presente pesquisa para classificar documentos. Entretanto, considera-se
satisfatório o experimento pois preencheu uma lacuna dos trabalhos relacionados pois
não havia sido encontrado nenhum experimento utilizando técnica de Supervisão Fraca
aplicada a documentos jurídicos até o momento.
       De modo a permitir uma análise mais aprofundada e confiável dos resultados,
propõe-se como sugestão que estudos futuros obtenham mais dados na fase de extração
da amostra de documentos para considerar também a proporção de julgamento em relação
a cada turma recursal, como também cada magistrado na função de relator. Essa conside-
ração poderia permitir análises segmentadas por magistrado na função de relator de modo
a viabilizar a análise da seguinte hipótese: Relatores diferentes (dentro de uma mesma
108


turma recursal) influenciam a proporção de julgamentos favoráveis a cada uma das
partes, ou seja, há correlação entre o relator e a proporção de julgamentos de uma
turma recursal.
           Enfim, a presente pesquisa buscou trazer novos dados a discussões presentes na
sociedade sobre a questão do viés na Justiça, principalmente, na Justiça do Trabalho.
Assim, considerando que a pesquisa de Salama, Carlotti e Yeung (2018) encontrou resul-
tados que sugerem que, a nível de primeiro grau de jurisdição na Justiça do Trabalho, há
uma proporção muito maior de julgamentos favoráveis a empregados, os dados da pre-
sente pesquisa sugerem a confirmação dessa proporção a nível de segundo grau, apesar de
haver algumas turmas recursais que realizam a correção dessa distorção. A fim de facilitar
a reprodução da pesquisa, foi disponibilizado online na plataforma Github o código-fonte
do projeto1 .
