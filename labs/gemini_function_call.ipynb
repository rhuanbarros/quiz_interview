{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()  # take environment variables from .env."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/quiz_interview/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "from google.ai.generativelanguage_v1beta.types import content\n",
    "\n",
    "key_gemini = os.environ[\"GOOGLE_API_KEY\"]\n",
    "\n",
    "genai.configure(api_key=key_gemini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That's wonderful!  What breeds are they?  Are they both pups, or do you have one of each?  Do they have any special tricks or personalities?  I'd love to hear more about them! 🐶 \n",
      "\n",
      "Since you have two dogs, and each dog has four paws, there are a total of **eight** paws in your house! 🐾 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "chat = model.start_chat(\n",
    "    history=[\n",
    "        {\"role\": \"user\", \"parts\": \"Hello\"},\n",
    "        {\"role\": \"model\", \"parts\": \"Great to meet you. What would you like to know?\"},\n",
    "    ]\n",
    ")\n",
    "response = chat.send_message(\"I have 2 dogs in my house.\")\n",
    "print(response.text)\n",
    "response = chat.send_message(\"How many paws are in my house?\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retriever(query: str) -> list[dict[str, str]]:\n",
    "    \"\"\" Search system that retrieves documents from a knowldgebase based in the text in the parameter 'query'.\"\"\"\n",
    "    return [\n",
    "        {\n",
    "            \"id\": \"doc1\",\n",
    "            \"content\": \"O acesso ao PJE é feito por meio do site do PJe ou do aplicativo PJe portable.\"\n",
    "        },\n",
    "        {\n",
    "            \"id\": \"doc2\",\n",
    "            \"content\": \"O acesso ao PJE é feito por meio do site do PJe ou do aplicativo PJe portable.\"\n",
    "        }\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions_dict = {\n",
    "    \"retriever\": retriever\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = (\n",
    "    \"You are a helpful bot create to help user from the IT section called Setic in their daily activities\\n\"\n",
    "    \"You should help answer the user questions.\\n\"\n",
    "    \"you could use the functions provided to gather documents from other systems to aggregate relevant context.\\n\"\n",
    "    \"If the context provided by the functions is not relevant and you dont know the answer, just state this to the user and ask for clarification.\\n\"\n",
    "    \"Answer in the same user language.\\n\"\n",
    "    # \"In the beginning of the conversation you will not have any con\"\n",
    "    \"If there isn't any context from a function called in the conversation yet, you should try to to use one of the functions to get some updated context.\\n\"\n",
    "    )\n",
    "\n",
    "model = genai.GenerativeModel(model_name='gemini-1.5-flash',\n",
    "                              tools=[retriever],\n",
    "                              system_instruction=instruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.generativeai.types import content_types\n",
    "from collections.abc import Iterable\n",
    "\n",
    "\n",
    "def tool_config_from_mode(mode: str, fns: Iterable[str] = ()):\n",
    "    \"\"\"Create a tool config with the specified function calling mode.\"\"\"\n",
    "    return content_types.to_tool_config(\n",
    "        {\"function_calling_config\": {\"mode\": mode, \"allowed_function_names\": fns}}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = model.start_chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text: \"Para te ajudar a acessar o PJe, preciso entender melhor o que você precisa. Você pode me dizer qual tipo de acesso você precisa? Por exemplo: \\n\\n* Você precisa acessar o PJe como advogado? \\n* Você precisa acessar o PJe como parte? \\n* Você precisa acessar o PJe como servidor público?\\n\\nCom mais informações, posso te ajudar a encontrar a resposta que você precisa. \\n\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tool_config = tool_config_from_mode(\"auto\")\n",
    "\n",
    "response = chat.send_message(\"como faço para acessar o PJe?\", tool_config=tool_config)\n",
    "print(response.parts[0])\n",
    "# chat.rewind();  # You are not actually calling the function, so remove this from the history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "response:\n",
       "GenerateContentResponse(\n",
       "    done=True,\n",
       "    iterator=None,\n",
       "    result=protos.GenerateContentResponse({\n",
       "      \"candidates\": [\n",
       "        {\n",
       "          \"content\": {\n",
       "            \"parts\": [\n",
       "              {\n",
       "                \"function_call\": {\n",
       "                  \"name\": \"retriever\",\n",
       "                  \"args\": {\n",
       "                    \"query\": \"acessar PJe\"\n",
       "                  }\n",
       "                }\n",
       "              }\n",
       "            ],\n",
       "            \"role\": \"model\"\n",
       "          },\n",
       "          \"finish_reason\": \"STOP\",\n",
       "          \"index\": 0,\n",
       "          \"safety_ratings\": [\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            }\n",
       "          ]\n",
       "        }\n",
       "      ],\n",
       "      \"usage_metadata\": {\n",
       "        \"prompt_token_count\": 256,\n",
       "        \"candidates_token_count\": 18,\n",
       "        \"total_token_count\": 274\n",
       "      }\n",
       "    }),\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retriever(query=acessar PJe)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'id': 'doc1',\n",
       "  'content': 'O acesso ao PJE é feito por meio do site do PJe ou do aplicativo PJe portable.'},\n",
       " {'id': 'doc2',\n",
       "  'content': 'O acesso ao PJE é feito por meio do site do PJe ou do aplicativo PJe portable.'}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for part in response.parts:\n",
    "    if fn := part.function_call:\n",
    "        args = \", \".join(f\"{key}={val}\" for key, val in fn.args.items())\n",
    "        print(f\"{fn.name}({args})\")\n",
    "        response = functions_dict[fn.name](**fn.args)\n",
    "\n",
    "response     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = {\n",
    "    \"retriever\": response\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Para acessar o PJe, você pode usar o site do PJe ou o aplicativo PJe portable. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Build the response parts.\n",
    "response_parts = [\n",
    "    genai.protos.Part(function_response=genai.protos.FunctionResponse(\n",
    "        name=fn, response={\"result\": val}))\n",
    "    for fn, val in responses.items()\n",
    "]\n",
    "\n",
    "response = chat.send_message(response_parts)\n",
    "print(response.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
