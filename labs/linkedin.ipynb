{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()  # take environment variables from .env."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/quiz_interview/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "from google.ai.generativelanguage_v1beta.types import content\n",
    "\n",
    "key_gemini = os.environ[\"GOOGLE_API_KEY\"]\n",
    "\n",
    "genai.configure(api_key=key_gemini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "generation_config = {\n",
    "    \"temperature\": 0.75,\n",
    "    \"top_p\": 0.95,\n",
    "    # \"top_k\": 64,\n",
    "    # \"max_output_tokens\": 8192,\n",
    "    \"response_mime_type\": \"text/plain\",\n",
    "    # \"response_schema\": schema,\n",
    "    # \"response_mime_type\": \"application/json\",\n",
    "}\n",
    "    \n",
    "\n",
    "llm_gemini = genai.GenerativeModel(\n",
    "    # model_name=\"gemini-1.5-flash\",\n",
    "    # model_name=\"gemini-1.5-flash-exp-0827\",\n",
    "    model_name=\"gemini-1.5-pro-002\",\n",
    "    generation_config=generation_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_cheatsheet = (\n",
    "    \"TEXT:\\n\\n\"\n",
    "    \"{TEXT}\"\n",
    "    \"given the text of my work in my mastes degree above create a list of the experiences I have.\"\n",
    "    \"use the folloing titles to guide the creatio and to group the experience\"\n",
    "    \"business analisys, data scraping, data preparation (etl), machine learning modeling, statiscal analisys, dashboards presentation\"\n",
    "    \"write everything in english\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: /workspaces/quiz_interview/labs\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Get the current working directory\n",
    "current_dir = os.getcwd()\n",
    "print(\"Current directory:\", current_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('master_tesis.txt', 'r') as file:\n",
    "    txt = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4 METODOLOGIA\\n\\n\\n          A presente pesquisa adotou a metodologia CRISP-DM Guide 1.0 (CHAPMAN\\net al., 2000) para validação experimental, assim, considerou-se interessante apresentar\\na seguir os pontos-chave dessa metodologia. Além disso, devido à utilização de testes\\nestatísticos em alguns experimentos, também se considerou interessante apresentar os\\npontos-chave da metodologia adotada apresentada no trabalho de Snijders (2002).\\n\\n\\n\\n4.1 Processo de descoberta de conhecimento em base de dados\\n\\n\\n          Este trabalho segue a abordagem metodológica descrita em CRISP-DM Guide 1.0\\n(CHAPMAN et al., 2000) para a descoberta de conhecimento em base de dados que é\\nutilizada para extrair conhecimento útil de grandes coleções de dados. Essa metodologia\\napresenta um processo iterativo composto de diversas fases, que compõe desde a compre-\\nensão e as necessidades de negócio até a modelagem dos dados e sua aplicação, as quais\\nsão descritas em mais detalhes nas seções seguintes. A Figura 4.1 apresenta o ciclo do\\nprocesso.\\n\\n\\n\\nFigura 4.1: Ciclo de desenvolvimento do processo metodológico CRISP-DM Guide 1.0.\\n\\n\\n\\n\\nAdaptado de Chapman et al. (2000)\\n\\x0c46\\n\\n\\n4.1.1 Compreensão do Negócio\\n\\n\\n        Essa fase consiste em compreender o valor do conhecimento a ser gerado pela\\nperspectiva do negócio, de modo a alinhar o projeto com os objetivos estratégicos da\\norganização. Assim, esse estágio compreende a análise do contexto em que o negócio\\nse encontra inserido de modo a compreender o que o cliente realmente necessita e seu\\nobjetivo principal. Essa análise vai guiar todas as fases do processo de descoberta de\\nconhecimento, pois são definidos pontos fundamentais, como, por exemplo, o objetivo de\\nmineração. Esse estágio é essencial pois uma possível definição incorreta dos problemas\\nde negócio levaria a pesquisa invariavelmente a trazer resultados inúteis. A seguir são\\napresentados os principais elementos que compõem essa fase:\\n\\n\\n     • Objetivos de negócio: compreensão do contexto em relação ao mercado em que o\\n       negócio se encontra; definição dos objetivos do negócio em relação ao projeto de\\n       descoberta de conhecimento em base de dados; definição de critérios de sucesso do\\n       projeto.\\n     • Recursos do projeto: inclui inventário de recursos disponíveis para a realização do\\n       projeto; listagem de requisitos e restrições que podem haver, como, por exemplo,\\n       data limite para realização, níveis de qualidade, segurança e disposições legais em\\n       relação aos dados; além de análise da relação custo-benefício esperado obter com o\\n       projeto.\\n     • Objetivo de mineração: definição clara do objetivo de mineração é um passo fun-\\n       damental no processo que permite a execução satisfatória da pesquisa, além dos\\n       critérios de sucesso os quais vão permitir a verificação da eficiência dos modelos\\n       desenvolvidos.\\n     • Planejamento do Projeto: inclui a listagem dos passos necessários para alcançar os\\n       objetivos, como também lista de ferramentas necessárias para a execução e prazos\\n       de execução.\\n\\n\\n\\n4.1.2 Compreensão dos dados\\n\\n\\n        Inicia com a coleta dos dados e com a exploração inicial, o que permite a iden-\\ntificação de problemas de qualidade e a aferição de conhecimentos estatísticos sobre a\\nmassa de dados. Essa fase pode identificar se realmente os dados podem responder às\\n\\x0c                                                                                         47\\n\\n\\nperguntas do negócio e identificar as variáveis significativas. A seguir são apresentados\\nos principais elementos que compõem essa fase:\\n\\n\\n\\n\\n   • Coleta de dados: inclui a extração de dados iniciais ao projeto e a sua descrição\\n      de modo que seja especificada sua localização, técnica utilizada para extração e\\n      resolução de problemas encontrados.\\n   • Descrição dos dados: inclui análise dos dados de maneira a especificar os tipos de\\n      dados disponíveis, seu formato e quantidade. Também permite inferir se os dados\\n      disponíveis satisfazem aos requisitos especificados.\\n   • Exploração dos dados: análise da maneira como os dados estão distribuídos no\\n      banco de dados e de seus relacionamentos por meio da apresentação de gráficos e\\n      relatórios.\\n   • Qualidade: verificação da qualidade dos dados extraídos por meio da verificação de\\n      possíveis erros na extração, além verificação se há valores que estejam faltando em\\n      determinados campos.\\n\\n\\n\\n4.1.3 Preparação dos dados\\n\\n\\n       O objetivo é o pré-processamento dos dados para torná-los relevantes e consisten-\\ntes com respeito à tarefa de busca de conhecimento. Essa fase é extremamente necessá-\\nria, pois os dados muitas vezes podem estar incompletos, inconsistentes ou podem, até\\nmesmo, conter erros. A seguir são apresentados os principais elementos que compõem\\nessa fase:\\n\\n\\n\\n\\n   • Seleção e integração dos dados: se os dados estiverem distribuídos em diversas\\n      bases, será necessário realizar procedimentos para uni-los de modo a permitir pos-\\n      teriormente a seleção das melhores observações coletadas para análise e processa-\\n      mento.\\n   • Limpeza dos dados: realizar o tratamento dos dados de modo a remover dados ou\\n      caracteres que podem reduzir os níveis de acurácia de certos modelos utilizados.\\n   • Construção e formatação dos dados: certas técnicas de modelagem exigem que os\\n      dados estejam em determinado formato para a sua correta utilização.\\n\\x0c48\\n\\n\\n4.1.4 Modelagem\\n\\n\\n         Consiste na tarefa de escolha de métodos e parametrização para a extração de\\npadrões, classificação, segmentação, regressão ou associação de itens, os quais gerarão\\nnovos conhecimentos sobre a importância de cada uma das variáveis em função do re-\\nsultado esperado. A seguir são apresentados os principais elementos que compõem essa\\nfase:\\n\\n\\n\\n\\n     • Escolha da técnica de modelagem: Análise e escolha da melhor técnica de modela-\\n        gem que se aplique ao caso.\\n     • Testes: desenvolver uma técnica que permita a realização da avaliação do modelo\\n        após a sua construção. Muitas vezes, é construída uma base de dados anotada no\\n        estágio anterior de modo que seja possível separar uma parte para testes.\\n     • Construção do modelo: referente ao desenvolvimento do modelo por meio de técni-\\n        cas de treinamento por aprendizado de máquina, por exemplo, incluindo a escolha\\n        de parâmetros.\\n     • Avaliação técnica: consiste em analisar o modelo construído em função de diversos\\n        parâmetros em busca da melhor combinação possível.\\n\\n\\n\\n4.1.5 Avaliação\\n\\n\\n         Fase em que os padrões reconhecidos, regras de associação e todo conhecimento\\ngerado é analisado para verificação da sua real utilidade. Podem ser utilizadas medidas\\nestatísticas, como também visualizações, para ajudar a perceber a utilidade dos dados. A\\nseguir são apresentados os principais elementos que compõem essa fase:\\n\\n\\n\\n\\n     • Análise de resultados: diferentemente da avaliação técnica do modelo, neste caso\\n        o importante é avaliar se o modelo atende aos requisitos de negócio, desse modo, é\\n        possível testar o modelo em um protótipo de aplicação real com usuários finais, por\\n        exemplo.\\n     • Revisão e próximos passos: análise de todas as atividades realizadas e sua eficácia,\\n        além de descrever futuras ações.\\n\\x0c                                                                                         49\\n\\n\\n4.1.6 Aplicação\\n\\n\\n       Consiste na consolidação de todo processo na forma de relatório e publicação do\\nconhecimento ou na incorporação da modelagem a um sistema computacional. A seguir\\nsão apresentados os principais elementos que compõem essa fase:\\n\\n\\n   • Plano de implementação: certos casos exigem que os dados sejam transformados\\n      antes de serem processados por um modelo, assim, todo o processo precisa ser\\n      documentado.\\n   • Plano de monitoramento: pode ser necessário a verificação da qualidade dos dados\\n      recebidos em um fluxo de processamento para alimentação de um modelo de dados.\\n   • Relatório final e revisão: sumário de todo o projeto incluindo uma apresentação\\n      final para os clientes.\\n\\n\\n\\n4.2 Teste de hipótese estatística\\n\\n\\n       A presente pesquisa busca realizar análise quantitativa em relação à proporção\\nde acórdãos julgados favoravelmente para as partes empregado e empresa de modo a\\nresponder à hipótese levantada na Seção 6.1.1. Assim, de modo a aferir se realmente\\nexiste diferença estatística entre as proporções obtidas, julga-se necessária a aplicação de\\ntestes estatísticos, como também o cálculo do nível de força e efeito.\\n       O teste de hipótese estatística desenvolvido neste trabalho segue a proposta de me-\\ntodologia descrita por SNIJDERS no trabalho Snijders (2002). De modo geral, o pesqui-\\nsador define uma questão de pesquisa cuja resposta tem por base a análise de propriedades\\nde um conjunto de observações obtidas a partir de um processo estocástico representado\\npor meio de uma distribuição estatística, ou seja, dados quantitativos. Assim, dados são\\ncoletadas e resumidos de acordo com as propriedades sendo analisadas, que podem ser,\\npor exemplo, valores médios para distribuições contínuas ou proporções para distribui-\\nções binomiais. Após, a questão de pesquisa é reescrita de forma a considerar a existên-\\ncia ou não de um efeito que pode ser observado considerando a propriedade medida por\\nmeio da comparação desse valor com outro valor específico ou com a mesma propriedade\\nobservada de outro grupo estatístico.\\n       Desse modo, é definida a hipótese nula a qual verifica a inexistência de efeito, ou\\nseja, que não há diferença nas observações em relação às propriedades em análise. Já em\\n\\x0c50\\n\\n\\nrelação à comparação entre dois grupos, a hipótese nula pode implicar a verificação da\\nigualdade da propriedade entre dois grupos. Além disso, também é definida a hipótese\\nalternativa a qual define a existência de algum efeito ou define a existência de diferença\\nentre grupos em relação a propriedade sendo analisada. Ao mesmo tempo, é necessário\\ndefinir o nível de significância que deve ser usado para comparar com o resultado do teste\\nestatístico aplicado, normalmente definido como 5%.\\n        Assim, o teste estatístico a ser escolhido computa os dados e apresenta a estatística\\ndo teste e o P-value. A estatística do teste apresenta o quanto os dados diferem da hipótese\\nnula de acordo com a distribuição normal. Já o P-value apresenta a probabilidade de obter\\nos dados analisados se a hipótese nula é na verdade verdadeira na população. A fins de\\ninterpretação de resultados, optou-se por usar o P-value nesta pesquisa em vista da sua\\nobjetividade, pois a interpretação depende da comparação do P-value com o nível de\\nsignificância definido previamente. Se o P-value for menor que o nível de significância,\\nrejeita-se a hipótese nula. Se o P-value for maior, há falha em rejeitar a hipótese nula.\\n        Ademais, o teste estatístico a ser aplicado varia de acordo com o tipo de distribui-\\nção de dados e do tipo de propriedade da distribuição sendo analisada. Testes conhecidos\\ncomo paramétricos basicamente assumem que a distribuição dos dados segue padrões de\\nnormalidade. Já os testes conhecidos como não-paramétricos não assumem que os dados\\nseguem padrões de normalidade. Em relação aos testes paramétricos, existem testes de\\ncorrelação que verificam o relacionamento entre variáveis sem a noção de causa e efeito,\\ntestes de regressão que verificam o relacionamento entre variáveis incluindo a noção de\\ncausa e efeito e testes de comparação que verificam a diferença entre médias e proporções.\\n        Após a escolha do teste estatístico, é necessário verificar se as condições de vali-\\ndade do teste estão satisfeitas em relação aos dados da amostra. Assim, por exemplo, o\\nteste estatístico que realiza a comparação entre proporções de duas distribuições binomi-\\nais necessita que as seguintes suposições estejam satisfeitas:\\n\\n\\n     • Amostra deve conter observações extraídas aleatoriamente com probabilidades\\n       iguais.\\n     • As observações devem ser independentes.\\n     • n1 ∗ p1 ≥ 5 e n1 ∗ (1 − p1) ≥ 5, sendo n1 = quantidade de observações no grupo\\n       1, p1 = proporção no grupo 1.\\n\\n\\n        Por fim, o teste estatístico é aplicado e o P-value é comparado com o nível de\\nsignificância definido previamente. Além disso, é necessário apresentar a conclusão do\\n\\x0c                                                                                     51\\n\\n\\nteste informando a rejeição da hipótese nula ou falha da sua rejeição, como também, a\\ninterpretação dos resultados em relação aos objetivos de negócio estabelecidos.\\n\\n\\n\\n4.3 Resumo do Capítulo\\n\\n\\n       Neste capítulo, iniciou-se apresentando a contextualização metodológica da pes-\\nquisa. Após, foi apresentada a metodologia base utilizada para desenvolvimento de todo o\\nprocesso de validação experimental. Em função do carácter eminentemente prático do es-\\ntudo, optou-se pela metodologia CRISP-DM Guide 1.0 (CHAPMAN et al., 2000), a qual\\napresenta-se amplamente difundida na área profissional. Por outro lado, em vista de que\\na validação experimental inclui análise quantitativa de dados e análise de proporções de\\ndistribuições, optou-se por utilizar também metodologia de pesquisa estatística Snijders\\n(2002) para esta fase dos experimentos.\\n\\x0c52\\n\\n\\n5 MATERIAIS E MÉTODOS\\n\\n\\n       Neste capítulo é apresentada visão geral da pesquisa por meio da classificação\\ntaxonômica e também por meio da descrição do método de validação experimental.\\n\\n\\n\\n5.1 Classificação da pesquisa\\n\\n\\n       A seguir é realizada a classificação da presente pesquisa de acordo com a taxono-\\nmia descrita em Wazlawick (2017). Por se tratar de um tema recente e seus resultados\\ndependerem da aplicação prática de técnicas de mineração de texto no contexto de do-\\ncumentos jurídicos, este trabalho pode ser classificado como uma pesquisa de natureza\\naplicada, pois busca desenvolver conhecimento que pode ser utilizado para aprimorar\\nprocesso de tomada de decisões em empresas e em escritórios de advocacia.\\n       Os objetivos do trabalho o caracterizam como uma pesquisa descritiva, uma vez\\nque os documentos jurídicos são classificados para realização de análise quantitativa.\\n       Em relação aos procedimentos técnicos, foi adotada a pesquisa experimental para\\nalcançar o propósito do trabalho, coletando dados de fontes públicas de sites governamen-\\ntais e desenvolvimento de modelos de aprendizado de máquina. Quanto à abordagem, foi\\nrealizada pesquisa quantitativa em relação aos dados classificados por meio dos modelos\\nde Aprendizado de Máquina.\\n       A avaliação dos resultados da pesquisa quantitativa foi feita por meio de testes\\nestatísticos de significância que permitem a avaliação dos resultados.\\n       Na Tabela 5.1 é possível observar resumo da classificação da pesquisa desenvol-\\nvida com base na taxonomia descrita em Wazlawick (2017).\\n\\n\\n\\n\\n             Tabela 5.1: Resumo da classificação metodológica da pesquisa.\\n     Tipo        Classificação                                   Justificativa\\n Natureza        Aplicada        Aprimoramento do processo de tomada de decisões.\\n Objetivos       Descritiva      Descrição de tendência estatística de julgamento.\\n Procedimentos   Experimental    Coleta de dados, classificação, análise e resposta à hipótese estatística.\\n Abordagem       Quantitativa    Classificação dos dados por meio de modelo de Aprendizado de Máquina.\\n\\x0c                                                                                          53\\n\\n\\n5.2 Método de Validação Experimental\\n\\n\\n       A execução dos experimentos foi realizada utilizando a metodologia descrita em\\nCRISP-DM Guide 1.0 (CHAPMAN et al., 2000) a qual apresenta um método iterativo\\ncomposto de diversas fases cujo objetivo é alinhar o processo de Mineração de Dados às\\nexpectativas do negócio. Por outro lado, essa mesma metodologia prevê o retorno a fases\\niniciais de modo a alinhar os requisitos e objetivos de pesquisa de acordo com conheci-\\nmento novo obtido nas fases de execução de experimentos. Isso se deve principalmente\\nà natureza da pesquisa de Mineração de Dados que busca extrair conhecimento oculto de\\numa base de documentos. Desse modo, a seguir será apresentado o resumo do método se-\\nquencial de execução da validação experimental após a execução iterativa da metodologia\\ndescrita no Capítulo 4.\\n       Assim, primeiramente foi definida a questão de pesquisa como Seria possível que\\nos tribunais avaliados e suas turmas recursais julguem favoravelmente proporção\\nsignificativamente maior de recursos para uma das partes do que para outra em mé-\\ndia? A seguir, foi definido que seria utilizado teste estatístico para verificação da questão\\nde pesquisa. Então, foi definido como hipótese estatística o seguinte: Os tribunais ava-\\nliados e suas turmas recursais julgam favoravelmente proporção significativamente\\nmaior de recursos para uma das partes do que para outra em média. Assim, definiu-\\nse como Pa a proporção de recursos de empregados deferidos e Pb a proporção de recursos\\nde empresas deferidos. Então, foi definida como hipótese nula H0 Pa = Pb. Já a hipótese\\nalternativa como Pa 6= Pb. A seguir, é apresentado resumo do teste de hipótese estatística:\\n\\n\\n   • Pa = proporção de recursos de empregados deferidos.\\n   • Pb = proporção de recursos de empresas deferidos.\\n   • H0: Pa = Pb.\\n   • Ha: Pa 6= Pb.\\n\\n\\n       De modo a realizar a análise quantitativa das proporções de julgados favoráveis às\\npartes empregados e empresas era necessário obter instâncias de observações contendo es-\\nsas informações. Assim, procedeu-se ao desenvolvimento da base de dados pela utilização\\nde técnicas de Mineração de Dados. Portanto, foi definido como objetivo de Mineração de\\nDados classificar automaticamente acórdãos judiciais em relação ao deferimento ou\\nnão e classificar automaticamente o requerente do recurso em relação a ser empresa\\nou a ser empregado. Além disso, classificar com os modelos desenvolvidos quanti-\\n\\x0c54\\n\\n\\ndade significante de decisões judiciais e apresentar relatórios contendo as proporções\\nde julgados positivamente para cada uma das partes.\\n             A seguir, passou a execução do processo de Mineração de Dados o qual compre-\\nende as seguintes fases: Coleta de Dados, que inclui a extração dos documentos da inter-\\nnet; Preparação dos Dados, que inclui a limpeza dos dados, a anotação manual e anotação\\nautomática das bases de dados extraídas; Modelagem que inclui o desenvolvimento de\\nmodelos de Aprendizado de Máquina para a classificação automática das instâncias pre-\\nparadas na fase anterior; Aplicação que inclui a efetiva classificação das instâncias, análise\\nquantitativa, aplicação de testes estatísticos e desenvolvimento de gráficos. A Figura 5.1\\napresenta ilustração explicativa do pipeline da Validação Experimental da pesquisa. Nas\\nseções seguintes são apresentados pontos-chave das fases do processo de Mineração de\\nDados. Além disso, foi disponibilizado também por meio do repositório1 o código-fonte\\nde todo processamento da pesquisa, que pode ser usado para consulta dos detalhes de\\nimplementação e reprodução dos experimentos.\\n\\n\\n\\n5.2.1 Coleta dos Dados\\n\\n\\n             Os documentos judiciais que contém a informação sobre o julgamento de deter-\\nminado processo judicial são chamados de acórdãos, o quais são disponibilizados via in-\\nternet. Esses documentos contêm informação quanto ao vencedor da causa. Assim, esses\\ndocumentos são as instâncias que precisam ser coletadas e processadas na fase seguinte\\nda Mineração de Dados. Assim, foi definido que seriam analisados quantitativamente\\nacórdãos de dois tribunais diferentes, a saber Tribunal Regional do Trabalho da 3a Região\\ne Tribunal Regional do Trabalho da 4a Região.\\n             Os documentos do TRT da 3a Região foram extraídos a partir do site <http:\\n//lexml.gov.br/> por meio dos arquivos sitemap.xml na raiz do site. Quanto ao site\\n<http://trt4.jus.br/>, foi utilizada a página de busca disponibilizada que permite a filtra-\\ngem de documentos por meio de palavras-chave. Assim, foram desenvolvidos robôs de\\nextração de dados utilizando a linguagem Python e a biblioteca Scrapy2 . Na época da exe-\\ncução dos experimentos estavam disponibilizados nas páginas os montantes de acórdãos\\ndescritos na Tabela 6.2, essa tabela também apresenta a quantidade extraída efetivamente\\npelos robôs de extração. Diversas requisições HTTP foram negadas pelos servidores o\\n\\n     1\\n         <https://github.com/rhuanbarros/jurimetria_justica_do_trabalho>\\n     2\\n         <https://scrapy.org/>\\n\\x0c                                                                                       55\\n\\n\\nFigura 5.1: Ilustração explicativa do pipeline da Validação Experimental da pesquisa in-\\ncluindo visão geral do processo.\\n\\n\\n\\n\\nque resultou na impossibilidade de extração de alguns documentos.\\n\\n\\n\\n5.2.2 Preparação dos Dados\\n\\n\\n           A Preparação dos Dados consiste em realizar ajustes para a utilização dos dados\\npor algoritmos de Aprendizado de Máquina. Assim, primeiramente é realizada uma lim-\\npeza para a remoção de instâncias que apresentem mensagens de erro ou que contenham\\ncaracteres truncados. Portanto foi aplicado um filtro que removeu todas as instâncias com\\nmenos de 150 palavras. Importante salientar que a tokenização foi realizada utilizando\\nalgoritmo que processa características específicas da língua portuguesa disponibilizado\\nno repositório da pesquisa3 .\\n           Após a limpeza, passou-se a transformação dos dados. Primeiramente foram ex-\\ntraídos dados dos documentos por meio de expressões regulares o quais foram inseridos\\n   3\\n       <https://github.com/rhuanbarros/jurimetria_justica_do_trabalho>\\n\\x0c56\\n\\n\\nna base de dados como metadados. O código-fonte Python e Regex pode ser encontrado\\nno repositório da pesquisa. Também foi realizada a extração de uma seção dos docu-\\nmentos de texto chamada Dispositivo. Essa seção contém informação suficiente para que\\nos algoritmos de Aprendizado de Máquina extraiam features e classifiquem corretamente\\nas instâncias. Além disso, todos os documentos mais de um recorrente também foram\\nremovidos. Nesse ponto dos experimentos, a base de dados contém os metadados extraí-\\ndos juntamente com o dispositivo dos acórdãos e apenas decisões onde houve apenas um\\nrecorrente, resultando o total de 22.946 instâncias.\\n       A seguir, prosseguiu-se a criação das bases de dados anotadas para utilização com\\nos algoritmos de Aprendizado de Máquina. Como o objetivo de Mineração de Dados\\nexige a realização de dois tipos de classificações, são necessárias duas bases de treina-\\nmento, uma que viabilize a classificação em relação ao tipo de recorrente e outra em\\nrelação ao deferimento ou não da causa judicial.\\n       A criação da base de dados para classificação em relação ao tipo de recorrente foi\\nrealizada por meio da extração aleatória de 270 instâncias de cada um dos tribunais em\\nformato CSV, totalizando 540 observações. Essas anotações foram realizadas exclusiva-\\nmente pelo próprio autor apenas, pois tal tarefa não exige nenhum conhecimento especí-\\nfico relacionado ao Direito. Os rótulos aplicados foram os seguintes: RECLAMANTE ou\\nRECLAMADA.\\n       Após, passou-se a criação de uma base de dados padrão-ouro utilizada para classi-\\nficação em relação ao deferimento ou não da causa. Essa base foi utilizada para realização\\nde experimentos de modelagem de Algoritmo de Aprendizado de Máquina como também\\nfoi utilizada para testes de eficácia dos modelos desenvolvidos. Essa fase foi desenvol-\\nvida seguindo critérios rigorosos de qualidade de acordo com a metodologia descrita em\\n(PUSTEJOVSKY; STUBBS, 2012). Foram selecionadas aleatoriamente 1.000 instân-\\ncias da base de dados preparada anteriormente que foram anotadas pelo próprio autor da\\npesquisa, o qual detém conhecimentos jurídicos suficientes para esta tarefa. Além disso,\\ndessas 1.000, 500 foram anotadas também por uma pessoa bacharel em Direito e as outras\\n500 também foram anotadas por uma pessoa bacharel em Direito. Resultando assim, em\\n1.000 instâncias anotadas por duas pessoas. Importante considerar que foram utilizadas\\npara anotação apenas a parte do Dispositivo dos acórdãos. Os rótulos aplicados foram os\\nseguintes: DEFERIMENTO, INDEFERIMENTO ou SEM_ANALISE_MERITO.\\n       Também foi realizada a anotação automática da base de documentos por meio de\\ntécnica de Supervisão Fraca utilizando o Framework Snorkel. Foram desenvolvidas 13\\n\\x0c                                                                                       57\\n\\n\\nFunções de Rotulação que apenas verificam a existência de uma palavra na instância e\\naplicam um rótulo específico, sendo possível verificar detalhes na Tabela 6.10. Então, o\\nalgoritmo do Snorkel foi aplicado a totalidade de instâncias disponíveis de 22.946, re-\\nsultando, assim, numa base de treinamento criada programaticamente totalizando 22.471\\ninstâncias. Por outro lado, observou-se que a base de dados criada programaticamente\\napresentava grande desbalanceamento. Então procedeu-se ao tratamento dessa questão\\npor meio de Under-sampling criando-se assim outra base de treinamento, mas nesse caso\\ncontendo o total de 1.644 instâncias, sendo 548 instâncias para cada classe.\\n       Enfim, na fase de Preparação dos Dados foram criadas 4 bases de treinamento.\\nUma base para o treinamento em relação ao tipo de recorrente, contendo 540 instâncias.\\nTrês bases para o treinamento em relação ao deferimento ou não da causa. Sendo uma\\ndelas a base padrão-ouro anotada por especialistas, contendo 1.000 instâncias e duas delas\\ncriadas programaticamente contendo 22.471 instâncias e 1.644 instâncias, mas nesse caso\\nbalanceada.\\n\\n\\n\\n5.2.3 Modelagem\\n\\n\\n       A seguir prosseguiu-se a fase de modelagem utilizando as bases de dados criadas\\nnas fases anteriores. Todos os experimentos nessa fase foram desenvolvidos de acordo\\ncom o seguinte fluxo de pré-processamento: as instâncias são tokenizadas com algoritmo\\nespecífico que trata detalhes da língua portuguesa, em seguida é extraída a raiz de cada\\npalavra usando a biblioteca Spacy, após é realizada a vetorização por meio de TF-IDF e\\npor fim é realizada a modelagem com algoritmos de Aprendizado de Máquina, conforme\\nilustrado na Figura 5.2. Além disso todos os experimentos foram modelados utilizando\\nos seguintes algoritmos da biblioteca Scikit Learn: Rocchio classifier, Gradient Boosting\\nClassifier, Naive Bayes Classifier, K-nearest Neighbor, Support Vector Machine (SVM),\\nDecision Tree, Random Forest. Também foi definido como padrão a utilização da métrica\\nF1 como parâmetro de avaliação.\\n       Primeiramente foi desenvolvido um experimento para classificação do tipo de re-\\nquerente como empregado ou empresa sendo utilizado 70% da base para treinamento e\\n30% para testes. Enfim, o algoritmo Support Vector Machine (SVM) atingiu a métrica\\nmais alta de 96,91%.\\n       O desenvolvimento do modelo necessário para classificar as decisões em relação\\nao deferimento ou não da causa judicial foi realizado por meio de três experimentos. Um\\n\\x0c58\\n\\n\\nFigura 5.2: Ilustração explicativa do fluxo de pré-processamento para modelagem por\\nalgoritmos de Aprendizado de Máquina.\\n\\n\\n\\n\\nutilizando a base de dados padrão-ouro, outro utilizando a base criada programaticamente\\nbalanceada e outro utilizando a base de dados criada programaticamente com todas as\\ninstâncias.\\n       O experimento utilizando a base de dados padrão-ouro foi realizado utilizando\\n30% da base para testes e 70% para treinamento. Sendo que também foi realizada a\\nvalidação-cruzada em 7 camadas com as instâncias de treinamento. Já quanto aos dois\\nexperimentos utilizando as bases de dados criadas programaticamente, sendo uma balan-\\nceada e a outra contendo a totalidade de instâncias, não houve a separação em 70/30.\\nNesse caso, foi utilizada a totalidade de cada base criada programaticamente para trei-\\nnamento e usada a totalidade da base padrão-ouro para testes. Assim, foi selecionado o\\nalgoritmo Gradient Boosting pois foi o que atingiu a maior média na métrica F1 sendo de\\n\\x0c                                                                                         59\\n\\n\\n92,48%.\\n\\n\\n\\n5.2.4 Aplicação\\n\\n\\n         Nessa fase foi realizada a aplicação dos dois modelos de Aprendizado de Máquina\\nselecionados a totalidade de 22.946 instâncias extraídas e processadas nas fases anteriores.\\nNesse ponto, foi realizada a filtragem e remoção de todos os documentos que continham o\\nrótulo SEM_ANALISE_MERITO em virtude de que os objetivos de negócio exigem ape-\\nnas a verificação das instâncias rotuladas com DEFERIMENTO ou INDEFERIMENTO.\\nA seguir foi realizado cálculo de proporções de julgamentos deferidos e indeferidos e apli-\\ncados testes estatísticos de proporção utilizando a biblioteca Python Statsmodel. Por fim,\\nforam desenvolvidos gráficos que apresentam as proporções de julgamentos de maneira\\nvisualmente interessante.\\n\\n\\n\\n5.3 Resumo do Capítulo\\n\\n\\n         Este capítulo apresentou resumo do método de validação experimental executado\\nna presente pesquisa e detalhado no Capítulo 6. Assim, primeiramente é realizada a clas-\\nsificação da pesquisa de modo a nortear o leitor sobre o tipo de estudo realizado. Na\\nsequência é salientada o tipo de metodologia utilizada para execução do trabalho e como\\nela foi executada neste trabalho. Após é descrito método de execução da Validação Ex-\\nperimental de modo a permitir a fácil reprodução da pesquisa. Também é disponibilizado\\nlink para acesso ao código-fonte do projeto o que permite verificar detalhes de implemen-\\ntação.\\n\\x0c60\\n\\n\\n6 VALIDAÇÃO EXPERIMENTAL\\n\\n\\n       A validação experimental da presente pesquisa segue metodologia CRISP-DM\\nGuide 1.0 (CHAPMAN et al., 2000) conforme descrito no Capítulo 4. Desse modo,\\nconsiderou-se conveniente apresentar os resultados em seções com mesmos nomes das\\nfases da metodologia proposta. Assim, o Capítulo Validação Experimental está subdivi-\\ndido nas seguintes Seções: Compreensão do negócio, Preparação dos dados, Modelagem,\\nAvaliação de resultados e Aplicação. Também foi incluída ao final do capítulo a Seção\\nLimitações que trata detalhadamente das limitações dos experimentos.\\n\\n\\n\\n6.1 Compreensão do negócio\\n\\n\\n       Tradicionalmente, pesquisas jurisprudenciais são realizadas para a verificação de\\ncomo as decisões judiciais são feitas, dos motivos que levam um magistrado a decidir\\nde determinada forma em cada caso, além dos argumentos em questão utilizados como\\ntambém as consequências dessas decisões em relação a cada assunto. Com tais pesquisas\\nbusca-se diminuir a insegurança e conhecer os caminhos que os processos judiciais po-\\ndem tomar de acordo com o entendimento dominante de um tribunal, turma recursal ou\\nmagistrado.\\n       Entretanto, devido ao distanciamento do Direito de outras ciências (GABARDO;\\nMORETTINI, 2013), como a Ciência da Computação, tais pesquisas eram realizadas sem\\na utilização de recursos automáticos, aliás, eram realizadas manualmente (SALAMA et\\nal., 2011) com uma pequena amostra selecionada. Com a evolução das tecnologias de\\nBig Data e mineração de texto, podemos processar e analisar a grande maioria dos docu-\\nmentos judiciais em busca de padrões desconhecidos, confirmando ou negando hipóteses\\nsupostas devido ao conhecimento geral adquirido na experiência de trabalho, e indo além,\\ndesenvolvendo sistemas preditivos baseados em uma grande gama de dados.\\n       Além disso, o conhecimento da tendência de julgamento de uma turma recursal\\nda Justiça do Trabalho em relação à determinada matéria pode ser um fator de vantagem\\nno momento de realizar um acordo entre as partes, por exemplo. Especificamente nesse\\nramo do Judiciário brasileiro, o acordo entre as partes é incentivado em todos os níveis\\nde jurisdição (TRT4, 2020) de forma que as partes entrem em consenso sozinhas em\\nrelação a um valor justo que leve o processo ao fim. Além disso, é importante notar\\nque um processo judicial que tenha um acordo homologado por magistrado não tem mais\\n\\x0c                                                                                       61\\n\\n\\ndireito a recursos, dando, assim, fim definitivo ao caso, o que acarreta grande economia\\nprocessual a Justiça. Então, quando um processo é dirigido a nível de segundo grau a\\numa turma recursal, o advogado que estiver mais bem informado sobre as tendências\\nde opinião daquele órgão julgador, será mais capaz de tomar uma decisão de aceitar ou\\noferecer um acordo judicial que pode chegar a milhões de reais (TRT4, 2017).\\n\\n\\n\\n6.1.1 Objetivo de negócio\\n\\n\\n       De acordo com Salama, Carlotti e Yeung (2018), o conhecimento popular e a ex-\\nperiência de anos de operadores do Direito parecem encaminhar para a consolidação de\\num senso comum de que existem certos magistrados ou turmas recursais na Justiça do\\nTrabalho inclinadas a proteger mais empregados do que empresas e vice versa. Isso le-\\nvanta questionamentos éticos quanto à parcialidade dos magistrados, conforme abordado\\nno Capítulo 2.1.3. Entretanto, essa situação é perfeitamente possível considerando que\\na legislação brasileira deixa muitos aspectos em aberto permitindo a discricionariedade\\ndos magistrados em relação a que lado tomar para determinados assuntos a serem decidi-\\ndos. É importante considerar também que a dinâmica do Direito permite aos magistrados\\ntomarem posições diferentes em relação a mesma matéria e a argumentar de acordo. En-\\ntretanto, o ponto interessante para os advogados e empresas na prática jurídica é conhecer\\nquem são os magistrados ou turmas recursais mais inclinados para empresas ou empre-\\ngados. Assim, deseja-se confirmar por meio de técnicas computacionais e estatísticas se\\na seguinte questão de pesquisa estabelecida se configura verdadeira: Seria possível que\\nos tribunais avaliados e suas turmas recursais julguem favoravelmente proporção\\nsignificativamente maior de recursos para uma das partes do que para outra em\\nmédia?\\n\\n\\n6.1.1.1 Teste estatístico\\n\\n       A hipótese foi definida como Os tribunais avaliados e suas turmas recursais jul-\\ngam favoravelmente proporção significativamente maior de recursos para uma das\\npartes do que para outra em média. Assim a hipótese a ser validada exige a compara-\\nção de duas proporções em relação à existência de diferença estatística. Assim, definiu-se\\ncomo Pa a proporção de recursos de empregados deferidos e Pb a proporção de recursos\\nde empresas deferidos. Então, foi definida como hipótese nula H0 Pa = Pb. Já a hipótese\\n\\x0c62\\n\\n\\nalternativa como Pa 6= Pb. A seguir, é apresentado resumo do teste de hipótese estatística:\\n\\n\\n     • Pa = proporção de recursos de empregados deferidos.\\n     • Pb = proporção de recursos de empresas deferidos.\\n     • H0: Pa = Pb.\\n     • Ha: Pa 6= Pb.\\n\\n\\n6.1.1.2 Critério de sucesso do objetivo de negócio\\n\\n        Foi definido como critério de sucesso do projeto o processamento e análise de de-\\ncisões judiciais por meio de testes estatísticos e o desenvolvimento de relatório contendo a\\nproporção de decisões para cada uma das partes em cada dos tribunais e turmas recursais\\nestudados, incluindo também dados dos testes estatísticos, como o nível de efeito e nível\\nde força estatística.\\n\\n\\n\\n6.1.2 Requisitos e restrições\\n\\n\\n        O processamento e análise dos dados precisa ser realizado utilizando amostra ex-\\ntraída significante para representar o total de decisões disponibilizadas publicamente.\\nAlém disso, é necessário manter o sigilo quanto a qualquer informação de nomes das\\npartes que sejam citados nos processos judiciais. Por outro lado, a extração automatizada\\nde dados de páginas de internet pode ser proibida, ou até mesmo, o processo pode causar\\ncertos danos aos servidores. Assim, foi definido também que seria respeitada qualquer li-\\nmitação imposta pelos sites a robôs de busca e que a extração dos dados seria realizada da\\nmaneira mais preservada possível. Considerou-se necessário também a análise quantita-\\ntiva de ao menos dois tribunais diferentes para permitir a verificação da performance dos\\nmodelos de Aprendizado de Máquina em documentos de origens diversas, como também\\npermitir a comparação das proporções de julgados entre tribunais diferentes.\\n\\n\\n\\n6.1.3 Custo-benefício\\n\\n\\n        Grandes escritórios de advocacia lidam diariamente com milhares de processos\\ntrabalhistas de uma única empresa. De acordo com Salama, Carlotti e Yeung (2019),\\na condenação média no Tribunal Regional do Trabalho da 2a Região está em torno de\\n\\x0c                                                                                     63\\n\\n\\nR$28.493,54 e o tempo médio de execução de dívida trabalhista de 4 anos e 10 me-\\nses. Considerando o caso de um processo judicial hipotético nessa média de valor de\\ncondenação, valeria a pena para a empresa efetivar acordo no valor até R$21.340,00 e\\npara empregado, acordo acima desse valor. Isso porque uma empresa poderia aplicar o\\ndinheiro durante os 4 anos e 10 meses a uma taxa média de 1% ao mês e no final a aplica-\\nção poderia ter rendido R$38,006,00. Quanto ao empregado, ele poderia aplicar o mesmo\\nvalor a uma taxa de 0,5% ao mês e ainda sair lucrando. Entretanto, o advogado que tiver\\nposse de relatório contendo as tendências médias estatísticas de julgamento em relação\\na empregado e a empregador da turma recursal que recebeu o processo para julgamento\\npode tomar decisão diversa baseado nesses dados. Além disso, deve ser considerado\\nque a turma recursal pode aumentar o valor de condenação (o que seria negativo para a\\nempresa), ou diminuir o valor de condenação (o que seria negativo para o empregado).\\nAssim, um empregado que receba oferta de acordo pouco abaixo do valor ótimo, poderia\\nescolher aceitar considerando que a turma recursal julgando o processo tenha tendência\\nde favorecer empresas e vice-versa.\\n\\n\\n\\n6.1.4 Objetivo de mineração de dados\\n\\n\\n       O objetivo de Mineração de Dados é classificar automaticamente acórdãos ju-\\ndiciais em relação ao deferimento ou não e classificar automaticamente o requerente\\ndo recurso em relação a ser empresa ou a ser empregado. Além disso, classificar\\ncom os modelos desenvolvidos quantidade significante de decisões judiciais e apre-\\nsentar relatórios contendo as proporções de julgados positivamente para cada uma\\ndas partes.\\n\\n\\n\\n6.2 Compreensão dos dados\\n\\n\\n       Primeiramente, procurou-se reunir a matéria prima da pesquisa, os acórdãos judi-\\nciais. Nesse caso, os acórdãos são os documentos judiciais que publicam a decisão dos\\nmagistrados indicando o deferimento ou não dos pedidos dos empregados e empregado-\\nres. Assim, esses documentos extraídos da internet vão compor a amostra para a execução\\nda presente pesquisa. Ou seja, cada instância de observação da amostra é na verdade um\\nacórdão judicial.\\n\\x0c64\\n\\n\\nTabela 6.1: Dados do Justiça em Números (CNJ, 2020) que apresentam a quantidade de\\ncasos novos ajuizados no ano de 2019.\\n                         Quantidade de casos novos em 2019\\n                         TRT 4a Região             267.036\\n                         TJ RS                   1.413.893\\n\\n\\n\\n\\n         Tais documentos são disponibilizados publicamente por todos os tribunais brasi-\\nleiros em suas páginas de internet por meio de site de pesquisa em que os usuários podem\\ninformar palavras-chave para busca. Assim, por meio dessas páginas de busca, foi reali-\\nzada uma exploração prévia da base de dados para reunir conhecimento sobre que tipos\\nde documentos estão disponibilizados, qual a frequência e quantidade de publicação dos\\nTribunais, como os documentos são redigidos, que tipos de palavras são utilizadas, que\\ntipos de metadados são disponibilizados em conjunto. Durante essa fase de exploração\\ninicial, foram analisadas decisões judiciais da Justiça do Trabalho e da Justiça Comum\\ndo Rio Grande do Sul. Durante essa avaliação, foram considerados diversos fatores como\\na legibilidade dos documentos, quantidade de assuntos tratados nas decisões, estruturas\\ncomuns aos documentos, padrões seguidos pelos magistrados, além do conhecimento do\\npesquisador nas matérias do domínio do Direito analisadas.\\n         Desse modo, decidiu-se por realizar a pesquisa utilizando documentos da Justiça\\ndo Trabalho. Tal decisão se baseia principalmente na experiência adquirida pelo pesqui-\\nsador após anos de trabalho como servidor público da Justiça do Trabalho. Por outro lado,\\na Justiça do Trabalho trata de processos de causas estritamente trabalhistas, por ser uma\\nJustiça especializada nesse tipo de causa, ao contrário do que ocorre na Justiça Comum,\\nque trata de uma gama muito ampla de assuntos, desde cíveis até mesmo penais. Desse\\nmodo, supôs-se que os documentos criados abrangem uma gama menor de assuntos e\\nque assim permitiriam uma análise mais acessível, objetiva e especializada. Apenas para\\ntítulo de comparação, podemos observar que a Justiça do Trabalho é muito menor que\\na Justiça Comum averiguando os dados de abertura de processos novos disponibilizados\\npela CNJ no relatório Justiça em Números (CNJ, 2020) e verificando a Tabela 6.1 com\\nas informações resumidas. A partir desses dados, é possível verificar que a quantidade de\\nprocessos abertos na Justiça do Estado do Rio Grande do Sul é aproximadamente 5 vezes\\nmaior.\\n\\x0c                                                                                         65\\n\\n\\n6.2.1 Coleta de dados\\n\\n\\n        Após a decisão de qual Justiça seria foco na pesquisa, passou-se a análise de quais\\npáginas de internet seriam utilizadas para realizar a extração dos dados. Como os dados\\nprecisariam ser extraídos automaticamente, foram avaliados diversos sites para escolher\\nos que não implementassem nenhum tipo de bloqueio a robôs de busca. Assim, foram\\nescolhidos dois sites para extração de dados, o <http://lexml.gov.br/> e o <http://trt4.jus.\\nbr/>.\\n        Por outro lado, de modo a realizar a extração de dados para evitar qualquer pre-\\njuízo aos órgãos públicos e seus domínios na internet, foram implementados métodos\\npara a redução de qualquer possível dano gerado. Assim, foi colocado como diretriz da\\npesquisa o respeito a qualquer limitação imposta pelos próprios sites a robôs de busca.\\nTais limitações geralmente são encontradas nos termos de uso dos sites e em um arquivo\\nchamado robots.txt na raiz do domínio. Além disso, não foram encontrados outros tipos\\nde limitações, como por exemplo, a necessidade de o usuário provar que não é um robô\\npela leitura de caracteres em uma imagem, ou resolução de um problema de lógica que\\napenas um ser humano conseguiria resolver.\\n        Ademais, nenhum dos sites apresenta qualquer documento jurídico indicando os\\ntermos de uso, tampouco apresentavam, à época da realização da atividade, qualquer\\nlimitação a robôs de busca de escanearem todos os documentos públicos dos sites. Havia\\napenas bloqueios em relação a acessos às áreas privadas, como, por exemplo, páginas de\\nintranet. Por outro lado, todos os documentos disponibilizados nos sites são de acesso\\npúblico, sem nem a necessidade de utilizar login.\\n        Além disso, todos os dados pessoais que possam identificar as partes não são publi-\\ncados em nenhuma parte da presente pesquisa. Desse modo, manteve-se a anonimização\\ndas partes. Isso porque o mais importante para a pesquisa é analisar a massa de dados\\nagregada, e não os indivíduos em si. Ademais, foi obtido por e-mail autorização para a\\nutilização de decisões judiciais para a realização de pesquisa quantitativa com técnicas de\\ninteligência artificial e jurimetria.\\n        Enfim, o site do Tribunal Regional do Trabalho da 4a Região foi escolhido por se\\ntratar da Justiça do Trabalho com jurisdição em todo o território do Estado do Rio Grande\\ndo Sul o qual se torna mais interessante para a comunidade acadêmica da nossa Universi-\\ndade como também para os cidadãos que usufruem das pesquisas realizadas na UFRGS.\\nPor outro lado, foi decidido realizar a pesquisa também em outro Estado para permitir a\\n\\x0c66\\n\\n\\ncomparação e avaliação das possíveis diferenças nos dados estatísticos produzidos, como\\ntambém observar possíveis diferenças de escritas nos documentos que poderiam afetar a\\nperformance de algoritmos desenvolvidos. Assim, as decisões do TRT da 4a Região fo-\\nram extraídas de seu próprio site e do site LexML foram extraídas as decisões do Tribunal\\nRegional do Trabalho da 3a Região. Tal Tribunal foi escolhido por ser o tribunal com\\nmais decisões da Justiça do Trabalho disponibilizadas no site. Para ambos os tribunais\\noptou-se por realizar a extração de decisões publicadas a partir do ano de 2017 até 2019.\\n\\n\\n6.2.1.1 Métodos de extração\\n\\n             Os robôs de extração de dados foram desenvolvidos utilizando a linguagem Python\\ne a biblioteca Scrapy1 . Quanto ao site <lexml.gov.br>, eram disponibilizados diversos\\narquivos sitemap.xml na raiz do site para facilitar a extração de dados. Tais arquivos\\ncontinham uma URL para cada documento disponibilizado. Além disso, por meio de\\ncada URL era possível saber do que o documento tratava, permitindo assim a seleção de\\ntodos os documentos necessários a serem extraídos diretamente pelas URLs. Então, o\\nconteúdo completo das decisões era disponibilizado em páginas HTML, as quais foram\\nacessadas diretamente pelos robôs de extração de dados. Quanto ao site <trt4.jus.br>, há\\numa página de busca que permite a filtragem de documentos por meio de palavras-chave.\\nCada resultado é apresentado na mesma página com um link para o documento HTML\\ncontendo a decisão completa. Assim, foi desenvolvido um robô de extração de dados para\\nsimular um humano realizando a pesquisa no site, filtrar os resultados de acordo com os\\ncritérios necessários e acessar os links contendo os acórdãos judiciais completos.\\n\\n\\n6.2.1.2 Tamanho da amostra\\n\\n             A hipótese analisada exige a comparação da proporção de recursos de empregados\\ndeferidos com a proporção de recursos de empresas deferidos, conforme a Seção 6.1.1.1.\\nPor outro lado, utilizou-se a biblioteca Statsmodels2 para realização do teste estatístico,\\npara cálculo das propriedades de efeito e força estatística, como também para cálculo do\\ntamanho da amostra. Desse modo, o cálculo do tamanho da amostra exige como variáveis\\no tamanho das proporções sendo avaliadas, o tamanho da diferença entre as proporções\\nque se deseja verificar, o nível de força estatística e o nível de confiança desejados. En-\\ntretanto, os valores dessas variáveis não são conhecidos antes da efetiva verificação dos\\n     1\\n         <https://scrapy.org/>\\n     2\\n         <https://www.statsmodels.org/stable/index.html>\\n\\x0c                                                                                      67\\n\\n\\nTabela 6.2: Quantidade de decisões disponibilizadas e a quantidade da amostra inicial\\nextraída para cada tribunal.\\n                             Tribunal    População Amostra\\n                        TRT da 3a Região   268.691      26.634\\n                                 a\\n                        TRT da 4 Região    140.545      29.894\\n\\n\\ndados.\\n         Assim, buscou-se realizar a extração de decisões judiciais em certa quantidade\\nque permitisse o processamento inicial e sua análise exploratória para permitir a verifi-\\ncação aproximada das variáveis necessárias. Por outro lado, importante considerar que o\\nobjetivo de negócio exige a realização de teste estatístico em relação às proporções em\\nfunção de cada tribunal como também em relação a cada turma recursal. Desse modo,\\nexiste também a necessidade de se definir as quantidades mínimas de observações neces-\\nsárias em relação a cada turma recursal, o que impõe outra dificuldade, pois não se tem\\nconhecimento prévio das quantidades de processos deferidos para cada uma das partes\\nem cada turma recursal. Enfim, a Tabela 6.2 apresenta o tamanho das amostras extraídas\\npara análise inicial dos dados.\\n\\n\\n6.2.1.3 Dificuldades encontradas\\n\\n         Os robôs de extração de dados desenvolvidos não conseguiram extrair a totalidade\\ndos documentos disponíveis em virtude de que houve problemas de requisições HTTP\\nnão respondidas pelos servidores, como também certa quantidade dos documentos foram\\ndisponibilizadas apenas em formato PDF. Enfim, foi possível extrair diretamente o texto\\npuro da maioria dos arquivos, entretanto, os arquivos PDF precisaram ser processados em\\numa segunda etapa na fase de coleta.\\n\\n\\n\\n6.2.2 Descrição dos dados\\n\\n\\n         A fase de coleta dos dados resultou na compilação de 2 arquivos CSV em relação\\nao TRT da 3a Região e 1 arquivo em relação ao TRT da 4a Região, conforme Tabela 6.3.\\nNo caso do TRT da 3a Região, foram gerados dois arquivos em virtude de dificuldades\\ntécnicas de processamento da carga de dados no momento da extração. Os arquivos CSV\\nsão compostos de um campo com o nome INTEIRO_TEOR contendo o texto puro dos\\nacórdãos judiciais. Foi utilizada a biblioteca Pandas para manipulação dos arquivos nesse\\nformato em virtude da facilidade de uso.\\n\\x0c68\\n\\n\\n Tabela 6.3: Relação dos arquivos gerados a partir da extração dos dados dos tribunais.\\n                                                                    Quantidade de amostras\\n   Tribunal                        Nome do arquivo                  efetivamente extraídas   Tamanho\\nTRT da 3a Região   TRT3_inteiro_teor_2017_2018_2019_amostra_1.csv                   17.846   245MB\\nTRT da 3a Região   TRT3_inteiro_teor_2017_2018_2019_amostra_2.csv                    8.788   120MB\\nTRT da 4a Região   TRT4_inteiro_teor_2017_2018_2019_amostra.csv                     29.894   541MB\\n\\n\\nTabela 6.4: Descrição da base de dados extraída do TRT da 3a Região em relação à\\nquantidade de palavras.\\n                                                Palavras\\n                          Quantidade média        2.093\\n                          Desvio padrão           1.936\\n                          Quantidade mínima            1\\n                          25% percentil             810\\n                          50% percentil           1.457\\n                          75% percentil           2.690\\n                          Quantidade máxima      23.625\\n\\n\\n6.2.3 Exploração dos dados\\n\\n\\n       As bases de dados foram analisadas separadamente, assim, o conjunto do TRT\\nda 3a Região apresentou o total de 26.634 instâncias, já o TRT da 4a Região apresen-\\ntou 29.894. A descrição da quantidade de palavras contidas nos documentos pode ser\\nobservada nas Tabelas 6.4 e 6.5. Os Gráficos contendo as distribuições dos unigramas,\\nbigramas e trigramas é apresentada no Apêndice na Seção A.3.\\n\\n\\n\\n6.2.4 Qualidade dos dados coletados\\n\\n\\n       A qualidade das instâncias extraídas a partir dos arquivos HTML foi satisfatória na\\nmaioria dos casos, entretanto, houve algumas instâncias que continham apenas mensagens\\nde erros com servidores, assim, tais documentos foram removidos na fase de Preparação\\n\\n\\nTabela 6.5: Descrição da base de dados extraída do TRT da 4a Região em relação à\\nquantidade de palavras.\\n                                                Palavras\\n                          Quantidade média        2.738\\n                          Desvio padrão           2.357\\n                          Quantidade mínima            0\\n                          25% percentil           1.051\\n                          50% percentil           2.065\\n                          75% percentil           3.654\\n                          Quantidade máxima      23.391\\n\\x0c                                                                                      69\\n\\n\\ndos Dados. Já em relação aos arquivos PDF, não foi possível utilizar nenhuma dessas\\ninstâncias. A extração do texto puro foi realizada por meio do aplicativo gratuito Xpd-\\nfReader 3 , entretanto o processamento gerou arquivos com caracteres inseridos em partes\\nincorretas do texto, especialmente caracteres referentes a cabeçalhos e rodapés.\\n\\n\\n\\n6.3 Preparação dos dados\\n\\n\\n         Nesta fase da pesquisa são realizados diversos processamentos com os documen-\\ntos para prepará-los para serem usados na fase seguinte de modelagem de dados. Assim,\\nsão realizadas limpeza dos dados como também transformações para extrair e ressaltar\\nas features mais importantes para a tarefa de classificação. Além disso, também é rea-\\nlizada a construção da base padrão-ouro, a qual é utilizada para os testes dos modelos\\ndesenvolvidos.\\n\\n\\n\\n6.3.1 Limpeza dos dados\\n\\n\\n         A limpeza dos documentos de texto foi realizada para garantir a qualidade mí-\\nnima das instâncias para serem utilizadas nas fases subsequentes de transformação de\\ndados e modelagem. Conforme as Tabelas 6.4 e 6.5, é possível observar que há instân-\\ncias contendo nenhuma ou apenas uma palavra. Assim, foi realizada a análise visual das\\ninstâncias contendo menos de 150 palavras e verificou-se que havia muitas mensagens\\nde erros nos documentos. Algumas instâncias continham palavras irreconhecíveis. En-\\nfim, considerou-se prudente remover todas as instâncias que continham menos de 150\\npalavras.\\n\\n\\n\\n6.3.2 Transformação dos dados\\n\\n\\n         Essa fase tem por objetivo extrair e ressaltar as features mais importantes para\\nos algoritmos de modelagem de dados. Assim, são adicionados metadados às decisões,\\ncomo também são removidos documentos e partes dos documentos que não são relevantes\\nà pesquisa.\\n\\n\\n  3\\n      <https://www.xpdfreader.com/pdftotext-man.html>\\n\\x0c70\\n\\n\\n6.3.2.1 Enriquecimento com metadados das decisões judiciais\\n\\n             Os documentos coletados continham de maneira não estruturada em seu conteúdo\\nde texto informações úteis importantes para a realização de agregações e análises em fases\\nposteriores. Assim, foram extraídos por meio de expressões regulares os seguintes dados:\\ndata de publicação, nome do relator, órgão julgador, nome dos recorrentes, dispositivo do\\nacórdão e a quantidade de recorrentes. Esses dados foram extraídos por meio da utilização\\nde palavras-chave e strings Regex. O código-fonte Python e Regex pode ser encontrado\\nno repositório da pesquisa4 .\\n             Entretanto houve dificuldades na aplicação dessa técnica pois certos documentos\\nutilizavam um padrão para escrever essas informações e outros documentos usavam outro\\npadrão. Assim, procurou-se criar expressões regulares que abrangessem o maior número\\nde casos possíveis. Infelizmente, um pequeno número de instâncias não teve esses dados\\nextraídos devido a um modo de escrita diverso e acabaram por ser removidas da base\\nde dados. Enfim, todas as amostras em que as expressões regulares foram efetivas na\\nextração foram enriquecidas com esses dados inseridos como colunas adjacentes.\\n\\n\\n6.3.2.2 Extração do dispositivo da sentença\\n\\n             De acordo com a Seção 2.1, as decisões proferidas pelos magistrados brasileiros\\ndevem ser redigidas seguindo certos padrões e conter determinados elementos. Um des-\\nses elementos é chamado de dispositivo da sentença, o qual é de caráter obrigatório e deve\\nconter em todas as decisões e acórdãos publicados. Essa parte do texto deve conter parti-\\ncularmente a informação sobre se o recorrente teve seu pedido deferido ou não em poucos\\nparágrafos, direto e objetivamente. Assim, essa parte do texto foi extraída, pois é nesse\\ntrecho que está a informação necessária a ser modelada pelo algoritmo de Aprendizado\\nde Máquina a ser desenvolvido.\\n\\n\\n6.3.2.3 Remoção de documentos com mais de um recorrente\\n\\n             Muitos dos acórdãos publicados pelos tribunais dizem respeito a mais de um re-\\ncurso impetrado, nesses casos, ambas as partes recorreram da decisão. Assim, o acórdão\\ntrata dos pedidos de recurso de ambos os recorrentes e o dispositivo da decisão precisa\\nser objetivo e dar uma resposta a cada um dos recursos.\\n             Assim, esse tipo de documento, em que ambas as partes recorreram, exigiria uma\\n     4\\n         <https://github.com/rhuanbarros/jurimetria_justica_do_trabalho>\\n\\x0c                                                                                       71\\n\\n\\nanotação diferenciada para ser possível abranger por completo a semântica necessária\\npara alcançar o objetivo de mineração. Nesse caso, seria necessário anotar individual-\\nmente os tokens do documento para ser possível identificar os elementos distintivos que\\nrepresentam cada uma das partes e o seu deferimento ou não.\\n       Entretanto, construir um modelo que consiga identificar a resposta dos magis-\\ntrados em relação a cada um dos recursos aumentaria o grau de dificuldade do modelo\\nproposto a ser construído pois necessitaria da aplicação de demasiadas técnicas de apren-\\ndizado de máquina e processamento de linguagem natural. Assim, para não aumentar o\\nnível de complexidade da pesquisa num primeiro momento, decidiu-se por não proces-\\nsar tais documentos. Além disso, o objetivo de negócio não exige especificamente que\\nesse tipo de documento seja analisado pelo algoritmo, tornando, assim, fora do escopo do\\nprojeto analisar recursos com mais de um recorrente.\\n       Desse modo, os documentos foram processados em busca de todos que continham\\nmais de um recorrente por meio de análise do texto do campo Recorrente dos documentos\\ncontendo uma vírgula ou um e. Se houvesse, tal documento se tratava de mais de um\\nrecorrente e foram removidos do da base. Enfim, após todo o processamento e remoção\\nde instâncias desnecessárias, a base de documentos do Tribunal Regional do Trabalho da\\n3a Região restou com o total de 10.875 instâncias, já o Tribunal Regional do Trabalho da\\n4a Região com 12.071. Foram removidas 33.582 instâncias.\\n       A remoção dessas instâncias da base de dados pode ter enfraquecido o nível de\\nforça do teste estatístico aplicado nas fases finais da pesquisa em vista de que houve\\ndiminuição considerável de documentos disponíveis para análise. Entretanto, neste ponto\\nda pesquisa não é possível estimar o impacto visto que só é possível calcular o nível de\\nforça do teste estatístico após a realização do teste num momento em que a base de dados\\njá foi totalmente processada em relação às proporções de julgados favoráveis a cada parte.\\n\\n\\n\\n6.3.3 Anotação manual da base de documentos\\n\\n\\n       Os documentos extraídos e processados nos capítulos anteriores foram salvos em\\nformato CSV em ordem aleatória e analisados diretamente em aplicativo editor de planilha\\nde texto. A anotação manual da base de documentos foi desenvolvida seguindo a meto-\\ndologia apresentada no Capítulo 2.4 a qual inicia pela fase de modelagem do metamodelo\\nde rótulos a serem aplicados. Assim, foi necessário que cada documento contivesse uma\\nmarcação em relação a se o requerente é empresa ou empregado e também outra marcação\\n\\x0c72\\n\\n\\nindicando se o recurso foi deferido ou não.\\n\\n\\n6.3.3.1 Anotação para desenvolvimento do modelo de classificação do tipo de recorrente\\n\\n       Foram modelados dois rótulos utilizando a nomenclatura própria do Direito do\\nTrabalho, conforme exposto na Seção 2.1.1: RECLAMANTE, que indica que a parte é\\nempregado, e RECLAMADA, que indica que a parte é empresa. O modelo consiste de um\\nvocabulário de termos T, do relacionamento entre esses termos R, e da interpretação I,\\nconforme demonstrado abaixo.\\n\\n\\n     • T = {Tipo_documento, RECLAMANTE, RECLAMADA}\\n     • R = {Tipo_documento ::= RECLAMANTE | RECLAMADA}\\n     • I = {RECLAMANTE = Parte recorrente é empregado, RECLAMADA = Parte\\n      recorrente é empresa}\\n\\n\\n6.3.3.2 Execução do processo de anotação manual em relação ao tipo de recorrente\\n\\n       A anotação dos documentos em relação ao tipo de recorrente foi realizada pelo\\npróprio autor apenas, pois tal tarefa não exige nenhum conhecimento específico do Di-\\nreito. A rotulação consistiu apenas na verificação do nome do recorrente ser nome de\\npessoa física ou jurídica. Assim, foi extraído aleatoriamente 270 instâncias de cada um\\ndos tribunais em formato CSV, totalizando 540 observações. Essa quantidade foi definida\\narbitrariamente pelo autor após verificação da performance em testes de modelagem.\\n\\n\\n6.3.3.3 Anotação para desenvolvimento do modelo de classificação em relação ao deferi-\\n        mento ou indeferimento da decisão\\n\\n       A princípio foram modelados brevemente dois rótulos: DEFERIMENTO para in-\\ndicar uma decisão que houve julgamento favorável e INDEFERIMENTO para indicar uma\\ndecisão que não houve julgamento favorável. Após, foi iniciada a fase de anotação pelo\\npróprio autor, o qual observou que seria necessária a criação de outro rótulo pois havia\\ndocumentos que não se encaixavam em nenhum dos casos. Assim, foi criado o rótulo\\nSEM ANÁLISE DE MÉRITO.\\n       Foi necessária a criação desse rótulo pois há acórdãos em que não há análise\\nquanto aos pedidos contidos no recurso devido a algum elemento que prejudique sua\\napreciação pelos magistrados, conforme esclarecido no Capítulo 2.1.2. Entretanto, es-\\n\\x0c                                                                                         73\\n\\n\\nses acórdãos sem julgamento de mérito ocorrem em uma minoria de casos. Enfim, foi\\ninevitável o retorno à fase de modelagem para adequação do modelo com o novo rótulo.\\n       Além disso, considerou-se importante a criação do rótulo SEM ANÁLISE DE MÉ-\\nRITO para ser possível verificar o tamanho da distribuição desse tipo de documento na\\nbase de dados. Em fases finais de análise quantitativa e cálculo de proporções de julgados\\ndeferidos e indeferidos, poderia haver a dúvida em relação a qual classe esse tipo de do-\\ncumento haveria sido classificada, em virtude de não haver sido treinado o classificador\\ncom esse tipo de documento previamente. Assim, poderia ser levantado o questionamento\\nse esse tipo de documento não estaria inflando umas das proporções de deferidos ou in-\\ndeferidos. Enfim, abaixo é apresentado o modelo criado para essa tarefa de anotação.\\n\\n\\n   • T        =      {Tipo_documento,         DEFERIMENTO,            INDEFERIMENTO,\\n      SEM_ANALISE_MERITO}\\n   • R    =       {Tipo_documento    ::=   DEFERIMENTO          |   INDEFERIMENTO          |\\n      SEM_ANALISE_MERITO}\\n   • I = {DEFERIMENTO = Julgamento favorável ao recorrente, INDEFERIMENTO\\n      = Julgamento desfavorável ao recorrente, SEM_ANALISE_MERITO = Julga-\\n      mento não é favorável nem desfavorável ao recorrente}\\n\\n\\n6.3.3.4 Execução do processo de anotação manual em relação ao deferimento ou indefe-\\n       rimento da decisão\\n\\n       A rotulação dos documentos foi realizada por três pessoas, sendo o autor e dois\\nvoluntários bacharéis em Direito. Assim, foram elaboradas planilhas online no aplicativo\\nGoogle Suite com as decisões para anotação. Constaram uma coluna com as decisões e\\noutra para inserir o rótulo em cada linha respectivamente. A Figura A.8 apresenta foto da\\ntela da planilha com algumas decisões de exemplo. Assim, foram criadas duas planilhas,\\numa para cada anotador. Em cada planilha foi inserido 250 acórdãos do TRT da 3a Região\\ne 250 acórdãos do TRT da 4a Região. Ou seja, cada voluntário realizou a anotação de 500\\ndocumentos. Além disso, foi feita cópia de ambas as planilhas para serem anotadas pelo\\nautor da pesquisa. Enfim, houve o total de 1000 documentos anotados por duas pessoas.\\nCada um dos documentos foi anotado por um dos anotadores voluntários e pelo autor\\nda pesquisa. Cabe salientar que o autor da pesquisa detém conhecimentos jurídicos de\\nnível técnico e mais de 10 anos de experiência profissional na Justiça brasileira, incluindo\\ntempo de trabalho especificamente em varas do trabalho.\\n\\x0c74\\n\\n\\n       Vale ressaltar que a amostra selecionada para a tarefa de anotação inclui apenas\\ndecisões em que houve apenas um recorrente, o que tornou a tarefa de anotação mais\\nsimples porque havia apenas um recurso para ser apreciado, ou seja, apenas um recurso\\npara ser deferido ou indeferido. Além disso, o processamento final da base de documentos\\npara estimar a tendência de opinião dos magistrados também foi realizado com decisões\\nem que houve apenas um recorrente, conforme exposto na Seção 6.3.2.3.\\n       Por outro lado, houve a preocupação de criar a planilha para os anotadores de\\nmodo a facilitar a correta edição do documento. Assim, as áreas do documento que con-\\ntinham as decisões foram bloqueadas para edição, deixando livre para edição apenas a\\ncoluna Rótulo. Também houve a aplicação de cores alternadas para o fundo das linhas\\npara facilitar a leitura, visualização e edição.\\n       A seguir foi realizado o desenvolvimento das diretrizes de anotação a qual contém\\norientações gerais aos anotadores. Tal documento contém uma seção de introdução que\\nexpõe resumidamente o objetivo da pesquisa e como funciona o trabalho de anotação de\\ndocumentos por anotadores voluntários. Após, são apresentados os rótulos com a devida\\nexplicação detalhada de como cada um deve ser usado. Além disso, são apresentados\\nexemplos de decisões e o respectivo rótulo considerado correto pelo autor da pesquisa.\\nPor fim, é apresentada uma lista de pontos importantes a serem observados pelos anota-\\ndores. A Figura 6.1 apresenta trecho do documento que pode ser encontrado completo no\\nApêndice A.4.\\n\\nFigura 6.1: Trecho do documento Diretrizes para anotação manual de documentos jurídi-\\ncos para pesquisa de mestrado de Rhuan Barros\\n\\n\\n\\n\\n6.3.3.5 Avaliação da tarefa de anotação e criação do padrão-ouro\\n\\n       Conforme exposto na Seção 2.4.1, foi realizada a avaliação do nível de concordân-\\ncia entre os rótulos aplicados pelos anotadores. Assim, a Tabela 6.6 apresenta a matriz\\n\\x0c                                                                                     75\\n\\n\\n              Tabela 6.6: Matriz de confusão em relação aos rótulos aplicados\\n                                 P2              P2                 P2\\n                            DEFERIMENTO    INDEFERIMENTO    SEM_ANALISE_MERITO   TOTAL\\nP1      DEFERIMENTO         435            6                1                    442\\nP1     INDEFERIMENTO        4              534              1                    539\\nP1   SEM_ANALISE_MERITO     1              6                12                   19\\n           TOTAL            440            546              14                   1000\\n\\n\\n\\n\\nTabela 6.7: Balanceamento das classes da base de dados anotada em relação ao tipo de\\nrequerente.\\n                           CLASSE          QUANTIDADE\\n                        RECLAMANTE                      312\\n                        RECLAMADA                       226\\n\\n\\n\\n\\nde confusão em relação aos rótulos aplicados. Aplicando a fórmula Cohen’s Kappa é ob-\\ntido o valor de 0,963 que é considerado alto nível de concordância. Após, foi realizada\\na adjudicação da base de dados em que o próprio autor resolveu as discordâncias, sendo\\npossível observar algumas instâncias de exemplo no Apêndice A.5.\\n\\n\\n\\n6.3.4 Exploração das bases de dados anotadas manualmente\\n\\n\\n       Nesta fase da pesquisa é realizada novamente uma exploração da base de docu-\\nmentos, entretanto, neste caso é possível obter informações essenciais para as fases se-\\nguintes, pois os documentos receberam anotações. Assim, é possível analisar a frequência\\ndas palavras correlacionadas a cada categoria.\\n\\n\\n6.3.4.1 Base de dados anotada manualmente quanto ao tipo de requerente\\n\\n       O processamento da base de dados anotada manualmente quanto ao tipo de re-\\nquerente gerou análises quanto ao balanceamento das classes e também em relação às\\npalavras mais comuns. Assim, na Tabela 6.7 e na Figura 6.2 é possível observar o balan-\\nceamento das classes, sendo que a classe RECLAMADA contém pouco menos instâncias\\nanotadas. Quanto à análise dos unigramas mais comuns em cada classe, é possível ve-\\nrificar que, para a classe RECLAMANTE, sobrenomes comuns no Brasil, como Silva e\\nSantos figuram como mais frequentes. Já para a classe RECLAMADA, as palavras Ltda,\\nBrasil e SA ficam respectivamente em primeiro, segundo e terceiro lugar na lista de mais\\nfrequentes.\\n\\x0c76\\n\\n\\nFigura 6.2: Histograma apresentando o balanceamento das classes da base de dados ano-\\ntada em relação ao tipo de reclamante.\\n\\n\\n\\n\\nTabela 6.8: Balanceamento das classes da base de dados anotada em relação ao deferi-\\nmento ou não da decisão.\\n                           CLASSE               QUANTIDADE\\n                   INDEFERIMENTO                            539\\n                   DEFERIMENTO                              441\\n                   SEM_ANALISE_MERITO                        20\\n\\n\\n6.3.4.2 Base de dados anotada manualmente quanto ao deferimento ou não da decisão\\n\\n       Foi realizado o processamento e análise da base de dados anotada manualmente\\npara explorar o balanceamento das classes e as palavras mais comuns usadas no campo\\nDispositivo em função do rótulo recebido separadamente para cada tribunal. Assim,\\nna Tabela 6.8 e na Figura 6.3 é possível verificar que há desbalanceamento da classe\\nSEM_ANALISE_MERITO, a qual contém apenas 20 instâncias de um total de 1000.\\nQuanto ao texto do campo Dispositivo, foi verificado que a maioria das instâncias contém\\naté 250 palavras nesse campo, conforme Figura 6.4. Além disso, é possível observar na\\nTabela 6.9 que magistrados escrevem menos quando indeferem um recurso em compara-\\nção com os recursos deferidos.\\n       Por outro lado, também foi elaborada análise de termos e suas associações em re-\\nlação a cada classe anotada por meio da biblioteca Python Scattertext (KESSLER, 2017).\\nAssim, é possível observar os termos mais associados com cada uma das classes anotadas\\npara ambos os tribunais na Figura 6.5 e nas listas abaixo os termos mais associados para\\ncada uma das classes. Os termos foram selecionados por meio de tokenização realizada\\nutilizando expressões regulares que abrangem características da língua portuguesa.\\n\\x0c                                                                                   77\\n\\n\\nFigura 6.3: Histograma apresentando o balanceamento das classes da base de dados ano-\\ntada em relação ao deferimento ou não da decisão.\\n\\n\\n\\n\\n       Figura 6.4: Histograma quantidade de palavras no dispositivo por tribunal\\n\\n\\n\\n\\n   • Termos mais associados com os acórdãos anotados como DEFERIMENTO.\\n\\n        – ’deu lhe’,\\n        – ’dar provimento’,\\n        – ’divergência deu’,\\n        – ’dar’,\\n        – ’unanimidade dar’,\\n        – ’à condenação’,\\n        – ’parcial’,\\n        – ’condenar’,\\n\\x0c78\\n\\n\\nTabela 6.9: Descrição da base de dados anotada manualmente em função da quantidade\\nde palavras no campo Dispositivo em relação a cada rótulo aplicado em cada tribunal.\\n                                                                     Palavras\\nTribunal           Rótulo           Contagem de instâncias   Média    Mínimo     25%    50%    75%    Máximo\\n               DEFERIMENTO                            197     248           75    133    161    219     2540\\n TRT3         INDEFERIMENTO                           288     182           43     98    112    133     2743\\n            SEM_ANALISE_MERITO                         15     290           95    103    123    154     1572\\n               DEFERIMENTO                            244     124           34     83    113    149      494\\n TRT4         INDEFERIMENTO                           251      53           35     44     47     50      995\\n            SEM_ANALISE_MERITO                           5     84           64     69     84     90      117\\n\\n\\n\\n            – ’reflexos’,\\n            – ’provimento para’\\n\\n     • Termos mais associados com os acórdãos anotados como INDEFERIMENTO.\\n\\n            – ’divergência negou’,\\n            – ’negou lhe’,\\n            – ’negou’,\\n            – ’negar’,\\n            – ’negar provimento’,\\n            – ’unanimidade negar’,\\n            – ’embargos de’,\\n            – ’de declaração’,\\n            – ’embargos’,\\n            – ’declaração’\\n\\n     • Termos          mais    associados       com          os      acórdãos           anotados       como\\n       SEM_ANALISE_MERITO.\\n\\n            – ’ação de’,\\n            – ’de cobrança’,\\n            – ’cobrança de’,\\n            – ’cobrança’,\\n            – ’comum’,\\n            – ’competência’,\\n            – ’não conheceu’,\\n            – ’estadual’,\\n            – ’justiça comum’,\\n            – ’rel’,\\n\\n\\n           A partir da anotação manual dos documentos e também de sua exploração por\\n\\x0c                                                                                      79\\n\\n\\nFigura 6.5: Gráfico que apresenta os termos mais associados com cada uma das classes\\nanotadas. Mais próximas do canto superior esquerdo encontram-se palavras mais asso-\\nciadas com o rótulo Deferimento. Já próximas do canto inferior direito encontram-se\\npalavras mais associadas com o rótulo Indeferimento.\\n\\n\\n\\n\\nmeio de técnicas de mineração de texto, foi possível observar diversos padrões de escrita\\ndos magistrados particulares a sua área de domínio. Especialmente em relação aos recur-\\nsos negados, é comum os magistrados utilizarem as mesmas palavras, como, por exemplo,\\n“negar” e suas variações. Por outro lado, é possível observar que os magistrados têm o\\nhábito de utilizar a palavra “dar” e suas variações para representar o deferimento de um\\nrecurso.\\n\\n\\n\\n6.3.5 Anotação automática da base de documentos por meio de Supervisão Fraca\\n\\n\\n       A anotação automática de documentos por meio de Supervisão Fraca permite o\\ndesenvolvimento rápido de bases de dados para a utilização em algoritmos de classifi-\\ncação de documentos por meio de Aprendizagem de Máquina Supervisionada, além de\\nque a técnica permite a anotação de grande quantidade de instâncias diretamente. Assim,\\nsupôs-se que tal técnica poderia ajudar a mitigar ponto negativo da pesquisa em relação\\na pequena base de documentos anotada manualmente na Seção 6.3.3. Além disso, a ins-\\npiração para utilização dessa técnica foi obtida em vista de que o autor percebeu durante\\na fase de anotação manual que muitos termos se repetiam e que isso poderia ser usado\\na favo da pesquisa. Desse modo, optou-se por avaliar a performance dessa técnica em\\ndocumentos jurídicos. Enfim, foi utilizado o Snorkel Framework (RATNER et al., 2017)\\npara execução dessa etapa.\\n\\x0c80\\n\\n\\nTabela 6.10: Lista de funções de rotulação criadas para aplicação automática de rótulos à\\nbase de dados.\\n     Função de Rotulação            Palavra-chave                Classificação\\n   lf_negar_provimento          negar provimento          INDEFERIMENTO\\n   lf_rejeitar                  rejeitar                  INDEFERIMENTO\\n   lf_nao_acolher               não acolher               INDEFERIMENTO\\n   lf_manter_decisao            manter decisão            INDEFERIMENTO\\n   lf_julgou_improcedente       julgou improcedente       INDEFERIMENTO\\n   lf_dar_provimento            dar provimento            DEFERIMENTO\\n   lf_dar_parcial_provimento dar parcial provimento DEFERIMENTO\\n   lf_proveu                    proveu                    DEFERIMENTO\\n   lf_parcialmente_proveu       parcialmente proveu       DEFERIMENTO\\n   lf_nulidade_sentenca         nulidade sentença         SEM_ANALISE_MERITO\\n   lf_nao_conhecer              não conhecer              SEM_ANALISE_MERITO\\n   lf_deixar_conhecer           deixar conhecer           SEM_ANALISE_MERITO\\n   lf_prejudicada               prejudicada               SEM_ANALISE_MERITO\\n\\n\\n             Assim, prosseguiu-se com a análise dos termos mais associados às classes anota-\\ndas em relação ao deferimento do acórdão na Seção 6.3.4. Desse modo, foi possível ob-\\nservar que existem certos padrões na redação dos documentos pelos magistrados, os quais\\npodem ser explorados por meio da criação de Label Functions do Snorkel. Dessa maneira,\\na análise dessas informações gerou o desenvolvimento de heurísticas que processam por\\nmeio de Regex a presença ou não de certas palavras identificadoras do deferimento ou\\nnão do recurso pelo magistrado, conforme pode ser observado pela Tabela 6.10. Impor-\\ntante ressaltar que as palavras-chave são testadas utilizando o seu lemma processadas por\\nmeio da biblioteca Spacy 5 . Além disso, há a remoção de stopwords que incluem prono-\\nmes oblíquos átonos os quais muitas vezes se encontram no meio de locuções verbais e\\npoderiam interferir na localização das palavras-chave.\\n             Em vista de que foram desenvolvidas diversas Funções de Rotulação para reali-\\nzar a tarefa de classificação dos documentos, houve a sobreposição de classificação em\\ndiversas instâncias, como é possível observar pela coluna Sobreposições da Tabela 6.12,\\nentretanto a maioria delas obteve porcentagens abaixo de 10% o que indica baixa sobre-\\nposição. Além disso, podemos observar que houve aproximadamente 10% de rotulações\\nconflitantes em relação às classes INDEFERIMENTO e DEFERIMENTO, e menos de\\n5% em relação à classe SEM_ANALISE_MERITO, ou seja, nesses casos houve uma\\nanotação indicando ao menos duas classes diferentes. Importante ressaltar que as instân-\\ncias que receberam o rótulo ABSTAIN não entram na contagem de conflitantes. O rótulo\\nABSTAIN é aplicado quando a função de rotulação não tem conhecimento suficiente para\\n     5\\n         <https://spacy.io/>\\n\\x0c                                                                                        81\\n\\n\\naplicar um rótulo, conforme explicado na Seção 2.6.5. Por outro lado, é possível observar\\npela Figura 6.6 que aproximadamente 80% das instâncias receberam um rótulo e que em\\ntorno de 15% receberam dois ou mais rótulos.\\n       Após, foi utilizado o algoritmo LabelModel do Snorkel para realizar o processa-\\nmento da matriz contendo todas as classificações pelas Funções de Rotulação de modo\\ngerar um modelo probabilístico a fim de ser usado para processar a base de dados com-\\npleta e finalmente assinalar um rótulo final a cada instância. Cabe salientar que esse\\nmodelo probabilístico desenvolvido não tem capacidade de generalização ao realizar o\\nprocessamento de instâncias que as Funções de Rotulação também não tiveram capaci-\\ndade de aplicar um rótulo, em vista disso, instâncias que receberam o rótulo ABSTAIN,\\ncontinuaram recebendo esse rótulo nessa fase de processamento.\\n       Desse modo, o modelo treinado foi aplicado à totalidade 22.946 instâncias da base\\nde documentos disponível, tendo efetivamente aplicado rótulo de INDEFERIMENTO,\\nDEFERIMENTO ou SEM_ANALISE_MERITO a 97,91%, como é possível verificar\\npela Figura 6.7. Também é possível observar que aproximadamente 2% das instâncias\\nreceberam o rótulo ABSTAIN, ou seja, o modelo não aplicou nenhum rótulo. Portanto,\\na tarefa de anotação automática de documentos por meio de técnica de Supervisão Fraca\\ngerou uma nova base de dados contendo o total de 22.471 instâncias.\\n       Importante considerar que os tribunais avaliados disponibilizam centenas de mi-\\nlhares de decisões online de dezenas de anos passados. Entretanto, por dificuldades téc-\\nnicas, não foram possíveis de serem extraídos. Dessa maneira, em trabalhos futuros, essa\\ntotalidade de documentos poderiam ser extraídos e processados por meio do Snorkel Fra-\\nmework o que tenderia a aumentar o nível de acurácia alcançado.\\n       Além disso, é possível observar que o modelo generativo do Snorkel Framework\\nnão contém capacidade de generalização o que se traduz na sua incapacidade de rotular\\ninstâncias que as Funções de Rotulação não continham conhecimento de domínio sufici-\\nente para aplicar um rótulo correto e por fim aplicaram o rótulo ABSTAIN, nesse caso,\\nem 2% das instâncias disponíveis. Entretanto, a capacidade de generalização é uma ca-\\nracterística desejada em aplicações prática de modo que o modelo tenha habilidade de se\\nadaptar e rotular instâncias previamente não vistas e oriundas da mesma distribuição.\\n       Assim, essa incapacidade de generalização impede a utilização do modelo ge-\\nnerativo do Snorkel Framework para a classificação final da base de dados da presente\\npesquisa. Desse modo, na Seção 6.4, foram realizados experimentos para o desenvol-\\nvimento de modelo de Aprendizado de Máquina utilizando algoritmos que contenham a\\n\\x0c82\\n\\n\\nTabela 6.11: Quadro resumo contendo as bases de dados criadas na presente pesquisa\\nincluindo as quantidades de instâncias por classe.\\n                                                            Quantidade por classe\\n            Base de dados             INDEFERIMENTO     DEFERIMENTO SEM_ANALISE_MERITO     Total\\n Padrão-ouro                                      539              441               20    1.000\\n Anotada automaticamente                       12.000           9.923              548    22.471\\n Anotada automaticamente balanceada               548              548             548     1.644\\n\\n\\n\\ncapacidade de generalização. E por fim, na Seção 6.5 foi aplicado o modelo desenvolvido\\nselecionado a totalidade de 22.946 instâncias. O que permitiu a anotação da totalidade de\\ndocumentos disponíveis.\\n        Ademais, da mesma maneira que ocorreu com a base de dados anotada manu-\\nalmente, houve grande desbalanceamento da classe SEM_ANALISE_MERITO. Desse\\nmodo, foi aplicada técnica de Under-samplig a fim de serem removidas aleatoriamente\\ninstâncias das classes INDEFERIMENTO e DEFERIMENTO para conterem finalmente\\na mesma quantidade que a classe SEM_ANALISE_MERITO, totalizando 548 instâncias\\npara cada classe. Portanto, a base de dados final balanceada criada programaticamente\\nfoi gerada contendo o total de 1.644 instâncias. Enfim, por meio da Tabela 6.11, é pos-\\nsível observar a comparação entre todas as bases de dados criadas na presente pesquisa\\nincluindo as quantidades de instâncias por classe.\\n        A checagem dos documentos anotados automaticamente foi realizada pelo próprio\\nautor pela simples observação de algumas instâncias de modo a verificar erros grotescos.\\nPor outro lado, seria inviável realizar a checagem total, além disso, não faz parte da técnica\\nde Supervisão fraca a realização dessa checagem visto que o objetivo é construir a base\\nautomaticamente de maneira menos dispendiosa possível em relação ao tempo necessário\\ne em relação ao custo financeiro. Além disso, a checagem é, de certo modo, realizada ao\\nfinal da pesquisa por meio do treinamento do modelo utilizando a base de dados criada\\nprogramaticamente e por fim aplicação desse modelo a base de dados padrão-ouro.\\n\\n\\n\\n6.4 Modelagem\\n\\n\\n        Para a atender ao objetivo de mineração de dados contido na Seção 6.1.4, primei-\\nramente foi desenvolvido um modelo para classificação dos documentos em relação ao\\ntipo de recorrente. Após, foi desenvolvido um modelo para classificação quanto ao defe-\\nrimento ou indeferimento do dispositivo do acórdão. Em ambos os casos foram utilizadas\\nas respectivas bases de documentos anotadas manualmente conforme exposto na Seção\\n6.3.3. Além disso, para o segundo modelo, foi utilizada também base de documentos\\n\\x0c                                                                                      83\\n\\n\\nTabela 6.12: Apresenta lista com as Funções de Rotulação aplicadas à base de dados e\\nrespectivos dados de cobertura, sobreposições e conflitos.\\n    Função de rotulação           Polaridade       Cobertura   Sobreposições   Conflitos\\n lf_negar_provimento           INDEFERIMENTO        0,489410       0,090125    0,063192\\n lf_rejeitar                   INDEFERIMENTO        0,072823       0,055173    0,033078\\n lf_nao_acolher                INDEFERIMENTO        0,016691       0,000959    0,000567\\n lf_manter_decisao             INDEFERIMENTO        0,007060       0,006755    0,002876\\n lf_julgou_improcedente        INDEFERIMENTO        0,013902       0,011418    0,010198\\n lf_dar_provimento              DEFERIMENTO         0,307548       0,073651    0,068160\\n lf_dar_parcial_provimento      DEFERIMENTO         0,168483       0,037741    0,033819\\n lf_proveu                      DEFERIMENTO         0,019873       0,018260    0,014512\\n lf_parcialmente_proveu         DEFERIMENTO         0,001700       0,001700    0,001525\\n lf_nulidade_sentenca        SEM_ANALISE_MERITO     0,007757       0,007104    0,006406\\n lf_nao_conhecer             SEM_ANALISE_MERITO     0,047372       0,030114    0,029766\\n lf_deixar_conhecer          SEM_ANALISE_MERITO     0,003486       0,002310    0,002048\\n lf_prejudicada              SEM_ANALISE_MERITO     0,020047       0,017999    0,017214\\n\\nFigura 6.6: Gráfico de histograma que apresenta as porcentagens dos rótulos aplicados\\npela Funções de Rotulação.\\n\\n\\n\\n\\nanotada programaticamente conforme Seção 6.3.5.\\n\\n\\n\\n6.4.1 Modelo: classificação do tipo de requerente como empregado ou empresa\\n\\n\\n       A fase de preparação e exploração dos dados das seções anteriores resultou em\\numa lista contendo nomes de partes recorrentes a qual foi anotada manualmente com um\\nrótulo indicando se a parte é empregado ou empresa. Assim, nesta seção são realizados\\nexperimentos para avaliar algoritmos de classificação de texto utilizando a base anotada\\nconstruída.\\n       A fase de avaliação técnica dos modelos desenvolvidos em relação aos níveis dos\\nresultados apresentados foi realizada por meio das bases de dados desenvolvidas na fase\\n\\x0c84\\n\\n\\nFigura 6.7: Gráfico de histograma que apresenta as porcentagens dos rótulos finais apli-\\ncados pelo modelo desenvolvido.\\n\\n\\n\\n\\nde anotação manual. Assim, a base de dados foi dividida em 2 partes, 30% para testes\\ne 70% para treinamento dos modelos. Já essa parte de 70% dos dados foi utilizada para\\ntreinamento utilizando técnica de Validação Cruzada em 7 camadas, conforme Figura\\n6.8. As bases de documentos do TRT da 3a e 4a Região foram utilizadas em conjunto para\\ntreinamento e testes. Além disso, foram escolhidas as métricas acurácia, F1, revocação e\\nprecisão para comparação dos resultados.\\n       O treinamento do modelo necessário para classificar o tipo de requerente sendo\\nempregado ou empresa foi desenvolvido a partir de experimentos realizados utilizando\\nos algoritmos de classificação da biblioteca Scikit Learn. Foram testados os seguintes\\nalgoritmos: Rocchio classifier, Gradient Boosting Classifier, Naive Bayes Classifier, K-\\nnearest Neighbor, Support Vector Machine (SVM), Decision Tree, Random Forest.\\n       Não foram utilizados algoritmos de Redes Neurais em vista de que esses algorit-\\nmos necessitam de bases de dados contendo uma grande quantidade de instâncias e muita\\ndiversidade de features, o que não seria o caso desta base de treinamento. Por outro lado,\\nde modo a garantir a diversidade de métodos de processamento, foram selecionados al-\\ngoritmos que utilizam técnicas probabilísticas, técnicas de distância no espaço vetorial e\\ntécnicas de ensemble de árvores de decisões.\\n       Desse modo, os experimentos foram realizados utilizando os dados de requeren-\\ntes anotados manualmente de ambos os tribunais de maneira conjunta, ou seja, a lista de\\nrequerentes anotada de ambos os tribunais foi unida em uma estrutura de dados única e\\npreparada para o treinamento. Em relação à extração de features foi utilizada a classe\\nCountVectorizer da biblioteca Scikit Learn para realizar a transformação de todas as pa-\\n\\x0c                                                                                      85\\n\\n\\nFigura 6.8: Ilustração do projeto de teste do classificador de tipo de requerente infor-\\nmando as quantidades específicas de instâncias da base de dados.\\n\\n\\n\\n\\nlavras para minúsculas e também o algoritmo padrão dessa classe para realização de to-\\nkenização o qual extrai todas as palavras com dois ou mais caracteres, além de tratar\\ncaracteres de pontuação como separadores de palavras.\\n       Após, foi aplicada a classe TfidfTransformer a qual gera uma matriz contendo a\\nrepresentação TF-IDF. Não houve a aplicação de nenhuma técnica de redução de dimen-\\nsionalidade específica, tampouco foi realizado tratamento de stop-words ou extração de\\nLemma das palavras. Quanto aos algoritmos de classificação, foram utilizados os parâme-\\ntros padrão. Essa configuração mostrou-se satisfatória na fase de avaliação de resultados\\ne por isso foi mantida.\\n       Durante a fase de desenvolvimento, foi utilizada apenas a base reservada de 70%\\ndos dados para a realização de experimentos. Assim, foi utilizada técnica de Validação\\nCruzada em 7 camadas, sendo calculada a média das sete execuções para avaliar a perfor-\\nmance dos algoritmos. Importante ressaltar que também foram utilizadas as matrizes de\\nconfusão para verificação de desempenho.\\n       Após o desenvolvimento, foi utilizada a base de 30% para verificação final de\\ndesempenho dos algoritmos. Assim, foi selecionado o algoritmo com melhor valor de\\n\\x0c86\\n\\n\\nF1 para a construção do modelo final a ser utilizado na Seção 6.5 para realização de\\nprocessamento da base de documentos a fim de se atingir o objetivo de negócio e de\\nmineração de texto. Além disso, a construção desse modelo foi realizada utilizando a\\ntotalidade da base de documentos anotada manualmente de modo a utilizar a integralidade\\nde instâncias e de features disponíveis.\\n             A avaliação técnica dos modelos desenvolvidos foi realizada conforme o projeto\\nde teste. Na Tabela 6.13 e na Figura 6.9 são apresentados os valores de acurácia, F1,\\nrevocação e precisão, sendo possível observar que o algoritmo Support Vector Machine\\n(SVM) obteve o maior valor de F1 com 96,91%, seguido pelo algoritmo Naive Bayes com\\n95,48%. A Tabela 6.14 apresenta a lista de parâmetros escolhidos para o modelo treinado\\ncom o algoritmo Support Vector Machine (SVM). A descrição completa dos parâmetros\\npode ser encontrada no site oficial 6 .\\n\\nFigura 6.9: Métricas calculadas utilizando a base de 30% reservada previamente para\\ntestes do modelo de classificação do tipo de requerente.\\n\\n\\n\\n\\n6.4.2 Modelo: classificar a decisão em deferimento ou indeferimento\\n\\n\\n             A fase de preparação e exploração dos dados das seções anteriores resultou em\\numa base de documentos contendo milhares de decisões judiciais. Assim, foi realizada a\\nanotação manual de 1.000 instâncias desses documentos para compor a base padrão-ouro.\\nAssim, nesta seção são realizados experimentos para avaliar algoritmos de classificação de\\n     6\\n         https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html\\n\\x0c                                                                                 87\\n\\n\\n\\n\\nTabela 6.13: Métricas calculadas utilizando a base de 30% reservada previamente para\\ntestes do modelo de classificação do tipo de requerente.\\n            Classificador               Acurácia        F1   Precisão Revocação\\n  Rocchio                                 93,83% 94,95%       93,07%       96,91%\\n  Gradient Boosting                       87,65% 90,29%       85,32%       95,88%\\n  Naive Bayes                             94,44% 95,48%       93,14%       97,94%\\n  K-nearest Neighbor                      90,74% 92,15%       93,62%       90,72%\\n  Support Vector Machine (SVM)            96,30% 96,91% 96,91%             96,91%\\n  Decision Tree                           85,80% 87,43%       93,02%       82,47%\\n  Random Forest                           91,36% 93,07%       89,52%       96,91%\\n\\n\\n\\n\\nTabela 6.14: Parâmetros e argumentos do modelo de aprendizado de máquina treinado\\nutilizando o algoritmo SVM LinearSVC da biblioteca Scikit Learning.\\n                              Parâmetro      Argumento\\n                          C                      1.0\\n                          class_weight          None\\n                          dual                  True\\n                          fit_intercept         True\\n                          intercept_scaling        1\\n                          loss              squared_hinge\\n                          max_iter              1000\\n                          multi_class            ovr\\n                          penalty                 l2\\n                          random_state          None\\n                          tol                      1\\n                          verbose                  0\\n\\x0c88\\n\\n\\ntexto utilizando a base anotada construída. Também foi construída base de documentos\\nanotada automaticamente para avaliação de técnica de Supervisão Fraca, de técnica de\\nbalanceamento de classes e de algoritmos de classificação.\\n\\n\\n6.4.2.1 Experimento com base de dados criada manualmente padrão-ouro\\n\\n       Inicialmente são realizados experimentos de modelagem de dados utilizando a\\nbase padrão-ouro.     Assim é utilizada a base contendo 1.000 instâncias, sendo des-\\ntas 539 da classe INDEFERIMENTO, 441 da classe DEFERIMENTO e 20 da classe\\nSEM_ANALISE_MERITO. Desse modo, é possível observar que há grande desbalance-\\namento das classes.\\n       A avaliação técnica dos modelos desenvolvidos em relação aos níveis dos resul-\\ntados apresentados foi realizada por meio da base de dados padrão-ouro desenvolvida\\nconforme exposto na Seção 6.3.3. Assim, a base de dados foi dividida em 2 partes, 30%\\npara testes e 70% para treinamento dos modelos. Já essa parte de 70% dos dados foi\\nutilizada para treinamento utilizando técnica de Validação Cruzada em 7 camadas, con-\\nforme Figura 6.10. As bases de documentos do TRT da 3a e 4a Região foram utilizadas\\nem conjunto para treinamento e testes. Além disso, foram escolhidas as métricas acu-\\nrácia, f1, revocação e precisão para comparação dos resultados, sendo que, para as três\\núltimas, foram calculas suas métricas macro e micro por tratar-se de uma tarefa com três\\nclasses. Importante ressaltar que também foram utilizadas as matrizes de confusão para\\nverificação de desempenho.\\n       O treinamento dos modelos necessários para classificar o dispositivo da decisão foi\\ndesenvolvido a partir de experimentos realizados utilizando os algoritmos de classificação\\nda biblioteca Scikit Learn. Foram testados os seguintes algoritmos: Rocchio classifier,\\nGradient Boosting Classifier, Naive Bayes Classifier, K-nearest Neighbor, Support Vector\\nMachine (SVM), Decision Tree, Random Forest.\\n       Não foram utilizados algoritmos de Redes Neurais em vista de que esses algorit-\\nmos necessitam de bases de dados contendo uma grande quantidade de instâncias e muita\\ndiversidade de features, o que não seria o caso desta base de treinamento. Por outro lado,\\nde modo a garantir a diversidade de métodos de processamento, foram selecionados al-\\ngoritmos que utilizam técnicas probabilísticas, técnicas de distância no espaço vetorial e\\ntécnicas de ensemble de árvores de decisões.\\n       Desse modo, os experimentos foram realizados utilizando os dados da base\\npadrão-ouro de ambos os tribunais de maneira conjunta, ou seja, a lista de decisões ano-\\n\\x0c                                                                                       89\\n\\n\\nFigura 6.10: Ilustração do projeto de teste do classificador de tipo de requerente infor-\\nmando as quantidades específicas de instâncias da base de dados.\\n\\n\\n\\n\\ntada de ambos os tribunais foi unida em uma estrutura de dados única e preparada para o\\ntreinamento. Em relação à extração de features foi utilizada a classe CountVectorizer da\\nbiblioteca Scikit Learn para gerar a matriz de termos e documentos. Em conjunto a essa\\nclasse, foi utilizada a biblioteca Spacy7 para processamento do lemma dos termos. Tam-\\nbém foi utilizado código Regex de tokenização personalizado para a língua portuguesa\\nque abrangesse palavras com traços, além da remoção de stop-words.\\n           Após, foi aplicada a classe TfidfTransformer a qual gera uma matriz contendo\\na representação TF-IDF. Não houve a aplicação de nenhuma técnica de redução de di-\\nmensionalidade específica. Quanto aos algoritmos de classificação, foram utilizados os\\nparâmetros padrão. Essa configuração mostrou-se satisfatória na fase de avaliação de\\nresultados e por isso foi mantida.\\n           Durante a fase de desenvolvimento, foi utilizada apenas a base reservada de 70%\\ndos dados para a realização de experimentos. Assim, foi utilizada técnica de Validação\\nCruzada em 7 camadas, sendo calculada a média das sete execuções para avaliar a perfor-\\nmance dos algoritmos. Importante ressaltar que também foram utilizadas as matrizes de\\n   7\\n       <https://spacy.io/>\\n\\x0c90\\n\\n\\nTabela 6.15: Modelos treinados com base padrão-ouro e métricas calculadas utilizando a\\nbase de 30% reservada previamente para testes do modelo de classificação do deferimento\\nou não da decisão.\\n                                            Precisão   Revocação              Precisão   Revocação\\n     Classificador    Acurácia   F1 macro                          F1 micro\\n                                             macro      macro                  micro       micro\\n      Rocchio          82,33%     61,68%     62,55%       77,23%    82,33%     82,33%       82,33%\\n Gradient Boosting     98,33%     90,73%     85,96%      98,84%     98,33%     98,33%      98,33%\\n    Naive Bayes        78,67%     51,56%     55,91%       51,57%    78,67%     78,67%       78,67%\\n K-nearest Neighbor    74,67%     48,33%     53,65%       48,66%    74,67%     74,67%       74,67%\\n       SVM             94,00%     62,97%     62,78%       63,19%    94,00%     94,00%       94,00%\\n   Decision Tree       95,00%     74,82%     74,96%       74,71%    95,00%     95,00%       95,00%\\n   Random Forest       94,67%     63,43%     63,08%       63,79%    94,67%     94,67%       94,67%\\n\\n\\nconfusão para verificação de desempenho. Após o desenvolvimento, foi utilizada a base\\nde 30% para verificação final de desempenho dos algoritmos.\\n         Os modelos desenvolvidos foram avaliados conforme o projeto de teste. É possível\\nobservar por meio da Tabela 6.15 e da Figura 6.11 que há grande discrepância entre os\\nvalores macro e micro. Por outro lado, verificando as matrizes de confusão apresentadas\\nna Seção A.6, é visto que a maioria das instâncias da classe SEM_ANALISE_MERITO\\nnão foram classificadas corretamente pelos algoritmos que tiveram as piores performances\\nem relação às métricas macro. Isso se deve ao fato do grande desbalanceamento dessa\\nclasse, conforme Figura 6.3.\\n\\nFigura 6.11: Modelos treinados com base padrão-ouro e métricas calculadas utilizando a\\nbase de 30% reservada previamente para testes do modelo de classificação do deferimento\\nou não da decisão.\\n\\x0c                                                                                        91\\n\\n\\n6.4.2.2 Experimento com base de dados criada programaticamente balanceada\\n\\n          Primeiramente é realizada a modelagem dos dados utilizando a base de dados\\ncriada automaticamente balanceada. Nesse caso, a base contém 1.644 instâncias, sendo\\ndestas 548 da classe INDEFERIMENTO, 548 da classe DEFERIMENTO e 548 da classe\\nSEM_ANALISE_MERITO, estando assim, as classes totalmente niveladas.\\n          A avaliação técnica dos modelos desenvolvidos em relação aos níveis dos resul-\\ntados apresentados foi realizada por meio da base de dados padrão-ouro desenvolvida\\nconforme exposto na Seção 6.3.3. Desse modo, houve o treinamento com a base de da-\\ndos balanceada criada programaticamente e realizado o teste cruzado com a base anotada\\nmanualmente. Da mesma maneira, neste caso foram escolhidas as métricas acurácia, f1,\\nrevocação e precisão para comparação dos resultados, sendo que, para as três últimas, fo-\\nram calculadas suas métricas macro e micro por tratar-se de uma tarefa com três classes.\\nImportante ressaltar que também foram utilizadas as matrizes de confusão para verifica-\\nção de desempenho.\\n          O treinamento dos modelos foi realizado utilizando os algoritmos de classificação\\nda biblioteca Scikit Learn. Foram testados os seguintes algoritmos: Rocchio classifier,\\nGradient Boosting Classifier, Naive Bayes Classifier, K-nearest Neighbor, Support Vector\\nMachine (SVM), Decision Tree, Random Forest.\\n          Não foram utilizados algoritmos de Redes Neurais em vista de que esses algorit-\\nmos necessitam de bases de dados contendo uma grande quantidade de instâncias e muita\\ndiversidade de features, o que não seria o caso desta base de treinamento. Por outro lado,\\nde modo a garantir a diversidade de métodos de processamento, foram selecionados al-\\ngoritmos que utilizam técnicas probabilísticas, técnicas de distância no espaço vetorial e\\ntécnicas de ensemble de árvores de decisões.\\n          Desse modo, os experimentos foram realizados utilizando a base de dados balan-\\nceada criada programaticamente, conforme Seção 6.3.5, incluindo os dados de ambos os\\ntribunais de maneira conjunta, ou seja, a lista de decisões anotada de ambos os tribunais\\nfoi unida em uma estrutura de dados única e preparada para o treinamento. Em relação à\\nextração de features foi utilizada a classe CountVectorizer da biblioteca Scikit Learn para\\ngerar a matriz de termos e documentos. Em conjunto a essa classe, foi utilizada a bibli-\\n                 8\\noteca Spacy          para processamento do lemma dos termos. Também foi utilizado código\\nRegex de tokenização personalizado para a língua portuguesa que abrangesse palavras\\ncom traços, além da remoção de stop-words. Após, foi aplicada a classe TfidfTransfor-\\n  8\\n      <https://spacy.io/>\\n\\x0c92\\n\\n\\nTabela 6.16: Modelos treinados utilizando base criada programaticamente balanceada\\ne métricas calculadas utilizando a base de dados padrão-ouro para testes do modelo de\\nclassificação do deferimento ou não da decisão.\\n        Classificador           Acurácia   F1 macro    Precisão macro    Revocação macro    F1 micro   Precisão micro   Revocação micro\\n      Rocchio classifier           0,689      0,5658            0,6361             0,7606      0,689            0,689             0,689\\n Gradient Boosting Classifier      0,946      0,8475            0,8049             0,9446      0,946            0,946             0,946\\n         Naive Bayes               0,748      0,6009            0,6401             0,7957      0,748            0,748             0,748\\n     K-nearest Neighbor            0,741      0,5826            0,5963             0,6705      0,741            0,741             0,741\\nSupport Vector Machine (SVM)       0,942      0,8179             0,776             0,9271      0,942            0,942             0,942\\n        Decision Tree              0,944      0,8441            0,7977             0,9599      0,944            0,944             0,944\\n       Random Forest               0,956      0,8684            0,8201             0,9692      0,956            0,956             0,956\\n\\n\\n\\n\\nmer a qual gera uma matriz contendo a representação TF-IDF. Não houve a aplicação de\\nnenhuma técnica de redução de dimensionalidade específica. Quanto aos algoritmos de\\nclassificação, foram utilizados os parâmetros padrão.\\n          Os modelos desenvolvidos foram avaliados conforme o projeto de teste. Desse\\nmodo, os modelos foram treinados utilizando toda a base de dados criada programati-\\ncamente balanceada e foram usados para classificar toda a base padrão-ouro. A Tabela\\n6.16 e a Figura 6.12 apresentam as métricas de avaliação. É possível verificar que a\\nperformance máxima dos modelos em relação a métrica f1 macro foi inferior ao valor\\nreportado na Seção 6.4.2.1 tendo nenhum classificador alcançado valor maior que 90%.\\nPor outro lado, houve a concentração de algoritmos com média f1 macro entre 80% e\\n90%. Além disso, avaliando as matrizes de confusão presentes na Seção A.7 é possí-\\nvel verificar que todos os algoritmos tiveram classificações corretas em relação à classe\\nSEM_ANALISE_MERITO, diferente do que ocorreu no experimento da Seção 6.4.2.1,\\no que pode ser considerado um efeito positivo da base de dados balanceada com número\\nmaior de instâncias.\\n\\n\\n6.4.2.3 Experimento com base de dados criada programaticamente completa\\n\\n          Neste experimento foi realizada a modelagem dos dados utilizando a base de da-\\ndos criada automaticamente completa. Assim, foi utilizada a base anotada automatica-\\nmente completa contendo 22.471 instâncias, sendo destas 12.000 da classe INDEFERI-\\nMENTO, 9.923 da classe DEFERIMENTO e 548 da classe SEM_ANALISE_MERITO.\\nDesse modo, é possível observar que também há grande desbalanceamento das classes.\\n          Os experimentos realizados para desenvolvimento do modelo para classificar o\\ndispositivo da decisão foram realizados utilizando os algoritmos de classificação da bibli-\\noteca Scikit Learn. Foram testados os seguintes algoritmos: Rocchio classifier, Gradient\\nBoosting Classifier, Naive Bayes Classifier, K-nearest Neighbor, Support Vector Machine\\n(SVM), Decision Tree, Random Forest.\\n\\x0c                                                                                        93\\n\\n\\nFigura 6.12: Modelos treinados utilizando base criada programaticamente balanceada e\\nmétricas calculadas utilizando a base de dados padrão-ouro para testes do modelo de\\nclassificação do deferimento ou não da decisão.\\n\\n\\n\\n\\n          Não foram utilizados algoritmos de Redes Neurais em vista de que esses algorit-\\nmos necessitam de bases de dados contendo uma grande quantidade de instâncias e muita\\ndiversidade de features, o que não seria o caso desta base de treinamento. Por outro lado,\\nde modo a garantir a diversidade de métodos de processamento, foram selecionados al-\\ngoritmos que utilizam técnicas probabilísticas, técnicas de distância no espaço vetorial e\\ntécnicas de ensemble de árvores de decisões.\\n          Desse modo, os experimentos foram realizados utilizando a base de dados com-\\npleta criada programaticamente, conforme Seção 6.3.5, incluindo os dados de ambos os\\ntribunais de maneira conjunta, ou seja, a lista de decisões anotada de ambos os tribunais\\nfoi unida em uma estrutura de dados única e preparada para o treinamento. Em relação a\\nextração de features foi utilizada a classe CountVectorizer da biblioteca Scikit Learn para\\ngerar a matriz de termos e documentos. Em conjunto a essa classe, foi utilizada a bibli-\\n                 9\\noteca Spacy          para processamento do lemma dos termos. Também foi utilizado código\\nRegex de tokenização personalizado para a língua portuguesa que abrangesse palavras\\ncom traços, além da remoção de stop-words.\\n          Após, foi aplicada a classe TfidfTransformer a qual gera uma matriz contendo\\n\\n  9\\n      <https://spacy.io/>\\n\\x0c94\\n\\n\\nTabela 6.17: Modelos treinados utilizando base criada programaticamente completa e\\nmétricas calculadas utilizando a base de dados padrão-ouro para testes do modelo de\\nclassificação do deferimento ou não da decisão.\\n        Classificador           Acurácia   F1 macro    Precisão macro    Revocação macro    F1 micro   Precisão micro   Revocação micro\\n      Rocchio classifier           0,721       0,584            0,6306             0,7813      0,721            0,721             0,721\\n Gradient Boosting Classifier      0,954      0,9248            0,9053             0,9504      0,954            0,954             0,954\\n         Naive Bayes               0,846      0,5673            0,5721             0,5696      0,846            0,846             0,846\\n     K-nearest Neighbor            0,806      0,5648            0,7378              0,552      0,806            0,806             0,806\\nSupport Vector Machine (SVM)       0,961      0,9157            0,9237             0,9083      0,961            0,961             0,961\\n        Decision Tree              0,951      0,9168            0,8936             0,9484      0,951            0,951             0,951\\n        Random Forest               0,96      0,9179            0,9137             0,9231       0,96             0,96              0,96\\n\\n\\n\\n\\na representação TF-IDF. Não houve a aplicação de nenhuma técnica de redução de di-\\nmensionalidade específica. Quanto aos algoritmos de classificação, foram utilizados os\\nparâmetros padrão. Essa configuração mostrou-se satisfatória na fase de avaliação de\\nresultados e por isso foi mantida.\\n           Os modelos desenvolvidos foram avaliados conforme o projeto de teste. Desse\\nmodo, os modelos foram treinados utilizando toda a base de dados criada programatica-\\nmente e foram usados para classificar toda a base padrão-ouro. A Tabela 6.17 e a Figura\\n6.13 apresentam as métricas de avaliação. É possível verificar que houve quatro modelos\\nque obtiveram performance máxima em relação a métrica f1 macro superiores aos valores\\nreportados na Seção 6.4.2.1 e na Seção 6.4.2.2.\\n           Além disso, avaliando as matrizes de confusão presentes na Seção 6.4.2.1 é pos-\\nsível verificar que alguns algoritmos não obtiveram classificações em relação à classe\\nSEM_ANALISE_MERITO o que resultou em métricas f1 macro em torno de 60%. En-\\nfim, o modelo que obteve a melhor média f1 macro, a saber, Gradient Boosting, foi se-\\nlecionado para realizar a classificação final de toda a base de documentos para análise\\nna Seção 6.5. A Tabela 6.18 apresenta a lista de parâmetros escolhidos para o modelo\\ntreinado com o algoritmo Gradient Boosting. A descrição completa dos parâmetros pode\\nser encontrada no site oficial 10 .\\n\\n\\n\\n6.5 Avaliação de resultados\\n\\n\\n           O processo de mineração de dados textuais de decisões judiciais elaborado resul-\\ntou no desenvolvimento de dois modelos baseados em aprendizado de máquina super-\\nvisionado e na sua utilização para o processamento de 22.946 decisões judiciais, sendo\\n12.071 do TRT da 4a Região e 10.875 do TRT da 3a Região. Com a utilização desses mo-\\ndelos, os objetivos de mineração foram atingidos que eram classificar automaticamente\\n\\n  10\\n       https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html\\n\\x0c                                                                                       95\\n\\n\\nFigura 6.13: Modelos treinados utilizando base criada programaticamente completa e\\nmétricas calculadas utilizando a base de dados padrão-ouro para testes do modelo de\\nclassificação do deferimento ou não da decisão.\\n\\n\\n\\n\\nos acórdãos judiciais em relação ao deferimento ou não e classificar automaticamente o\\nrequerente do recurso em relação a ser empresa ou a ser empregado. Cabe salientar que,\\napós a aplicação dos modelos de classificação, todas as instâncias que receberam o ró-\\ntulo SEM_ANALISE_MERITO foram removidas da análise, pois não interessavam aos\\nobjetivos de negócio e de mineração de texto.\\n       Desse modo, foi possível atender também ao objetivo de negócio para verificar a\\nvalidade da hipótese por meio de teste estatístico se seria possível que os tribunais ava-\\nliados e suas turmas recursais julguem favoravelmente proporção maior de recursos para\\numa das partes do que para outra. Assim, também são apresentadas a conclusão e a inter-\\npretação dos testes estatísticos de proporção, força e efeito. Após, foram desenvolvidos\\nrelatórios com gráficos para apresentar os resultados obtidos com o processamento dos\\ndocumentos.\\n\\x0c96\\n\\n\\nTabela 6.18: Parâmetros e argumentos do modelo de aprendizado de máquina treinado\\nutilizando o algoritmo Gradient Boosting da biblioteca Scikit Learning.\\n                               Parâmetro            Argumento\\n                       ccp_alpha                         0.0\\n                       criterion                   friedman_mse\\n                       init                             None\\n                       learning_rate                     0.1\\n                       loss                           deviance\\n                       max_depth                          3\\n                       max_features                     None\\n                       max_leaf_nodes                   None\\n                       min_impurity_decrease             0.0\\n                       min_samples_leaf                   1\\n                       min_samples_split                  2\\n                       min_weight_fraction_leaf          0.0\\n                       n_estimators                      100\\n                       n_iter_no_change                 None\\n                       random_state                      1.0\\n                       subsample                       0.0001\\n                       tol                               0.1\\n                       validation_fraction               0.1\\n                       verbose                            0\\n                       warm_start                       False\\n\\n\\n\\n6.5.1 TRT da 4a Região - avaliação geral\\n\\n\\n       Na Figura 6.14 é possível observar a porcentagem da quantidade de recursos de-\\nferidos e indeferidos no TRT da 4a Região em relação ao recorrente ser empresa ou em-\\npregado. Assim, é possível verificar que 50% dos recursos impetrados pelos empregados\\nforam deferidos ou parcialmente deferidos. Além disso, também é possível verificar que,\\ndos recursos impetrados pelas empresas, 39% foram julgados deferidos ou parcialmente\\ndeferidos. Por outro lado, fica evidente a diferença de 12% na quantidade de recursos\\ndeferidos ou parcialmente deferidos quando o recorrente são os empregados. Importante\\nfrisar que essa média leva em consideração amostra dos acórdãos proferidos por todas as\\nTurmas Recursais do tribunal em conjunto.\\n       Nessa amostra foram processados 11.351 acórdãos, sendo 9.398 recursos da parte\\nempregado e 1.953 recursos da parte empresa. A parte empresa recorreu aproximada-\\nmente 4 vezes menos do que a parte empregado. Além disso, em relação aos testes esta-\\ntísticos aplicados, foi obtido P-value de 0%, ou seja, há grande confiança de que existe\\ndiferença estatística entre a proporção de deferimentos para empregado e para empresa.\\n\\x0c                                                                                                             97\\n\\n\\nFigura 6.14: Porcentagem de deferimento de recursos em relação ao recorrente ser em-\\npresa e empregado no Tribunal Regional do Trabalho da 4a Região.\\n\\n\\n\\n\\nTabela 6.19: Porcentagem de deferimento de recursos em relação ao recorrente ser em-\\npresa e empregado das Turmas Recursais do Tribunal Regional do Trabalho da 4a Região.\\n             TURMA        TOTAL DE                 PVALUE                   POWER                    EFFECT\\nTRIBUNAL                             PVALUE                      POWER                  EFFECT\\n            RECURSAL     PROCESSOS                 INTERP.                  INTERP.                  INTERP.\\n   TRT4       1a Turma      1.639    0,7172   NÃO HÁ DIFERENÇA   0,0863   INACEITÁVEL   0,0217   INSIGNIFICANTE\\n   TRT4       2a Turma      1.704       0       HÁ DIFERENÇA        1      ACEITÁVEL    0,5267        MÉDIA\\n   TRT4       3a Turma      1.832       0       HÁ DIFERENÇA        1      ACEITÁVEL    0,4853      PEQUENA\\n   TRT4       4a Turma      1.800    0,0343     HÁ DIFERENÇA     0,9575    ACEITÁVEL    0,1343   INSIGNIFICANTE\\n   TRT4       5a Turma      1.504    0,0003     HÁ DIFERENÇA     0,9999    ACEITÁVEL    0,2355      PEQUENA\\n   TRT4       6a Turma      1.171    0,1741   NÃO HÁ DIFERENÇA    0,638   INACEITÁVEL   0,1051   INSIGNIFICANTE\\n   TRT4       7a Turma       825     0,1687   NÃO HÁ DIFERENÇA   0,6817   INACEITÁVEL   0,1307   INSIGNIFICANTE\\n   TRT4       8a Turma       448     0,0032     HÁ DIFERENÇA     0,9988    ACEITÁVEL     0,366      PEQUENA\\n   TRT4       9a Turma       131     0,1106   NÃO HÁ DIFERENÇA   0,8029    ACEITÁVEL    0,3813      PEQUENA\\n   TRT4      10a Turma       115     0,0752   NÃO HÁ DIFERENÇA   0,7266   INACEITÁVEL   0,3892      PEQUENA\\n   TRT4      11a Turma       182     0,3001   NÃO HÁ DIFERENÇA   0,4141   INACEITÁVEL   0,2038      PEQUENA\\n\\n\\n\\n\\nEm relação ao nível de efeito estatístico em função da tabela Cohen’s, foi obtido o índice\\nde 22,11%, ou seja, o nível de efeito estatístico da diferença de proporções é pequeno.\\nQuanto à força do teste estatístico, foi obtido o 100%, ou seja, foi alcançado nível aceitá-\\nvel de força estatística e há risco baixo de não haver diferença entre as proporções.\\n\\n\\n\\n6.5.2 TRT da 4a Região - avaliação das Turmas Recursais\\n\\n\\n          Em relação a dados individuais de cada uma das Turmas Recursais do TRT da 4a\\nRegião, Figura 6.15, é possível verificar que as Turmas Recursais 2a , 3a , 5a , 8a , 9a e 11a\\napresentaram proporção parecida com a do tribunal para empregados. Por outro lado, a\\nFigura 6.16 apresenta a distribuição das proporções de deferimentos das turmas recursais.\\nAlém disso, na Tabela 6.19 são apresentados os dados em relação aos testes estatísticos\\naplicados, como o P-Value, Power e Effect. Assim, é possível verificar que há diversas\\nturmas recursais que o Power está abaixo de 0,8, o que ocorre devido à pouca quantidade\\nde dados para análise, entretanto é possível superar essa limitação pela ingestão de mais\\nobservações em trabalhos futuros.\\n\\x0c98\\n\\n\\nFigura 6.15: Porcentagem de deferimento de recursos em relação ao recorrente ser em-\\npresa e empregado das Turmas Recursais do Tribunal Regional do Trabalho da 4a Região.\\n\\n\\n\\n\\n6.5.3 TRT da 3a Região - avaliação geral\\n\\n\\n       Na Figura 6.17 é possível observar a porcentagem da quantidade de recursos defe-\\nridos e indeferidos no TRT da 3a Região em relação ao recorrente ser empresa ou empre-\\ngado. Assim, é possível verificar que 41,31% dos recursos impetrados pelos empregados\\nforam deferidos ou parcialmente deferidos. Além disso, também é possível verificar que,\\ndos recursos impetrados pelas empresas, 39,07% foram julgados deferidos ou parcial-\\nmente deferidos. Fica evidente a diferença de 2,24% na quantidade de recursos deferidos\\nou parcialmente deferidos quando o recorrente são os empregados. Importante frisar que\\nessa média leva em consideração amostra dos acórdãos proferidos por todas as Turmas\\nRecursais do tribunal em conjunto.\\n       Nessa amostra foram processados 10.477 acórdãos, sendo 7.349 recursos da parte\\n\\x0c                                                                                        99\\n\\n\\nFigura 6.16: Distribuição da porcentagem de deferimento de recursos em relação ao recor-\\nrente ser empresa e empregado das Turmas Recursais do Tribunal Regional do Trabalho\\nda 4a Região.\\n\\n\\n\\n\\nFigura 6.17: Porcentagem de deferimento de recursos em relação ao recorrente ser em-\\npresa e empregado no Tribunal Regional do Trabalho da 3a Região.\\n\\n\\n\\n\\nempregado e 3.128 recursos da parte empresa. Nessa amostra a parte empresa recorreu\\naproximadamente 2 vezes menos do que a parte empregado. Além disso, em relação aos\\ntestes estatísticos aplicados, foi obtido P-value de 3,19%, ou seja, há grande confiança\\nde que existe diferença estatística entre a proporção de deferimentos para empregado e\\npara empresa. Em relação ao nível de efeito estatístico em função da tabela Cohen’s, foi\\nobtido o índice de 4,58%, ou seja, o nível de efeito estatístico da diferença de proporções\\né insignificante. Quanto à força do teste estatístico, foi obtido o 79,28%, ou seja, foi\\nalcançado nível abaixo do aceitável de força estatística e há risco de não haver diferença\\n\\x0c100\\n\\n\\nTabela 6.20: Porcentagem de deferimento de recursos em relação ao recorrente ser em-\\npresa e empregado das Turmas Recursais do Tribunal Regional do Trabalho da 3a Região.\\n            TURMA        TOTAL DE                 PVALUE                     POWER                     EFFECT\\nTRIBUNAL                            PVALUE                      POWER                    EFFECT\\n           RECURSAL     PROCESSOS             INTERPRETACAO              INTERPRETAÇÃO            INTERPRETACAO\\n  TRT3       1a Turma      1058        0       HÁ DIFERENÇA        1        ACEITÁVEL    0,3749       PEQUENA\\n  TRT3       2a Turma       906     0,4009   NÃO HÁ DIFERENÇA   0,1789     INACEITÁVEL   0,0591    INSIGNIFICANTE\\n  TRT3       3a Turma       938     0,1047   NÃO HÁ DIFERENÇA   0,5978     INACEITÁVEL   0,1193    INSIGNIFICANTE\\n  TRT3       4a Turma       931     0,0014     HÁ DIFERENÇA     0,9803      ACEITÁVEL    0,2245       PEQUENA\\n  TRT3       5a Turma       889     0,3495   NÃO HÁ DIFERENÇA   0,2372     INACEITÁVEL   0,0692    INSIGNIFICANTE\\n  TRT3       6a Turma       973     0,0116     HÁ DIFERENÇA     0,9142      ACEITÁVEL    0,1788    INSIGNIFICANTE\\n  TRT3       7a Turma      1025        0       HÁ DIFERENÇA        1        ACEITÁVEL    0,4839       PEQUENA\\n  TRT3       8a Turma       850     0,0762   NÃO HÁ DIFERENÇA   0,6205     INACEITÁVEL   0,1321    INSIGNIFICANTE\\n  TRT3       9a Turma      1016        0       HÁ DIFERENÇA        1        ACEITÁVEL    0,5803         MÉDIA\\n  TRT3      10a Turma       957     0,0394     HÁ DIFERENÇA      0,747     INACEITÁVEL   0,1443    INSIGNIFICANTE\\n  TRT3      11a Turma       934        0       HÁ DIFERENÇA        1        ACEITÁVEL    0,3518       PEQUENA\\n\\n\\n\\n\\nentre as proporções. A saber, o nível de força estatística considerado aceitável é de 80%.\\n\\n\\n\\n6.5.4 TRT da 3a Região - avaliação das Turmas Recursais\\n\\n\\n         Em relação a dados individuais de cada uma das Turmas Recursais do TRT da\\n3a Região, Figura 6.18, é possível verificar que as Turmas Recursais 1a , 4a , 7a , 8a e 11a\\napresentaram proporção de deferimentos maior para empregados. Por outro lado, 6 das\\n11 Turmas Recursais apresentaram proporção de deferimentos maior para empresas. A\\nFigura 6.19 apresenta a distribuição das proporções de deferimentos das turmas recursais.\\nAlém disso, na Tabela 6.20 são apresentados os dados em relação aos testes estatísticos\\naplicados, como o P-Value, Power e Effect. Assim, é possível verificar que há diversas\\nturmas recursais que o Power está abaixo de 0,8, o que ocorre devido à pouca quantidade\\nde dados para análise, entretanto é possível superar essa limitação pela ingestão de mais\\nobservações em trabalhos futuros.\\n\\n\\n\\n6.6 Aplicação\\n\\n\\n         A presente pesquisa não necessita da realização de deployment dos modelos de-\\nsenvolvidos em nenhuma infraestrutura de processamento de dados para serem utilizados.\\nEntretanto, é importante ressaltar algumas considerações em relação a futuras utilizações\\ndos modelos desenvolvidos. Assim, ambos os modelos desenvolvidos assumem que os\\ndocumentos estejam redigidos em língua portuguesa formal, ou seja, sem erros comuns\\nde digitação. Além disso, seria interessante o monitoramento dos textos das decisões de\\nmodo à manutenção da qualidade das previsões, pois os níveis de acurácia dos modelos\\ndesenvolvidos dependem necessariamente de que os dados ingeridos estejam em níveis\\n\\x0c                                                                                    101\\n\\n\\nFigura 6.18: Porcentagem de deferimento de recursos em relação ao recorrente ser em-\\npresa e empregado das Turmas Recursais do Tribunal Regional do Trabalho da 3a Região.\\n\\n\\n\\n\\nde qualidade previstos.\\n\\n\\n\\n6.7 Limitações\\n\\n\\n       Os experimentos da presente pesquisam apresentaram certas limitações, como por\\nexemplo, a utilização do formato de redação dos documentos processados. Assim, o\\nalgoritmo de aprendizado de máquina desenvolvido levou em consideração padrões de\\nformatação e redação específicos ao corpus jurídico dos Tribunais avaliados. Além disso,\\nnão é possível afirmar com certeza que outros tribunais sigam os mesmos padrões, pois\\nnão foi realizado experimento de análise de documentos dos demais tribunais brasileiros.\\nEntretanto, essas informações contextuais dos documentos podem ser consideradas úteis\\n\\x0c102\\n\\n\\nFigura 6.19: Distribuição da porcentagem de deferimento de recursos em relação ao recor-\\nrente ser empresa e empregado das Turmas Recursais do Tribunal Regional do Trabalho\\nda 3a Região.\\n\\n\\n\\n\\npara os algoritmos, pois elas mimicam a forma como os usuários, advogados e praticantes\\nda atividade jurídica, leem os documentos.\\n       Entretanto, não era objetivo da pesquisa, em um primeiro momento, o desenvolvi-\\nmento de um algoritmo que processasse documentos de diversos formatos de redação de\\ndiversos tribunais diferentes. Desse modo, a padronização de redação dos documentos foi\\nexplorada a fim de se alcançar maior otimização do algoritmo. Por outro lado, mesmo em\\náreas devidamente estabelecidas, como a mineração de sentimentos, é possível encontrar\\nalgoritmos desenvolvidos especificamente para certos nichos, como é o caso dos micro-\\nblogs, como o Twitter, que implicam desafios particulares devido a especificidades dos\\ndocumentos encontrados (LIPPI; TORRONI, 2016).\\n       Além disso, foi realizado o processamento de acórdãos judiciais em que houve\\napenas uma das partes recorrente. Desse modo, todos os documentos em que havia a\\napreciação de mais de um recurso foram removidos da base de dados. Entretanto, foi\\nconsiderado que tal filtragem não apresentou prejuízos aos experimentos, visto que havia\\ngrande quantidade de documentos disponíveis para análise de acordo com técnicas de\\ndefinição de amostra estatística, conforme Seção 6.2.1.2.\\n       Outro fator que pode ser considerado uma limitação da pesquisa é o tamanho da\\n\\x0c                                                                                       103\\n\\n\\nbase de dados padrão-ouro desenvolvido na Seção 6.3.3. Entretanto, essa questão foi\\nmitiga por meio da aplicação de técnica de Supervisão Fraca a qual permitiu explorar a\\ngrande quantidade de documentos disponíveis para o treinamento dos modelos desenvol-\\nvidos na pesquisa, conforme Seção 6.3.5. Cabe salientar também as limitações impostas\\npelas próprias técnicas de Aprendizado de Máquinas utilizadas na pesquisa, como, por\\nexemplo, o viés ou a tendência inserida pelo algoritmo, que, para desenvolver um mo-\\ndelo, precisa realizar suposições e generalizações.\\n\\n\\n\\n6.8 Resumo do Capítulo\\n\\n\\n       Neste capítulo é apresentada a validação experimental completa da pesquisa de\\nacordo com as metodologias propostas. Assim, iniciou-se pela elucidação dos elementos\\nfundamentais do estudo que nortearam todas as fases seguintes por meio da Seção Com-\\npreensão do negócio. Nessa seção foram definidos os objetivos principais da validação\\nexperimental no contexto de negócio e de mineração de dados.\\n       Após, na Seção Compreensão dos dados, iniciou-se a execução prática da pesquisa\\npor meio da coleta dos dados da internet e da exploração inicial dos documentos obti-\\ndos. Essa fase trouxe resultados positivos para a pesquisa pois permitiu aferir a qualidade\\ndos dados como também permitiu analisar o conteúdo dos documentos. Essa análise do\\nconteúdo proporcionou inspiração positiva para o desenvolvimento de uma técnica para\\nreduzir o tamanho dos documentos, a qual foi implementada na fase seguinte da pesquisa.\\n       Já na fase da Seção Preparação dos dados houve a impressão de grande esforço\\npara a preparação da melhor maneira possível de toda base de documentos para ser utili-\\nzada na fase de modelagem de dados. Assim, primeiramente foi realizada a devida lim-\\npeza de caracteres e documentos que não atingiam a qualidade mínima para a pesquisa.\\nApós, foram aplicadas as transformações nos documentos idealizadas na fase anterior da\\npesquisa. Assim, foram extraídos apenas os dispositivos das decisões judiciais. É nos\\ndispositivos do documento que contém as features necessárias para que os algoritmos de\\nmodelagem possam classificar corretamente as instâncias.\\n       Ainda na fase de preparação dos dados, na Seção 6.3.3, houve a criação da base de\\ndocumentos padrão-ouro, a qual foi desenvolvida não apenas com esforço do autor, como\\ntambém de duas pessoas bacharéis em Direito. Dessa maneira, a base foi utilizada para a\\nrealização de testes dos modelos de Aprendizado de Máquina Supervisionado desenvol-\\nvidos, como também para análise exploratório dos documentos, mas neste caso, fazendo\\n\\x0c104\\n\\n\\na análise cruzada com os rótulos das instâncias. Essa análise permitiu-se inferir featu-\\nres que viabilizaram a criação de Funções de Rotulação utilizando o Snorkel Framework\\npara aplicação de técnica de Supervisão Fraca, para criar uma base de documentos para\\ntreinamento muito maior do que a base padrão-ouro.\\n       Na sequência, a Seção Modelagem apresenta a execução de quatro experimentos\\nde modelagem de dados por meio de algoritmos de Aprendizado de Máquina Supervisio-\\nnado. Assim, primeiramente foram avaliados diversos algoritmos para o desenvolvimento\\nde um modelo para realizar a classificação dos documentos em relação ao tipo de parte\\nrequerente no processo, sendo ela empregado ou empresa. Nesse caso, o algoritmo que\\napresentou a melhor performance e foi escolhido foi o Support Vector Machine (SVM).\\nEm relação aos outros três experimentos realizados nessa seção, em ambos foram avalia-\\ndos diversos algoritmos para o desenvolvimento de um modelo para realizar a classifica-\\nção dos documentos em relação ao deferimento ou não do recurso impetrado. Entretanto,\\no que diferencia é a base de documentos utilizada. Desse modo, no segundo experimento\\nos algoritmos foram treinados utilizando a base de dados padrão-ouro a qual continha\\n1.000 instâncias para treinamento, mas as suas classes estavam muito desbalanceadas.\\nNo terceiro experimento foi avaliado o treinamento dos mesmos algoritmos utilizando a\\nbase de documentos criada automaticamente contendo 1.644 instâncias, mas nesse caso\\ntotalmente balanceada. Por último, foi realizado experimento de treinamento utilizando\\na base de documentos criada automaticamente contendo a totalidade das instâncias ano-\\ntadas de 22.471, mas nesse caso muito desbalanceada para uma das classes. Enfim, foi\\nrealizada a avaliação técnica dos modelos desenvolvidos e selecionado o modelo criado\\ncom o algoritmo Gradient Boosting para a classificação efetiva dos documentos.\\n       Por fim, na Seção Avaliação de resultados, foi realizada a classificação de 22.946\\ndocumentos com os modelos desenvolvidos, foram aplicados os testes estatísticos de\\nacordo com a metodologia escolhida e por fim foram gerados diversos gráficos demons-\\ntrando as proporções de julgamentos encontrados na amostra selecionada. Enfim, foi\\npossível identificar diferença estatística em ambos os tribunais com proporção maior de\\njulgamentos para empregados, por outro lado, também foi observado que há turmas recur-\\nsais que divergem da média geral de cada tribunal apresentando, assim, proporção maior\\nde julgamentos para empresas. Também é possível verificar na Seção 6.7 o conjunto de\\nlimitações encontradas para a presente pesquisa de maneira detalhada.\\n\\x0c                                                                                       105\\n\\n\\n7 DISCUSSÃO DE RESULTADOS\\n\\n\\n       A presente pesquisa desenvolveu processo de Ciência de Dados para a classifica-\\nção automática de decisões judiciais em relação ao beneficiário do julgamento ser em-\\npregado ou empresa de modo a quantificar a proporção de julgamentos favorável a cada\\nparte. Assim, foi possível responder a questão de pesquisa: Seria possível que os tri-\\nbunais avaliados e suas turmas recursais julguem favoravelmente proporção signifi-\\ncativamente maior de recursos para uma das partes do que para outra em média?\\nEnfim, foi possível verificar diferença de proporção estatística significante em relação ao\\nTribunal Regional do Trabalho da 3 e 4a Região. Cabe ressaltar que a diferença de pro-\\nporção encontrada nos dados do TRT da 4a Região foi de 12% a mais para empregados e,\\nnos dados do TRT da 3a Região, a diferença foi de 2% a mais para empregados.\\n       Por outro lado, os dados sugerem haver também diferenças estatísticas de propor-\\nção se forem analisadas individualmente as Turmas Recursais que compõem cada tribu-\\nnal. Em relação ao TRT da 4a Região, é possível verificar que 6 das 11 Turmas Recursais\\nacompanham a média geral do tribunal tendo maior proporção de julgados favoráveis a\\nempregados, sendo que a 2a , 3a e 8a Turmas Recursais apresentam mais de 2 desvios pa-\\ndrão de diferença. Por outro lado, em relação ao TRT da 3a Região, também é possível\\nverificar diferenças estatísticas de proporção. Entretanto, neste caso, menos da metade\\ndas Turmas Recursais acompanharam a média geral do tribunal. Assim, 5 das 11 Turmas\\nRecursais apresentaram proporção de deferimentos maior para empregados, tendo 3 delas\\ndiferença maior que 2 desvios-padrão. Em contrapartida, 6 das 11 Turmas Recursais apre-\\nsentaram proporção de deferimentos maior para empresas, tendo apenas 1 delas diferença\\nmaior que 3 desvios-padrão.\\n       Enfim, as médias gerais dos tribunais analisados e também as médias especificas\\nde diversas Turmas Recursais contribuíram para suportar a hipótese levantada de que há\\nórgãos judiciais que julgam proporção consideravelmente maior para uma das partes do\\nque para outra. Desse modo, a quantidade de dados extraídos em relação aos tribunais\\ncomo um todo se mostrou satisfatória para alcançar o nível de força desejado de 80%.\\nEntretanto, em relação às Turmas Recursais individualmente, menos da metade das aná-\\nlises obtiveram nível de força abaixo de 80%, como é possível ser observado pela Tabela\\n6.19 e 6.20, constando, assim, como uma limitação da presente pesquisa.\\n       Além da análise quantitativa das decisões judiciais processadas automaticamente,\\ntambém foi realizado experimento para avaliar a efetividade de técnica de Supervisão\\n\\x0c106\\n\\n\\nFraca de modo a aumentar a quantidade de documentos anotados utilizados no treina-\\nmento dos modelos de Aprendizado de Máquina. Assim, a técnica se mostrou satisfató-\\nria, pois permitiu a anotação automática de mais de 22 mil documentos, ou seja, aumen-\\ntando a base de treinamento em mais de 22 vezes. O presente resultado foi alcançado\\nconsiderando que os magistrados empregam no dia-a-dia estilo de escrita padronizado e\\npreferencialmente as mesmas palavras-chave em certos trechos dos documentos, ou, até\\nmesmo, reutilizam modelos de documentos alterando apenas nomes de pessoas sendo pro-\\ncessadas por exemplo. Por um lado, essa característica específica da base de documentos\\nprocessada pode ser considerada positiva, pois permitiu a construção rápida de funções\\nde rotulação as quais possibilitaram a anotação automática da base de documentos para\\ntreinamento. Entretanto, por outro lado, essa característica de padronização dos docu-\\nmentos pode imprimir desafios, pois muitas das instâncias anotadas automaticamente não\\napresentam grande variação de features o que pode impactar determinados algoritmos.\\n\\x0c                                                                                     107\\n\\n\\n8 CONCLUSÕES\\n\\n\\n       Esta pesquisa teve por objetivo principal utilizar métodos computacionais automá-\\nticos para responder a questão de pesquisa se Seria possível que os tribunais avaliados e\\nsuas turmas recursais julguem favoravelmente proporção significativamente maior\\nde recursos para uma das partes do que para outra em média? Assim, foi executada\\npesquisa de descoberta de conhecimento em base de dados de acordo com a metodologia\\nCrisp-dm (CHAPMAN et al., 2000) que incluiu o processamento por meio de Algoritmo\\nde Aprendizado de Máquina e PLN de mais de 20 mil decisões judiciais de modo a re-\\nalizar estudo quantitativo e estatístico da base de decisões. Os resultados indicaram que\\nrealmente há tribunais e turmas recursais que apresentam diferença significante de pro-\\nporção de julgamentos favorável para empregados e empresas e vice-versa.\\n       Além disso, também foram atingidos os objetivos específicos que constituíam na\\nanálise exploratória dos documentos coletadas na Web, o que resultou em conhecimento\\nsobre a frequência das palavras utilizadas pelos magistrados, como também no conheci-\\nmento sobre a padronização dos documentos. Igualmente foi desenvolvida base padrão-\\nouro para treinamento de algoritmos de Aprendizado de Máquina o que pode ser consi-\\nderado um dos produtos da pesquisa.\\n       Por outro lado, foi realizada também a experimentação da utilização de técnica de\\nSupervisão Fraca para o desenvolvimento de base de treinamento criada automaticamente\\npor meio da expansão dos dados, a qual apresentou resultados satisfatórios. Além disso,\\ncomo trabalho futuro poderia ser considerada a elaboração de funções de rotulação que\\nsejam mais flexíveis as palavras-chave utilizadas para classificar os documentos. Nesse\\ncaso, poderiam ser utilizadas Embeddings de modo a localizar expressões semelhantes\\nàs utilizadas na presente pesquisa para classificar documentos. Entretanto, considera-se\\nsatisfatório o experimento pois preencheu uma lacuna dos trabalhos relacionados pois\\nnão havia sido encontrado nenhum experimento utilizando técnica de Supervisão Fraca\\naplicada a documentos jurídicos até o momento.\\n       De modo a permitir uma análise mais aprofundada e confiável dos resultados,\\npropõe-se como sugestão que estudos futuros obtenham mais dados na fase de extração\\nda amostra de documentos para considerar também a proporção de julgamento em relação\\na cada turma recursal, como também cada magistrado na função de relator. Essa conside-\\nração poderia permitir análises segmentadas por magistrado na função de relator de modo\\na viabilizar a análise da seguinte hipótese: Relatores diferentes (dentro de uma mesma\\n\\x0c108\\n\\n\\nturma recursal) influenciam a proporção de julgamentos favoráveis a cada uma das\\npartes, ou seja, há correlação entre o relator e a proporção de julgamentos de uma\\nturma recursal.\\n           Enfim, a presente pesquisa buscou trazer novos dados a discussões presentes na\\nsociedade sobre a questão do viés na Justiça, principalmente, na Justiça do Trabalho.\\nAssim, considerando que a pesquisa de Salama, Carlotti e Yeung (2018) encontrou resul-\\ntados que sugerem que, a nível de primeiro grau de jurisdição na Justiça do Trabalho, há\\numa proporção muito maior de julgamentos favoráveis a empregados, os dados da pre-\\nsente pesquisa sugerem a confirmação dessa proporção a nível de segundo grau, apesar de\\nhaver algumas turmas recursais que realizam a correção dessa distorção. A fim de facilitar\\na reprodução da pesquisa, foi disponibilizado online na plataforma Github o código-fonte\\ndo projeto1 .\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "136419"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = len(txt)\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEXT:\n",
      "\n",
      "4 METODOLOGIA\n",
      "\n",
      "\n",
      "          A presente pesquisa adotou a metodologia CRISP-DM Guide 1.0 (CHAPMAN\n",
      "et al., 2000) para validação experimental, assim, considerou-se interessante apresentar\n",
      "a seguir os pontos-chave dessa metodologia. Além disso, devido à utilização de testes\n",
      "estatísticos em alguns experimentos, também se considerou interessante apresentar os\n",
      "pontos-chave da metodologia adotada apresentada no trabalho de Snijders (2002).\n",
      "\n",
      "\n",
      "\n",
      "4.1 Processo de descoberta de conhecimento em base de dados\n",
      "\n",
      "\n",
      "          Este trabalho segue a abordagem metodológica descrita em CRISP-DM Guide 1.0\n",
      "(CHAPMAN et al., 2000) para a descoberta de conhecimento em base de dados que é\n",
      "utilizada para extrair conhecimento útil de grandes coleções de dados. Essa metodologia\n",
      "apresenta um processo iterativo composto de diversas fases, que compõe desde a compre-\n",
      "ensão e as necessidades de negócio até a modelagem dos dados e sua aplicação, as quais\n",
      "são descritas em mais detalhes nas seções seguintes. A Figura 4.1 apresenta o ciclo do\n",
      "processo.\n",
      "\n",
      "\n",
      "\n",
      "Figura 4.1: Ciclo de desenvolvimento do processo metodológico CRISP-DM Guide 1.0.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Adaptado de Chapman et al. (2000)\n",
      "\f46\n",
      "\n",
      "\n",
      "4.1.1 Compreensão do Negócio\n",
      "\n",
      "\n",
      "        Essa fase consiste em compreender o valor do conhecimento a ser gerado pela\n",
      "perspectiva do negócio, de modo a alinhar o projeto com os objetivos estratégicos da\n",
      "organização. Assim, esse estágio compreende a análise do contexto em que o negócio\n",
      "se encontra inserido de modo a compreender o que o cliente realmente necessita e seu\n",
      "objetivo principal. Essa análise vai guiar todas as fases do processo de descoberta de\n",
      "conhecimento, pois são definidos pontos fundamentais, como, por exemplo, o objetivo de\n",
      "mineração. Esse estágio é essencial pois uma possível definição incorreta dos problemas\n",
      "de negócio levaria a pesquisa invariavelmente a trazer resultados inúteis. A seguir são\n",
      "apresentados os principais elementos que compõem essa fase:\n",
      "\n",
      "\n",
      "     • Objetivos de negócio: compreensão do contexto em relação ao mercado em que o\n",
      "       negócio se encontra; definição dos objetivos do negócio em relação ao projeto de\n",
      "       descoberta de conhecimento em base de dados; definição de critérios de sucesso do\n",
      "       projeto.\n",
      "     • Recursos do projeto: inclui inventário de recursos disponíveis para a realização do\n",
      "       projeto; listagem de requisitos e restrições que podem haver, como, por exemplo,\n",
      "       data limite para realização, níveis de qualidade, segurança e disposições legais em\n",
      "       relação aos dados; além de análise da relação custo-benefício esperado obter com o\n",
      "       projeto.\n",
      "     • Objetivo de mineração: definição clara do objetivo de mineração é um passo fun-\n",
      "       damental no processo que permite a execução satisfatória da pesquisa, além dos\n",
      "       critérios de sucesso os quais vão permitir a verificação da eficiência dos modelos\n",
      "       desenvolvidos.\n",
      "     • Planejamento do Projeto: inclui a listagem dos passos necessários para alcançar os\n",
      "       objetivos, como também lista de ferramentas necessárias para a execução e prazos\n",
      "       de execução.\n",
      "\n",
      "\n",
      "\n",
      "4.1.2 Compreensão dos dados\n",
      "\n",
      "\n",
      "        Inicia com a coleta dos dados e com a exploração inicial, o que permite a iden-\n",
      "tificação de problemas de qualidade e a aferição de conhecimentos estatísticos sobre a\n",
      "massa de dados. Essa fase pode identificar se realmente os dados podem responder às\n",
      "\f                                                                                         47\n",
      "\n",
      "\n",
      "perguntas do negócio e identificar as variáveis significativas. A seguir são apresentados\n",
      "os principais elementos que compõem essa fase:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "   • Coleta de dados: inclui a extração de dados iniciais ao projeto e a sua descrição\n",
      "      de modo que seja especificada sua localização, técnica utilizada para extração e\n",
      "      resolução de problemas encontrados.\n",
      "   • Descrição dos dados: inclui análise dos dados de maneira a especificar os tipos de\n",
      "      dados disponíveis, seu formato e quantidade. Também permite inferir se os dados\n",
      "      disponíveis satisfazem aos requisitos especificados.\n",
      "   • Exploração dos dados: análise da maneira como os dados estão distribuídos no\n",
      "      banco de dados e de seus relacionamentos por meio da apresentação de gráficos e\n",
      "      relatórios.\n",
      "   • Qualidade: verificação da qualidade dos dados extraídos por meio da verificação de\n",
      "      possíveis erros na extração, além verificação se há valores que estejam faltando em\n",
      "      determinados campos.\n",
      "\n",
      "\n",
      "\n",
      "4.1.3 Preparação dos dados\n",
      "\n",
      "\n",
      "       O objetivo é o pré-processamento dos dados para torná-los relevantes e consisten-\n",
      "tes com respeito à tarefa de busca de conhecimento. Essa fase é extremamente necessá-\n",
      "ria, pois os dados muitas vezes podem estar incompletos, inconsistentes ou podem, até\n",
      "mesmo, conter erros. A seguir são apresentados os principais elementos que compõem\n",
      "essa fase:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "   • Seleção e integração dos dados: se os dados estiverem distribuídos em diversas\n",
      "      bases, será necessário realizar procedimentos para uni-los de modo a permitir pos-\n",
      "      teriormente a seleção das melhores observações coletadas para análise e processa-\n",
      "      mento.\n",
      "   • Limpeza dos dados: realizar o tratamento dos dados de modo a remover dados ou\n",
      "      caracteres que podem reduzir os níveis de acurácia de certos modelos utilizados.\n",
      "   • Construção e formatação dos dados: certas técnicas de modelagem exigem que os\n",
      "      dados estejam em determinado formato para a sua correta utilização.\n",
      "\f48\n",
      "\n",
      "\n",
      "4.1.4 Modelagem\n",
      "\n",
      "\n",
      "         Consiste na tarefa de escolha de métodos e parametrização para a extração de\n",
      "padrões, classificação, segmentação, regressão ou associação de itens, os quais gerarão\n",
      "novos conhecimentos sobre a importância de cada uma das variáveis em função do re-\n",
      "sultado esperado. A seguir são apresentados os principais elementos que compõem essa\n",
      "fase:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "     • Escolha da técnica de modelagem: Análise e escolha da melhor técnica de modela-\n",
      "        gem que se aplique ao caso.\n",
      "     • Testes: desenvolver uma técnica que permita a realização da avaliação do modelo\n",
      "        após a sua construção. Muitas vezes, é construída uma base de dados anotada no\n",
      "        estágio anterior de modo que seja possível separar uma parte para testes.\n",
      "     • Construção do modelo: referente ao desenvolvimento do modelo por meio de técni-\n",
      "        cas de treinamento por aprendizado de máquina, por exemplo, incluindo a escolha\n",
      "        de parâmetros.\n",
      "     • Avaliação técnica: consiste em analisar o modelo construído em função de diversos\n",
      "        parâmetros em busca da melhor combinação possível.\n",
      "\n",
      "\n",
      "\n",
      "4.1.5 Avaliação\n",
      "\n",
      "\n",
      "         Fase em que os padrões reconhecidos, regras de associação e todo conhecimento\n",
      "gerado é analisado para verificação da sua real utilidade. Podem ser utilizadas medidas\n",
      "estatísticas, como também visualizações, para ajudar a perceber a utilidade dos dados. A\n",
      "seguir são apresentados os principais elementos que compõem essa fase:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "     • Análise de resultados: diferentemente da avaliação técnica do modelo, neste caso\n",
      "        o importante é avaliar se o modelo atende aos requisitos de negócio, desse modo, é\n",
      "        possível testar o modelo em um protótipo de aplicação real com usuários finais, por\n",
      "        exemplo.\n",
      "     • Revisão e próximos passos: análise de todas as atividades realizadas e sua eficácia,\n",
      "        além de descrever futuras ações.\n",
      "\f                                                                                         49\n",
      "\n",
      "\n",
      "4.1.6 Aplicação\n",
      "\n",
      "\n",
      "       Consiste na consolidação de todo processo na forma de relatório e publicação do\n",
      "conhecimento ou na incorporação da modelagem a um sistema computacional. A seguir\n",
      "são apresentados os principais elementos que compõem essa fase:\n",
      "\n",
      "\n",
      "   • Plano de implementação: certos casos exigem que os dados sejam transformados\n",
      "      antes de serem processados por um modelo, assim, todo o processo precisa ser\n",
      "      documentado.\n",
      "   • Plano de monitoramento: pode ser necessário a verificação da qualidade dos dados\n",
      "      recebidos em um fluxo de processamento para alimentação de um modelo de dados.\n",
      "   • Relatório final e revisão: sumário de todo o projeto incluindo uma apresentação\n",
      "      final para os clientes.\n",
      "\n",
      "\n",
      "\n",
      "4.2 Teste de hipótese estatística\n",
      "\n",
      "\n",
      "       A presente pesquisa busca realizar análise quantitativa em relação à proporção\n",
      "de acórdãos julgados favoravelmente para as partes empregado e empresa de modo a\n",
      "responder à hipótese levantada na Seção 6.1.1. Assim, de modo a aferir se realmente\n",
      "existe diferença estatística entre as proporções obtidas, julga-se necessária a aplicação de\n",
      "testes estatísticos, como também o cálculo do nível de força e efeito.\n",
      "       O teste de hipótese estatística desenvolvido neste trabalho segue a proposta de me-\n",
      "todologia descrita por SNIJDERS no trabalho Snijders (2002). De modo geral, o pesqui-\n",
      "sador define uma questão de pesquisa cuja resposta tem por base a análise de propriedades\n",
      "de um conjunto de observações obtidas a partir de um processo estocástico representado\n",
      "por meio de uma distribuição estatística, ou seja, dados quantitativos. Assim, dados são\n",
      "coletadas e resumidos de acordo com as propriedades sendo analisadas, que podem ser,\n",
      "por exemplo, valores médios para distribuições contínuas ou proporções para distribui-\n",
      "ções binomiais. Após, a questão de pesquisa é reescrita de forma a considerar a existên-\n",
      "cia ou não de um efeito que pode ser observado considerando a propriedade medida por\n",
      "meio da comparação desse valor com outro valor específico ou com a mesma propriedade\n",
      "observada de outro grupo estatístico.\n",
      "       Desse modo, é definida a hipótese nula a qual verifica a inexistência de efeito, ou\n",
      "seja, que não há diferença nas observações em relação às propriedades em análise. Já em\n",
      "\f50\n",
      "\n",
      "\n",
      "relação à comparação entre dois grupos, a hipótese nula pode implicar a verificação da\n",
      "igualdade da propriedade entre dois grupos. Além disso, também é definida a hipótese\n",
      "alternativa a qual define a existência de algum efeito ou define a existência de diferença\n",
      "entre grupos em relação a propriedade sendo analisada. Ao mesmo tempo, é necessário\n",
      "definir o nível de significância que deve ser usado para comparar com o resultado do teste\n",
      "estatístico aplicado, normalmente definido como 5%.\n",
      "        Assim, o teste estatístico a ser escolhido computa os dados e apresenta a estatística\n",
      "do teste e o P-value. A estatística do teste apresenta o quanto os dados diferem da hipótese\n",
      "nula de acordo com a distribuição normal. Já o P-value apresenta a probabilidade de obter\n",
      "os dados analisados se a hipótese nula é na verdade verdadeira na população. A fins de\n",
      "interpretação de resultados, optou-se por usar o P-value nesta pesquisa em vista da sua\n",
      "objetividade, pois a interpretação depende da comparação do P-value com o nível de\n",
      "significância definido previamente. Se o P-value for menor que o nível de significância,\n",
      "rejeita-se a hipótese nula. Se o P-value for maior, há falha em rejeitar a hipótese nula.\n",
      "        Ademais, o teste estatístico a ser aplicado varia de acordo com o tipo de distribui-\n",
      "ção de dados e do tipo de propriedade da distribuição sendo analisada. Testes conhecidos\n",
      "como paramétricos basicamente assumem que a distribuição dos dados segue padrões de\n",
      "normalidade. Já os testes conhecidos como não-paramétricos não assumem que os dados\n",
      "seguem padrões de normalidade. Em relação aos testes paramétricos, existem testes de\n",
      "correlação que verificam o relacionamento entre variáveis sem a noção de causa e efeito,\n",
      "testes de regressão que verificam o relacionamento entre variáveis incluindo a noção de\n",
      "causa e efeito e testes de comparação que verificam a diferença entre médias e proporções.\n",
      "        Após a escolha do teste estatístico, é necessário verificar se as condições de vali-\n",
      "dade do teste estão satisfeitas em relação aos dados da amostra. Assim, por exemplo, o\n",
      "teste estatístico que realiza a comparação entre proporções de duas distribuições binomi-\n",
      "ais necessita que as seguintes suposições estejam satisfeitas:\n",
      "\n",
      "\n",
      "     • Amostra deve conter observações extraídas aleatoriamente com probabilidades\n",
      "       iguais.\n",
      "     • As observações devem ser independentes.\n",
      "     • n1 ∗ p1 ≥ 5 e n1 ∗ (1 − p1) ≥ 5, sendo n1 = quantidade de observações no grupo\n",
      "       1, p1 = proporção no grupo 1.\n",
      "\n",
      "\n",
      "        Por fim, o teste estatístico é aplicado e o P-value é comparado com o nível de\n",
      "significância definido previamente. Além disso, é necessário apresentar a conclusão do\n",
      "\f                                                                                     51\n",
      "\n",
      "\n",
      "teste informando a rejeição da hipótese nula ou falha da sua rejeição, como também, a\n",
      "interpretação dos resultados em relação aos objetivos de negócio estabelecidos.\n",
      "\n",
      "\n",
      "\n",
      "4.3 Resumo do Capítulo\n",
      "\n",
      "\n",
      "       Neste capítulo, iniciou-se apresentando a contextualização metodológica da pes-\n",
      "quisa. Após, foi apresentada a metodologia base utilizada para desenvolvimento de todo o\n",
      "processo de validação experimental. Em função do carácter eminentemente prático do es-\n",
      "tudo, optou-se pela metodologia CRISP-DM Guide 1.0 (CHAPMAN et al., 2000), a qual\n",
      "apresenta-se amplamente difundida na área profissional. Por outro lado, em vista de que\n",
      "a validação experimental inclui análise quantitativa de dados e análise de proporções de\n",
      "distribuições, optou-se por utilizar também metodologia de pesquisa estatística Snijders\n",
      "(2002) para esta fase dos experimentos.\n",
      "\f52\n",
      "\n",
      "\n",
      "5 MATERIAIS E MÉTODOS\n",
      "\n",
      "\n",
      "       Neste capítulo é apresentada visão geral da pesquisa por meio da classificação\n",
      "taxonômica e também por meio da descrição do método de validação experimental.\n",
      "\n",
      "\n",
      "\n",
      "5.1 Classificação da pesquisa\n",
      "\n",
      "\n",
      "       A seguir é realizada a classificação da presente pesquisa de acordo com a taxono-\n",
      "mia descrita em Wazlawick (2017). Por se tratar de um tema recente e seus resultados\n",
      "dependerem da aplicação prática de técnicas de mineração de texto no contexto de do-\n",
      "cumentos jurídicos, este trabalho pode ser classificado como uma pesquisa de natureza\n",
      "aplicada, pois busca desenvolver conhecimento que pode ser utilizado para aprimorar\n",
      "processo de tomada de decisões em empresas e em escritórios de advocacia.\n",
      "       Os objetivos do trabalho o caracterizam como uma pesquisa descritiva, uma vez\n",
      "que os documentos jurídicos são classificados para realização de análise quantitativa.\n",
      "       Em relação aos procedimentos técnicos, foi adotada a pesquisa experimental para\n",
      "alcançar o propósito do trabalho, coletando dados de fontes públicas de sites governamen-\n",
      "tais e desenvolvimento de modelos de aprendizado de máquina. Quanto à abordagem, foi\n",
      "realizada pesquisa quantitativa em relação aos dados classificados por meio dos modelos\n",
      "de Aprendizado de Máquina.\n",
      "       A avaliação dos resultados da pesquisa quantitativa foi feita por meio de testes\n",
      "estatísticos de significância que permitem a avaliação dos resultados.\n",
      "       Na Tabela 5.1 é possível observar resumo da classificação da pesquisa desenvol-\n",
      "vida com base na taxonomia descrita em Wazlawick (2017).\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "             Tabela 5.1: Resumo da classificação metodológica da pesquisa.\n",
      "     Tipo        Classificação                                   Justificativa\n",
      " Natureza        Aplicada        Aprimoramento do processo de tomada de decisões.\n",
      " Objetivos       Descritiva      Descrição de tendência estatística de julgamento.\n",
      " Procedimentos   Experimental    Coleta de dados, classificação, análise e resposta à hipótese estatística.\n",
      " Abordagem       Quantitativa    Classificação dos dados por meio de modelo de Aprendizado de Máquina.\n",
      "\f                                                                                          53\n",
      "\n",
      "\n",
      "5.2 Método de Validação Experimental\n",
      "\n",
      "\n",
      "       A execução dos experimentos foi realizada utilizando a metodologia descrita em\n",
      "CRISP-DM Guide 1.0 (CHAPMAN et al., 2000) a qual apresenta um método iterativo\n",
      "composto de diversas fases cujo objetivo é alinhar o processo de Mineração de Dados às\n",
      "expectativas do negócio. Por outro lado, essa mesma metodologia prevê o retorno a fases\n",
      "iniciais de modo a alinhar os requisitos e objetivos de pesquisa de acordo com conheci-\n",
      "mento novo obtido nas fases de execução de experimentos. Isso se deve principalmente\n",
      "à natureza da pesquisa de Mineração de Dados que busca extrair conhecimento oculto de\n",
      "uma base de documentos. Desse modo, a seguir será apresentado o resumo do método se-\n",
      "quencial de execução da validação experimental após a execução iterativa da metodologia\n",
      "descrita no Capítulo 4.\n",
      "       Assim, primeiramente foi definida a questão de pesquisa como Seria possível que\n",
      "os tribunais avaliados e suas turmas recursais julguem favoravelmente proporção\n",
      "significativamente maior de recursos para uma das partes do que para outra em mé-\n",
      "dia? A seguir, foi definido que seria utilizado teste estatístico para verificação da questão\n",
      "de pesquisa. Então, foi definido como hipótese estatística o seguinte: Os tribunais ava-\n",
      "liados e suas turmas recursais julgam favoravelmente proporção significativamente\n",
      "maior de recursos para uma das partes do que para outra em média. Assim, definiu-\n",
      "se como Pa a proporção de recursos de empregados deferidos e Pb a proporção de recursos\n",
      "de empresas deferidos. Então, foi definida como hipótese nula H0 Pa = Pb. Já a hipótese\n",
      "alternativa como Pa 6= Pb. A seguir, é apresentado resumo do teste de hipótese estatística:\n",
      "\n",
      "\n",
      "   • Pa = proporção de recursos de empregados deferidos.\n",
      "   • Pb = proporção de recursos de empresas deferidos.\n",
      "   • H0: Pa = Pb.\n",
      "   • Ha: Pa 6= Pb.\n",
      "\n",
      "\n",
      "       De modo a realizar a análise quantitativa das proporções de julgados favoráveis às\n",
      "partes empregados e empresas era necessário obter instâncias de observações contendo es-\n",
      "sas informações. Assim, procedeu-se ao desenvolvimento da base de dados pela utilização\n",
      "de técnicas de Mineração de Dados. Portanto, foi definido como objetivo de Mineração de\n",
      "Dados classificar automaticamente acórdãos judiciais em relação ao deferimento ou\n",
      "não e classificar automaticamente o requerente do recurso em relação a ser empresa\n",
      "ou a ser empregado. Além disso, classificar com os modelos desenvolvidos quanti-\n",
      "\f54\n",
      "\n",
      "\n",
      "dade significante de decisões judiciais e apresentar relatórios contendo as proporções\n",
      "de julgados positivamente para cada uma das partes.\n",
      "             A seguir, passou a execução do processo de Mineração de Dados o qual compre-\n",
      "ende as seguintes fases: Coleta de Dados, que inclui a extração dos documentos da inter-\n",
      "net; Preparação dos Dados, que inclui a limpeza dos dados, a anotação manual e anotação\n",
      "automática das bases de dados extraídas; Modelagem que inclui o desenvolvimento de\n",
      "modelos de Aprendizado de Máquina para a classificação automática das instâncias pre-\n",
      "paradas na fase anterior; Aplicação que inclui a efetiva classificação das instâncias, análise\n",
      "quantitativa, aplicação de testes estatísticos e desenvolvimento de gráficos. A Figura 5.1\n",
      "apresenta ilustração explicativa do pipeline da Validação Experimental da pesquisa. Nas\n",
      "seções seguintes são apresentados pontos-chave das fases do processo de Mineração de\n",
      "Dados. Além disso, foi disponibilizado também por meio do repositório1 o código-fonte\n",
      "de todo processamento da pesquisa, que pode ser usado para consulta dos detalhes de\n",
      "implementação e reprodução dos experimentos.\n",
      "\n",
      "\n",
      "\n",
      "5.2.1 Coleta dos Dados\n",
      "\n",
      "\n",
      "             Os documentos judiciais que contém a informação sobre o julgamento de deter-\n",
      "minado processo judicial são chamados de acórdãos, o quais são disponibilizados via in-\n",
      "ternet. Esses documentos contêm informação quanto ao vencedor da causa. Assim, esses\n",
      "documentos são as instâncias que precisam ser coletadas e processadas na fase seguinte\n",
      "da Mineração de Dados. Assim, foi definido que seriam analisados quantitativamente\n",
      "acórdãos de dois tribunais diferentes, a saber Tribunal Regional do Trabalho da 3a Região\n",
      "e Tribunal Regional do Trabalho da 4a Região.\n",
      "             Os documentos do TRT da 3a Região foram extraídos a partir do site <http:\n",
      "//lexml.gov.br/> por meio dos arquivos sitemap.xml na raiz do site. Quanto ao site\n",
      "<http://trt4.jus.br/>, foi utilizada a página de busca disponibilizada que permite a filtra-\n",
      "gem de documentos por meio de palavras-chave. Assim, foram desenvolvidos robôs de\n",
      "extração de dados utilizando a linguagem Python e a biblioteca Scrapy2 . Na época da exe-\n",
      "cução dos experimentos estavam disponibilizados nas páginas os montantes de acórdãos\n",
      "descritos na Tabela 6.2, essa tabela também apresenta a quantidade extraída efetivamente\n",
      "pelos robôs de extração. Diversas requisições HTTP foram negadas pelos servidores o\n",
      "\n",
      "     1\n",
      "         <https://github.com/rhuanbarros/jurimetria_justica_do_trabalho>\n",
      "     2\n",
      "         <https://scrapy.org/>\n",
      "\f                                                                                       55\n",
      "\n",
      "\n",
      "Figura 5.1: Ilustração explicativa do pipeline da Validação Experimental da pesquisa in-\n",
      "cluindo visão geral do processo.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "que resultou na impossibilidade de extração de alguns documentos.\n",
      "\n",
      "\n",
      "\n",
      "5.2.2 Preparação dos Dados\n",
      "\n",
      "\n",
      "           A Preparação dos Dados consiste em realizar ajustes para a utilização dos dados\n",
      "por algoritmos de Aprendizado de Máquina. Assim, primeiramente é realizada uma lim-\n",
      "peza para a remoção de instâncias que apresentem mensagens de erro ou que contenham\n",
      "caracteres truncados. Portanto foi aplicado um filtro que removeu todas as instâncias com\n",
      "menos de 150 palavras. Importante salientar que a tokenização foi realizada utilizando\n",
      "algoritmo que processa características específicas da língua portuguesa disponibilizado\n",
      "no repositório da pesquisa3 .\n",
      "           Após a limpeza, passou-se a transformação dos dados. Primeiramente foram ex-\n",
      "traídos dados dos documentos por meio de expressões regulares o quais foram inseridos\n",
      "   3\n",
      "       <https://github.com/rhuanbarros/jurimetria_justica_do_trabalho>\n",
      "\f56\n",
      "\n",
      "\n",
      "na base de dados como metadados. O código-fonte Python e Regex pode ser encontrado\n",
      "no repositório da pesquisa. Também foi realizada a extração de uma seção dos docu-\n",
      "mentos de texto chamada Dispositivo. Essa seção contém informação suficiente para que\n",
      "os algoritmos de Aprendizado de Máquina extraiam features e classifiquem corretamente\n",
      "as instâncias. Além disso, todos os documentos mais de um recorrente também foram\n",
      "removidos. Nesse ponto dos experimentos, a base de dados contém os metadados extraí-\n",
      "dos juntamente com o dispositivo dos acórdãos e apenas decisões onde houve apenas um\n",
      "recorrente, resultando o total de 22.946 instâncias.\n",
      "       A seguir, prosseguiu-se a criação das bases de dados anotadas para utilização com\n",
      "os algoritmos de Aprendizado de Máquina. Como o objetivo de Mineração de Dados\n",
      "exige a realização de dois tipos de classificações, são necessárias duas bases de treina-\n",
      "mento, uma que viabilize a classificação em relação ao tipo de recorrente e outra em\n",
      "relação ao deferimento ou não da causa judicial.\n",
      "       A criação da base de dados para classificação em relação ao tipo de recorrente foi\n",
      "realizada por meio da extração aleatória de 270 instâncias de cada um dos tribunais em\n",
      "formato CSV, totalizando 540 observações. Essas anotações foram realizadas exclusiva-\n",
      "mente pelo próprio autor apenas, pois tal tarefa não exige nenhum conhecimento especí-\n",
      "fico relacionado ao Direito. Os rótulos aplicados foram os seguintes: RECLAMANTE ou\n",
      "RECLAMADA.\n",
      "       Após, passou-se a criação de uma base de dados padrão-ouro utilizada para classi-\n",
      "ficação em relação ao deferimento ou não da causa. Essa base foi utilizada para realização\n",
      "de experimentos de modelagem de Algoritmo de Aprendizado de Máquina como também\n",
      "foi utilizada para testes de eficácia dos modelos desenvolvidos. Essa fase foi desenvol-\n",
      "vida seguindo critérios rigorosos de qualidade de acordo com a metodologia descrita em\n",
      "(PUSTEJOVSKY; STUBBS, 2012). Foram selecionadas aleatoriamente 1.000 instân-\n",
      "cias da base de dados preparada anteriormente que foram anotadas pelo próprio autor da\n",
      "pesquisa, o qual detém conhecimentos jurídicos suficientes para esta tarefa. Além disso,\n",
      "dessas 1.000, 500 foram anotadas também por uma pessoa bacharel em Direito e as outras\n",
      "500 também foram anotadas por uma pessoa bacharel em Direito. Resultando assim, em\n",
      "1.000 instâncias anotadas por duas pessoas. Importante considerar que foram utilizadas\n",
      "para anotação apenas a parte do Dispositivo dos acórdãos. Os rótulos aplicados foram os\n",
      "seguintes: DEFERIMENTO, INDEFERIMENTO ou SEM_ANALISE_MERITO.\n",
      "       Também foi realizada a anotação automática da base de documentos por meio de\n",
      "técnica de Supervisão Fraca utilizando o Framework Snorkel. Foram desenvolvidas 13\n",
      "\f                                                                                       57\n",
      "\n",
      "\n",
      "Funções de Rotulação que apenas verificam a existência de uma palavra na instância e\n",
      "aplicam um rótulo específico, sendo possível verificar detalhes na Tabela 6.10. Então, o\n",
      "algoritmo do Snorkel foi aplicado a totalidade de instâncias disponíveis de 22.946, re-\n",
      "sultando, assim, numa base de treinamento criada programaticamente totalizando 22.471\n",
      "instâncias. Por outro lado, observou-se que a base de dados criada programaticamente\n",
      "apresentava grande desbalanceamento. Então procedeu-se ao tratamento dessa questão\n",
      "por meio de Under-sampling criando-se assim outra base de treinamento, mas nesse caso\n",
      "contendo o total de 1.644 instâncias, sendo 548 instâncias para cada classe.\n",
      "       Enfim, na fase de Preparação dos Dados foram criadas 4 bases de treinamento.\n",
      "Uma base para o treinamento em relação ao tipo de recorrente, contendo 540 instâncias.\n",
      "Três bases para o treinamento em relação ao deferimento ou não da causa. Sendo uma\n",
      "delas a base padrão-ouro anotada por especialistas, contendo 1.000 instâncias e duas delas\n",
      "criadas programaticamente contendo 22.471 instâncias e 1.644 instâncias, mas nesse caso\n",
      "balanceada.\n",
      "\n",
      "\n",
      "\n",
      "5.2.3 Modelagem\n",
      "\n",
      "\n",
      "       A seguir prosseguiu-se a fase de modelagem utilizando as bases de dados criadas\n",
      "nas fases anteriores. Todos os experimentos nessa fase foram desenvolvidos de acordo\n",
      "com o seguinte fluxo de pré-processamento: as instâncias são tokenizadas com algoritmo\n",
      "específico que trata detalhes da língua portuguesa, em seguida é extraída a raiz de cada\n",
      "palavra usando a biblioteca Spacy, após é realizada a vetorização por meio de TF-IDF e\n",
      "por fim é realizada a modelagem com algoritmos de Aprendizado de Máquina, conforme\n",
      "ilustrado na Figura 5.2. Além disso todos os experimentos foram modelados utilizando\n",
      "os seguintes algoritmos da biblioteca Scikit Learn: Rocchio classifier, Gradient Boosting\n",
      "Classifier, Naive Bayes Classifier, K-nearest Neighbor, Support Vector Machine (SVM),\n",
      "Decision Tree, Random Forest. Também foi definido como padrão a utilização da métrica\n",
      "F1 como parâmetro de avaliação.\n",
      "       Primeiramente foi desenvolvido um experimento para classificação do tipo de re-\n",
      "querente como empregado ou empresa sendo utilizado 70% da base para treinamento e\n",
      "30% para testes. Enfim, o algoritmo Support Vector Machine (SVM) atingiu a métrica\n",
      "mais alta de 96,91%.\n",
      "       O desenvolvimento do modelo necessário para classificar as decisões em relação\n",
      "ao deferimento ou não da causa judicial foi realizado por meio de três experimentos. Um\n",
      "\f58\n",
      "\n",
      "\n",
      "Figura 5.2: Ilustração explicativa do fluxo de pré-processamento para modelagem por\n",
      "algoritmos de Aprendizado de Máquina.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "utilizando a base de dados padrão-ouro, outro utilizando a base criada programaticamente\n",
      "balanceada e outro utilizando a base de dados criada programaticamente com todas as\n",
      "instâncias.\n",
      "       O experimento utilizando a base de dados padrão-ouro foi realizado utilizando\n",
      "30% da base para testes e 70% para treinamento. Sendo que também foi realizada a\n",
      "validação-cruzada em 7 camadas com as instâncias de treinamento. Já quanto aos dois\n",
      "experimentos utilizando as bases de dados criadas programaticamente, sendo uma balan-\n",
      "ceada e a outra contendo a totalidade de instâncias, não houve a separação em 70/30.\n",
      "Nesse caso, foi utilizada a totalidade de cada base criada programaticamente para trei-\n",
      "namento e usada a totalidade da base padrão-ouro para testes. Assim, foi selecionado o\n",
      "algoritmo Gradient Boosting pois foi o que atingiu a maior média na métrica F1 sendo de\n",
      "\f                                                                                         59\n",
      "\n",
      "\n",
      "92,48%.\n",
      "\n",
      "\n",
      "\n",
      "5.2.4 Aplicação\n",
      "\n",
      "\n",
      "         Nessa fase foi realizada a aplicação dos dois modelos de Aprendizado de Máquina\n",
      "selecionados a totalidade de 22.946 instâncias extraídas e processadas nas fases anteriores.\n",
      "Nesse ponto, foi realizada a filtragem e remoção de todos os documentos que continham o\n",
      "rótulo SEM_ANALISE_MERITO em virtude de que os objetivos de negócio exigem ape-\n",
      "nas a verificação das instâncias rotuladas com DEFERIMENTO ou INDEFERIMENTO.\n",
      "A seguir foi realizado cálculo de proporções de julgamentos deferidos e indeferidos e apli-\n",
      "cados testes estatísticos de proporção utilizando a biblioteca Python Statsmodel. Por fim,\n",
      "foram desenvolvidos gráficos que apresentam as proporções de julgamentos de maneira\n",
      "visualmente interessante.\n",
      "\n",
      "\n",
      "\n",
      "5.3 Resumo do Capítulo\n",
      "\n",
      "\n",
      "         Este capítulo apresentou resumo do método de validação experimental executado\n",
      "na presente pesquisa e detalhado no Capítulo 6. Assim, primeiramente é realizada a clas-\n",
      "sificação da pesquisa de modo a nortear o leitor sobre o tipo de estudo realizado. Na\n",
      "sequência é salientada o tipo de metodologia utilizada para execução do trabalho e como\n",
      "ela foi executada neste trabalho. Após é descrito método de execução da Validação Ex-\n",
      "perimental de modo a permitir a fácil reprodução da pesquisa. Também é disponibilizado\n",
      "link para acesso ao código-fonte do projeto o que permite verificar detalhes de implemen-\n",
      "tação.\n",
      "\f60\n",
      "\n",
      "\n",
      "6 VALIDAÇÃO EXPERIMENTAL\n",
      "\n",
      "\n",
      "       A validação experimental da presente pesquisa segue metodologia CRISP-DM\n",
      "Guide 1.0 (CHAPMAN et al., 2000) conforme descrito no Capítulo 4. Desse modo,\n",
      "considerou-se conveniente apresentar os resultados em seções com mesmos nomes das\n",
      "fases da metodologia proposta. Assim, o Capítulo Validação Experimental está subdivi-\n",
      "dido nas seguintes Seções: Compreensão do negócio, Preparação dos dados, Modelagem,\n",
      "Avaliação de resultados e Aplicação. Também foi incluída ao final do capítulo a Seção\n",
      "Limitações que trata detalhadamente das limitações dos experimentos.\n",
      "\n",
      "\n",
      "\n",
      "6.1 Compreensão do negócio\n",
      "\n",
      "\n",
      "       Tradicionalmente, pesquisas jurisprudenciais são realizadas para a verificação de\n",
      "como as decisões judiciais são feitas, dos motivos que levam um magistrado a decidir\n",
      "de determinada forma em cada caso, além dos argumentos em questão utilizados como\n",
      "também as consequências dessas decisões em relação a cada assunto. Com tais pesquisas\n",
      "busca-se diminuir a insegurança e conhecer os caminhos que os processos judiciais po-\n",
      "dem tomar de acordo com o entendimento dominante de um tribunal, turma recursal ou\n",
      "magistrado.\n",
      "       Entretanto, devido ao distanciamento do Direito de outras ciências (GABARDO;\n",
      "MORETTINI, 2013), como a Ciência da Computação, tais pesquisas eram realizadas sem\n",
      "a utilização de recursos automáticos, aliás, eram realizadas manualmente (SALAMA et\n",
      "al., 2011) com uma pequena amostra selecionada. Com a evolução das tecnologias de\n",
      "Big Data e mineração de texto, podemos processar e analisar a grande maioria dos docu-\n",
      "mentos judiciais em busca de padrões desconhecidos, confirmando ou negando hipóteses\n",
      "supostas devido ao conhecimento geral adquirido na experiência de trabalho, e indo além,\n",
      "desenvolvendo sistemas preditivos baseados em uma grande gama de dados.\n",
      "       Além disso, o conhecimento da tendência de julgamento de uma turma recursal\n",
      "da Justiça do Trabalho em relação à determinada matéria pode ser um fator de vantagem\n",
      "no momento de realizar um acordo entre as partes, por exemplo. Especificamente nesse\n",
      "ramo do Judiciário brasileiro, o acordo entre as partes é incentivado em todos os níveis\n",
      "de jurisdição (TRT4, 2020) de forma que as partes entrem em consenso sozinhas em\n",
      "relação a um valor justo que leve o processo ao fim. Além disso, é importante notar\n",
      "que um processo judicial que tenha um acordo homologado por magistrado não tem mais\n",
      "\f                                                                                       61\n",
      "\n",
      "\n",
      "direito a recursos, dando, assim, fim definitivo ao caso, o que acarreta grande economia\n",
      "processual a Justiça. Então, quando um processo é dirigido a nível de segundo grau a\n",
      "uma turma recursal, o advogado que estiver mais bem informado sobre as tendências\n",
      "de opinião daquele órgão julgador, será mais capaz de tomar uma decisão de aceitar ou\n",
      "oferecer um acordo judicial que pode chegar a milhões de reais (TRT4, 2017).\n",
      "\n",
      "\n",
      "\n",
      "6.1.1 Objetivo de negócio\n",
      "\n",
      "\n",
      "       De acordo com Salama, Carlotti e Yeung (2018), o conhecimento popular e a ex-\n",
      "periência de anos de operadores do Direito parecem encaminhar para a consolidação de\n",
      "um senso comum de que existem certos magistrados ou turmas recursais na Justiça do\n",
      "Trabalho inclinadas a proteger mais empregados do que empresas e vice versa. Isso le-\n",
      "vanta questionamentos éticos quanto à parcialidade dos magistrados, conforme abordado\n",
      "no Capítulo 2.1.3. Entretanto, essa situação é perfeitamente possível considerando que\n",
      "a legislação brasileira deixa muitos aspectos em aberto permitindo a discricionariedade\n",
      "dos magistrados em relação a que lado tomar para determinados assuntos a serem decidi-\n",
      "dos. É importante considerar também que a dinâmica do Direito permite aos magistrados\n",
      "tomarem posições diferentes em relação a mesma matéria e a argumentar de acordo. En-\n",
      "tretanto, o ponto interessante para os advogados e empresas na prática jurídica é conhecer\n",
      "quem são os magistrados ou turmas recursais mais inclinados para empresas ou empre-\n",
      "gados. Assim, deseja-se confirmar por meio de técnicas computacionais e estatísticas se\n",
      "a seguinte questão de pesquisa estabelecida se configura verdadeira: Seria possível que\n",
      "os tribunais avaliados e suas turmas recursais julguem favoravelmente proporção\n",
      "significativamente maior de recursos para uma das partes do que para outra em\n",
      "média?\n",
      "\n",
      "\n",
      "6.1.1.1 Teste estatístico\n",
      "\n",
      "       A hipótese foi definida como Os tribunais avaliados e suas turmas recursais jul-\n",
      "gam favoravelmente proporção significativamente maior de recursos para uma das\n",
      "partes do que para outra em média. Assim a hipótese a ser validada exige a compara-\n",
      "ção de duas proporções em relação à existência de diferença estatística. Assim, definiu-se\n",
      "como Pa a proporção de recursos de empregados deferidos e Pb a proporção de recursos\n",
      "de empresas deferidos. Então, foi definida como hipótese nula H0 Pa = Pb. Já a hipótese\n",
      "\f62\n",
      "\n",
      "\n",
      "alternativa como Pa 6= Pb. A seguir, é apresentado resumo do teste de hipótese estatística:\n",
      "\n",
      "\n",
      "     • Pa = proporção de recursos de empregados deferidos.\n",
      "     • Pb = proporção de recursos de empresas deferidos.\n",
      "     • H0: Pa = Pb.\n",
      "     • Ha: Pa 6= Pb.\n",
      "\n",
      "\n",
      "6.1.1.2 Critério de sucesso do objetivo de negócio\n",
      "\n",
      "        Foi definido como critério de sucesso do projeto o processamento e análise de de-\n",
      "cisões judiciais por meio de testes estatísticos e o desenvolvimento de relatório contendo a\n",
      "proporção de decisões para cada uma das partes em cada dos tribunais e turmas recursais\n",
      "estudados, incluindo também dados dos testes estatísticos, como o nível de efeito e nível\n",
      "de força estatística.\n",
      "\n",
      "\n",
      "\n",
      "6.1.2 Requisitos e restrições\n",
      "\n",
      "\n",
      "        O processamento e análise dos dados precisa ser realizado utilizando amostra ex-\n",
      "traída significante para representar o total de decisões disponibilizadas publicamente.\n",
      "Além disso, é necessário manter o sigilo quanto a qualquer informação de nomes das\n",
      "partes que sejam citados nos processos judiciais. Por outro lado, a extração automatizada\n",
      "de dados de páginas de internet pode ser proibida, ou até mesmo, o processo pode causar\n",
      "certos danos aos servidores. Assim, foi definido também que seria respeitada qualquer li-\n",
      "mitação imposta pelos sites a robôs de busca e que a extração dos dados seria realizada da\n",
      "maneira mais preservada possível. Considerou-se necessário também a análise quantita-\n",
      "tiva de ao menos dois tribunais diferentes para permitir a verificação da performance dos\n",
      "modelos de Aprendizado de Máquina em documentos de origens diversas, como também\n",
      "permitir a comparação das proporções de julgados entre tribunais diferentes.\n",
      "\n",
      "\n",
      "\n",
      "6.1.3 Custo-benefício\n",
      "\n",
      "\n",
      "        Grandes escritórios de advocacia lidam diariamente com milhares de processos\n",
      "trabalhistas de uma única empresa. De acordo com Salama, Carlotti e Yeung (2019),\n",
      "a condenação média no Tribunal Regional do Trabalho da 2a Região está em torno de\n",
      "\f                                                                                     63\n",
      "\n",
      "\n",
      "R$28.493,54 e o tempo médio de execução de dívida trabalhista de 4 anos e 10 me-\n",
      "ses. Considerando o caso de um processo judicial hipotético nessa média de valor de\n",
      "condenação, valeria a pena para a empresa efetivar acordo no valor até R$21.340,00 e\n",
      "para empregado, acordo acima desse valor. Isso porque uma empresa poderia aplicar o\n",
      "dinheiro durante os 4 anos e 10 meses a uma taxa média de 1% ao mês e no final a aplica-\n",
      "ção poderia ter rendido R$38,006,00. Quanto ao empregado, ele poderia aplicar o mesmo\n",
      "valor a uma taxa de 0,5% ao mês e ainda sair lucrando. Entretanto, o advogado que tiver\n",
      "posse de relatório contendo as tendências médias estatísticas de julgamento em relação\n",
      "a empregado e a empregador da turma recursal que recebeu o processo para julgamento\n",
      "pode tomar decisão diversa baseado nesses dados. Além disso, deve ser considerado\n",
      "que a turma recursal pode aumentar o valor de condenação (o que seria negativo para a\n",
      "empresa), ou diminuir o valor de condenação (o que seria negativo para o empregado).\n",
      "Assim, um empregado que receba oferta de acordo pouco abaixo do valor ótimo, poderia\n",
      "escolher aceitar considerando que a turma recursal julgando o processo tenha tendência\n",
      "de favorecer empresas e vice-versa.\n",
      "\n",
      "\n",
      "\n",
      "6.1.4 Objetivo de mineração de dados\n",
      "\n",
      "\n",
      "       O objetivo de Mineração de Dados é classificar automaticamente acórdãos ju-\n",
      "diciais em relação ao deferimento ou não e classificar automaticamente o requerente\n",
      "do recurso em relação a ser empresa ou a ser empregado. Além disso, classificar\n",
      "com os modelos desenvolvidos quantidade significante de decisões judiciais e apre-\n",
      "sentar relatórios contendo as proporções de julgados positivamente para cada uma\n",
      "das partes.\n",
      "\n",
      "\n",
      "\n",
      "6.2 Compreensão dos dados\n",
      "\n",
      "\n",
      "       Primeiramente, procurou-se reunir a matéria prima da pesquisa, os acórdãos judi-\n",
      "ciais. Nesse caso, os acórdãos são os documentos judiciais que publicam a decisão dos\n",
      "magistrados indicando o deferimento ou não dos pedidos dos empregados e empregado-\n",
      "res. Assim, esses documentos extraídos da internet vão compor a amostra para a execução\n",
      "da presente pesquisa. Ou seja, cada instância de observação da amostra é na verdade um\n",
      "acórdão judicial.\n",
      "\f64\n",
      "\n",
      "\n",
      "Tabela 6.1: Dados do Justiça em Números (CNJ, 2020) que apresentam a quantidade de\n",
      "casos novos ajuizados no ano de 2019.\n",
      "                         Quantidade de casos novos em 2019\n",
      "                         TRT 4a Região             267.036\n",
      "                         TJ RS                   1.413.893\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "         Tais documentos são disponibilizados publicamente por todos os tribunais brasi-\n",
      "leiros em suas páginas de internet por meio de site de pesquisa em que os usuários podem\n",
      "informar palavras-chave para busca. Assim, por meio dessas páginas de busca, foi reali-\n",
      "zada uma exploração prévia da base de dados para reunir conhecimento sobre que tipos\n",
      "de documentos estão disponibilizados, qual a frequência e quantidade de publicação dos\n",
      "Tribunais, como os documentos são redigidos, que tipos de palavras são utilizadas, que\n",
      "tipos de metadados são disponibilizados em conjunto. Durante essa fase de exploração\n",
      "inicial, foram analisadas decisões judiciais da Justiça do Trabalho e da Justiça Comum\n",
      "do Rio Grande do Sul. Durante essa avaliação, foram considerados diversos fatores como\n",
      "a legibilidade dos documentos, quantidade de assuntos tratados nas decisões, estruturas\n",
      "comuns aos documentos, padrões seguidos pelos magistrados, além do conhecimento do\n",
      "pesquisador nas matérias do domínio do Direito analisadas.\n",
      "         Desse modo, decidiu-se por realizar a pesquisa utilizando documentos da Justiça\n",
      "do Trabalho. Tal decisão se baseia principalmente na experiência adquirida pelo pesqui-\n",
      "sador após anos de trabalho como servidor público da Justiça do Trabalho. Por outro lado,\n",
      "a Justiça do Trabalho trata de processos de causas estritamente trabalhistas, por ser uma\n",
      "Justiça especializada nesse tipo de causa, ao contrário do que ocorre na Justiça Comum,\n",
      "que trata de uma gama muito ampla de assuntos, desde cíveis até mesmo penais. Desse\n",
      "modo, supôs-se que os documentos criados abrangem uma gama menor de assuntos e\n",
      "que assim permitiriam uma análise mais acessível, objetiva e especializada. Apenas para\n",
      "título de comparação, podemos observar que a Justiça do Trabalho é muito menor que\n",
      "a Justiça Comum averiguando os dados de abertura de processos novos disponibilizados\n",
      "pela CNJ no relatório Justiça em Números (CNJ, 2020) e verificando a Tabela 6.1 com\n",
      "as informações resumidas. A partir desses dados, é possível verificar que a quantidade de\n",
      "processos abertos na Justiça do Estado do Rio Grande do Sul é aproximadamente 5 vezes\n",
      "maior.\n",
      "\f                                                                                         65\n",
      "\n",
      "\n",
      "6.2.1 Coleta de dados\n",
      "\n",
      "\n",
      "        Após a decisão de qual Justiça seria foco na pesquisa, passou-se a análise de quais\n",
      "páginas de internet seriam utilizadas para realizar a extração dos dados. Como os dados\n",
      "precisariam ser extraídos automaticamente, foram avaliados diversos sites para escolher\n",
      "os que não implementassem nenhum tipo de bloqueio a robôs de busca. Assim, foram\n",
      "escolhidos dois sites para extração de dados, o <http://lexml.gov.br/> e o <http://trt4.jus.\n",
      "br/>.\n",
      "        Por outro lado, de modo a realizar a extração de dados para evitar qualquer pre-\n",
      "juízo aos órgãos públicos e seus domínios na internet, foram implementados métodos\n",
      "para a redução de qualquer possível dano gerado. Assim, foi colocado como diretriz da\n",
      "pesquisa o respeito a qualquer limitação imposta pelos próprios sites a robôs de busca.\n",
      "Tais limitações geralmente são encontradas nos termos de uso dos sites e em um arquivo\n",
      "chamado robots.txt na raiz do domínio. Além disso, não foram encontrados outros tipos\n",
      "de limitações, como por exemplo, a necessidade de o usuário provar que não é um robô\n",
      "pela leitura de caracteres em uma imagem, ou resolução de um problema de lógica que\n",
      "apenas um ser humano conseguiria resolver.\n",
      "        Ademais, nenhum dos sites apresenta qualquer documento jurídico indicando os\n",
      "termos de uso, tampouco apresentavam, à época da realização da atividade, qualquer\n",
      "limitação a robôs de busca de escanearem todos os documentos públicos dos sites. Havia\n",
      "apenas bloqueios em relação a acessos às áreas privadas, como, por exemplo, páginas de\n",
      "intranet. Por outro lado, todos os documentos disponibilizados nos sites são de acesso\n",
      "público, sem nem a necessidade de utilizar login.\n",
      "        Além disso, todos os dados pessoais que possam identificar as partes não são publi-\n",
      "cados em nenhuma parte da presente pesquisa. Desse modo, manteve-se a anonimização\n",
      "das partes. Isso porque o mais importante para a pesquisa é analisar a massa de dados\n",
      "agregada, e não os indivíduos em si. Ademais, foi obtido por e-mail autorização para a\n",
      "utilização de decisões judiciais para a realização de pesquisa quantitativa com técnicas de\n",
      "inteligência artificial e jurimetria.\n",
      "        Enfim, o site do Tribunal Regional do Trabalho da 4a Região foi escolhido por se\n",
      "tratar da Justiça do Trabalho com jurisdição em todo o território do Estado do Rio Grande\n",
      "do Sul o qual se torna mais interessante para a comunidade acadêmica da nossa Universi-\n",
      "dade como também para os cidadãos que usufruem das pesquisas realizadas na UFRGS.\n",
      "Por outro lado, foi decidido realizar a pesquisa também em outro Estado para permitir a\n",
      "\f66\n",
      "\n",
      "\n",
      "comparação e avaliação das possíveis diferenças nos dados estatísticos produzidos, como\n",
      "também observar possíveis diferenças de escritas nos documentos que poderiam afetar a\n",
      "performance de algoritmos desenvolvidos. Assim, as decisões do TRT da 4a Região fo-\n",
      "ram extraídas de seu próprio site e do site LexML foram extraídas as decisões do Tribunal\n",
      "Regional do Trabalho da 3a Região. Tal Tribunal foi escolhido por ser o tribunal com\n",
      "mais decisões da Justiça do Trabalho disponibilizadas no site. Para ambos os tribunais\n",
      "optou-se por realizar a extração de decisões publicadas a partir do ano de 2017 até 2019.\n",
      "\n",
      "\n",
      "6.2.1.1 Métodos de extração\n",
      "\n",
      "             Os robôs de extração de dados foram desenvolvidos utilizando a linguagem Python\n",
      "e a biblioteca Scrapy1 . Quanto ao site <lexml.gov.br>, eram disponibilizados diversos\n",
      "arquivos sitemap.xml na raiz do site para facilitar a extração de dados. Tais arquivos\n",
      "continham uma URL para cada documento disponibilizado. Além disso, por meio de\n",
      "cada URL era possível saber do que o documento tratava, permitindo assim a seleção de\n",
      "todos os documentos necessários a serem extraídos diretamente pelas URLs. Então, o\n",
      "conteúdo completo das decisões era disponibilizado em páginas HTML, as quais foram\n",
      "acessadas diretamente pelos robôs de extração de dados. Quanto ao site <trt4.jus.br>, há\n",
      "uma página de busca que permite a filtragem de documentos por meio de palavras-chave.\n",
      "Cada resultado é apresentado na mesma página com um link para o documento HTML\n",
      "contendo a decisão completa. Assim, foi desenvolvido um robô de extração de dados para\n",
      "simular um humano realizando a pesquisa no site, filtrar os resultados de acordo com os\n",
      "critérios necessários e acessar os links contendo os acórdãos judiciais completos.\n",
      "\n",
      "\n",
      "6.2.1.2 Tamanho da amostra\n",
      "\n",
      "             A hipótese analisada exige a comparação da proporção de recursos de empregados\n",
      "deferidos com a proporção de recursos de empresas deferidos, conforme a Seção 6.1.1.1.\n",
      "Por outro lado, utilizou-se a biblioteca Statsmodels2 para realização do teste estatístico,\n",
      "para cálculo das propriedades de efeito e força estatística, como também para cálculo do\n",
      "tamanho da amostra. Desse modo, o cálculo do tamanho da amostra exige como variáveis\n",
      "o tamanho das proporções sendo avaliadas, o tamanho da diferença entre as proporções\n",
      "que se deseja verificar, o nível de força estatística e o nível de confiança desejados. En-\n",
      "tretanto, os valores dessas variáveis não são conhecidos antes da efetiva verificação dos\n",
      "     1\n",
      "         <https://scrapy.org/>\n",
      "     2\n",
      "         <https://www.statsmodels.org/stable/index.html>\n",
      "\f                                                                                      67\n",
      "\n",
      "\n",
      "Tabela 6.2: Quantidade de decisões disponibilizadas e a quantidade da amostra inicial\n",
      "extraída para cada tribunal.\n",
      "                             Tribunal    População Amostra\n",
      "                        TRT da 3a Região   268.691      26.634\n",
      "                                 a\n",
      "                        TRT da 4 Região    140.545      29.894\n",
      "\n",
      "\n",
      "dados.\n",
      "         Assim, buscou-se realizar a extração de decisões judiciais em certa quantidade\n",
      "que permitisse o processamento inicial e sua análise exploratória para permitir a verifi-\n",
      "cação aproximada das variáveis necessárias. Por outro lado, importante considerar que o\n",
      "objetivo de negócio exige a realização de teste estatístico em relação às proporções em\n",
      "função de cada tribunal como também em relação a cada turma recursal. Desse modo,\n",
      "existe também a necessidade de se definir as quantidades mínimas de observações neces-\n",
      "sárias em relação a cada turma recursal, o que impõe outra dificuldade, pois não se tem\n",
      "conhecimento prévio das quantidades de processos deferidos para cada uma das partes\n",
      "em cada turma recursal. Enfim, a Tabela 6.2 apresenta o tamanho das amostras extraídas\n",
      "para análise inicial dos dados.\n",
      "\n",
      "\n",
      "6.2.1.3 Dificuldades encontradas\n",
      "\n",
      "         Os robôs de extração de dados desenvolvidos não conseguiram extrair a totalidade\n",
      "dos documentos disponíveis em virtude de que houve problemas de requisições HTTP\n",
      "não respondidas pelos servidores, como também certa quantidade dos documentos foram\n",
      "disponibilizadas apenas em formato PDF. Enfim, foi possível extrair diretamente o texto\n",
      "puro da maioria dos arquivos, entretanto, os arquivos PDF precisaram ser processados em\n",
      "uma segunda etapa na fase de coleta.\n",
      "\n",
      "\n",
      "\n",
      "6.2.2 Descrição dos dados\n",
      "\n",
      "\n",
      "         A fase de coleta dos dados resultou na compilação de 2 arquivos CSV em relação\n",
      "ao TRT da 3a Região e 1 arquivo em relação ao TRT da 4a Região, conforme Tabela 6.3.\n",
      "No caso do TRT da 3a Região, foram gerados dois arquivos em virtude de dificuldades\n",
      "técnicas de processamento da carga de dados no momento da extração. Os arquivos CSV\n",
      "são compostos de um campo com o nome INTEIRO_TEOR contendo o texto puro dos\n",
      "acórdãos judiciais. Foi utilizada a biblioteca Pandas para manipulação dos arquivos nesse\n",
      "formato em virtude da facilidade de uso.\n",
      "\f68\n",
      "\n",
      "\n",
      " Tabela 6.3: Relação dos arquivos gerados a partir da extração dos dados dos tribunais.\n",
      "                                                                    Quantidade de amostras\n",
      "   Tribunal                        Nome do arquivo                  efetivamente extraídas   Tamanho\n",
      "TRT da 3a Região   TRT3_inteiro_teor_2017_2018_2019_amostra_1.csv                   17.846   245MB\n",
      "TRT da 3a Região   TRT3_inteiro_teor_2017_2018_2019_amostra_2.csv                    8.788   120MB\n",
      "TRT da 4a Região   TRT4_inteiro_teor_2017_2018_2019_amostra.csv                     29.894   541MB\n",
      "\n",
      "\n",
      "Tabela 6.4: Descrição da base de dados extraída do TRT da 3a Região em relação à\n",
      "quantidade de palavras.\n",
      "                                                Palavras\n",
      "                          Quantidade média        2.093\n",
      "                          Desvio padrão           1.936\n",
      "                          Quantidade mínima            1\n",
      "                          25% percentil             810\n",
      "                          50% percentil           1.457\n",
      "                          75% percentil           2.690\n",
      "                          Quantidade máxima      23.625\n",
      "\n",
      "\n",
      "6.2.3 Exploração dos dados\n",
      "\n",
      "\n",
      "       As bases de dados foram analisadas separadamente, assim, o conjunto do TRT\n",
      "da 3a Região apresentou o total de 26.634 instâncias, já o TRT da 4a Região apresen-\n",
      "tou 29.894. A descrição da quantidade de palavras contidas nos documentos pode ser\n",
      "observada nas Tabelas 6.4 e 6.5. Os Gráficos contendo as distribuições dos unigramas,\n",
      "bigramas e trigramas é apresentada no Apêndice na Seção A.3.\n",
      "\n",
      "\n",
      "\n",
      "6.2.4 Qualidade dos dados coletados\n",
      "\n",
      "\n",
      "       A qualidade das instâncias extraídas a partir dos arquivos HTML foi satisfatória na\n",
      "maioria dos casos, entretanto, houve algumas instâncias que continham apenas mensagens\n",
      "de erros com servidores, assim, tais documentos foram removidos na fase de Preparação\n",
      "\n",
      "\n",
      "Tabela 6.5: Descrição da base de dados extraída do TRT da 4a Região em relação à\n",
      "quantidade de palavras.\n",
      "                                                Palavras\n",
      "                          Quantidade média        2.738\n",
      "                          Desvio padrão           2.357\n",
      "                          Quantidade mínima            0\n",
      "                          25% percentil           1.051\n",
      "                          50% percentil           2.065\n",
      "                          75% percentil           3.654\n",
      "                          Quantidade máxima      23.391\n",
      "\f                                                                                      69\n",
      "\n",
      "\n",
      "dos Dados. Já em relação aos arquivos PDF, não foi possível utilizar nenhuma dessas\n",
      "instâncias. A extração do texto puro foi realizada por meio do aplicativo gratuito Xpd-\n",
      "fReader 3 , entretanto o processamento gerou arquivos com caracteres inseridos em partes\n",
      "incorretas do texto, especialmente caracteres referentes a cabeçalhos e rodapés.\n",
      "\n",
      "\n",
      "\n",
      "6.3 Preparação dos dados\n",
      "\n",
      "\n",
      "         Nesta fase da pesquisa são realizados diversos processamentos com os documen-\n",
      "tos para prepará-los para serem usados na fase seguinte de modelagem de dados. Assim,\n",
      "são realizadas limpeza dos dados como também transformações para extrair e ressaltar\n",
      "as features mais importantes para a tarefa de classificação. Além disso, também é rea-\n",
      "lizada a construção da base padrão-ouro, a qual é utilizada para os testes dos modelos\n",
      "desenvolvidos.\n",
      "\n",
      "\n",
      "\n",
      "6.3.1 Limpeza dos dados\n",
      "\n",
      "\n",
      "         A limpeza dos documentos de texto foi realizada para garantir a qualidade mí-\n",
      "nima das instâncias para serem utilizadas nas fases subsequentes de transformação de\n",
      "dados e modelagem. Conforme as Tabelas 6.4 e 6.5, é possível observar que há instân-\n",
      "cias contendo nenhuma ou apenas uma palavra. Assim, foi realizada a análise visual das\n",
      "instâncias contendo menos de 150 palavras e verificou-se que havia muitas mensagens\n",
      "de erros nos documentos. Algumas instâncias continham palavras irreconhecíveis. En-\n",
      "fim, considerou-se prudente remover todas as instâncias que continham menos de 150\n",
      "palavras.\n",
      "\n",
      "\n",
      "\n",
      "6.3.2 Transformação dos dados\n",
      "\n",
      "\n",
      "         Essa fase tem por objetivo extrair e ressaltar as features mais importantes para\n",
      "os algoritmos de modelagem de dados. Assim, são adicionados metadados às decisões,\n",
      "como também são removidos documentos e partes dos documentos que não são relevantes\n",
      "à pesquisa.\n",
      "\n",
      "\n",
      "  3\n",
      "      <https://www.xpdfreader.com/pdftotext-man.html>\n",
      "\f70\n",
      "\n",
      "\n",
      "6.3.2.1 Enriquecimento com metadados das decisões judiciais\n",
      "\n",
      "             Os documentos coletados continham de maneira não estruturada em seu conteúdo\n",
      "de texto informações úteis importantes para a realização de agregações e análises em fases\n",
      "posteriores. Assim, foram extraídos por meio de expressões regulares os seguintes dados:\n",
      "data de publicação, nome do relator, órgão julgador, nome dos recorrentes, dispositivo do\n",
      "acórdão e a quantidade de recorrentes. Esses dados foram extraídos por meio da utilização\n",
      "de palavras-chave e strings Regex. O código-fonte Python e Regex pode ser encontrado\n",
      "no repositório da pesquisa4 .\n",
      "             Entretanto houve dificuldades na aplicação dessa técnica pois certos documentos\n",
      "utilizavam um padrão para escrever essas informações e outros documentos usavam outro\n",
      "padrão. Assim, procurou-se criar expressões regulares que abrangessem o maior número\n",
      "de casos possíveis. Infelizmente, um pequeno número de instâncias não teve esses dados\n",
      "extraídos devido a um modo de escrita diverso e acabaram por ser removidas da base\n",
      "de dados. Enfim, todas as amostras em que as expressões regulares foram efetivas na\n",
      "extração foram enriquecidas com esses dados inseridos como colunas adjacentes.\n",
      "\n",
      "\n",
      "6.3.2.2 Extração do dispositivo da sentença\n",
      "\n",
      "             De acordo com a Seção 2.1, as decisões proferidas pelos magistrados brasileiros\n",
      "devem ser redigidas seguindo certos padrões e conter determinados elementos. Um des-\n",
      "ses elementos é chamado de dispositivo da sentença, o qual é de caráter obrigatório e deve\n",
      "conter em todas as decisões e acórdãos publicados. Essa parte do texto deve conter parti-\n",
      "cularmente a informação sobre se o recorrente teve seu pedido deferido ou não em poucos\n",
      "parágrafos, direto e objetivamente. Assim, essa parte do texto foi extraída, pois é nesse\n",
      "trecho que está a informação necessária a ser modelada pelo algoritmo de Aprendizado\n",
      "de Máquina a ser desenvolvido.\n",
      "\n",
      "\n",
      "6.3.2.3 Remoção de documentos com mais de um recorrente\n",
      "\n",
      "             Muitos dos acórdãos publicados pelos tribunais dizem respeito a mais de um re-\n",
      "curso impetrado, nesses casos, ambas as partes recorreram da decisão. Assim, o acórdão\n",
      "trata dos pedidos de recurso de ambos os recorrentes e o dispositivo da decisão precisa\n",
      "ser objetivo e dar uma resposta a cada um dos recursos.\n",
      "             Assim, esse tipo de documento, em que ambas as partes recorreram, exigiria uma\n",
      "     4\n",
      "         <https://github.com/rhuanbarros/jurimetria_justica_do_trabalho>\n",
      "\f                                                                                       71\n",
      "\n",
      "\n",
      "anotação diferenciada para ser possível abranger por completo a semântica necessária\n",
      "para alcançar o objetivo de mineração. Nesse caso, seria necessário anotar individual-\n",
      "mente os tokens do documento para ser possível identificar os elementos distintivos que\n",
      "representam cada uma das partes e o seu deferimento ou não.\n",
      "       Entretanto, construir um modelo que consiga identificar a resposta dos magis-\n",
      "trados em relação a cada um dos recursos aumentaria o grau de dificuldade do modelo\n",
      "proposto a ser construído pois necessitaria da aplicação de demasiadas técnicas de apren-\n",
      "dizado de máquina e processamento de linguagem natural. Assim, para não aumentar o\n",
      "nível de complexidade da pesquisa num primeiro momento, decidiu-se por não proces-\n",
      "sar tais documentos. Além disso, o objetivo de negócio não exige especificamente que\n",
      "esse tipo de documento seja analisado pelo algoritmo, tornando, assim, fora do escopo do\n",
      "projeto analisar recursos com mais de um recorrente.\n",
      "       Desse modo, os documentos foram processados em busca de todos que continham\n",
      "mais de um recorrente por meio de análise do texto do campo Recorrente dos documentos\n",
      "contendo uma vírgula ou um e. Se houvesse, tal documento se tratava de mais de um\n",
      "recorrente e foram removidos do da base. Enfim, após todo o processamento e remoção\n",
      "de instâncias desnecessárias, a base de documentos do Tribunal Regional do Trabalho da\n",
      "3a Região restou com o total de 10.875 instâncias, já o Tribunal Regional do Trabalho da\n",
      "4a Região com 12.071. Foram removidas 33.582 instâncias.\n",
      "       A remoção dessas instâncias da base de dados pode ter enfraquecido o nível de\n",
      "força do teste estatístico aplicado nas fases finais da pesquisa em vista de que houve\n",
      "diminuição considerável de documentos disponíveis para análise. Entretanto, neste ponto\n",
      "da pesquisa não é possível estimar o impacto visto que só é possível calcular o nível de\n",
      "força do teste estatístico após a realização do teste num momento em que a base de dados\n",
      "já foi totalmente processada em relação às proporções de julgados favoráveis a cada parte.\n",
      "\n",
      "\n",
      "\n",
      "6.3.3 Anotação manual da base de documentos\n",
      "\n",
      "\n",
      "       Os documentos extraídos e processados nos capítulos anteriores foram salvos em\n",
      "formato CSV em ordem aleatória e analisados diretamente em aplicativo editor de planilha\n",
      "de texto. A anotação manual da base de documentos foi desenvolvida seguindo a meto-\n",
      "dologia apresentada no Capítulo 2.4 a qual inicia pela fase de modelagem do metamodelo\n",
      "de rótulos a serem aplicados. Assim, foi necessário que cada documento contivesse uma\n",
      "marcação em relação a se o requerente é empresa ou empregado e também outra marcação\n",
      "\f72\n",
      "\n",
      "\n",
      "indicando se o recurso foi deferido ou não.\n",
      "\n",
      "\n",
      "6.3.3.1 Anotação para desenvolvimento do modelo de classificação do tipo de recorrente\n",
      "\n",
      "       Foram modelados dois rótulos utilizando a nomenclatura própria do Direito do\n",
      "Trabalho, conforme exposto na Seção 2.1.1: RECLAMANTE, que indica que a parte é\n",
      "empregado, e RECLAMADA, que indica que a parte é empresa. O modelo consiste de um\n",
      "vocabulário de termos T, do relacionamento entre esses termos R, e da interpretação I,\n",
      "conforme demonstrado abaixo.\n",
      "\n",
      "\n",
      "     • T = {Tipo_documento, RECLAMANTE, RECLAMADA}\n",
      "     • R = {Tipo_documento ::= RECLAMANTE | RECLAMADA}\n",
      "     • I = {RECLAMANTE = Parte recorrente é empregado, RECLAMADA = Parte\n",
      "      recorrente é empresa}\n",
      "\n",
      "\n",
      "6.3.3.2 Execução do processo de anotação manual em relação ao tipo de recorrente\n",
      "\n",
      "       A anotação dos documentos em relação ao tipo de recorrente foi realizada pelo\n",
      "próprio autor apenas, pois tal tarefa não exige nenhum conhecimento específico do Di-\n",
      "reito. A rotulação consistiu apenas na verificação do nome do recorrente ser nome de\n",
      "pessoa física ou jurídica. Assim, foi extraído aleatoriamente 270 instâncias de cada um\n",
      "dos tribunais em formato CSV, totalizando 540 observações. Essa quantidade foi definida\n",
      "arbitrariamente pelo autor após verificação da performance em testes de modelagem.\n",
      "\n",
      "\n",
      "6.3.3.3 Anotação para desenvolvimento do modelo de classificação em relação ao deferi-\n",
      "        mento ou indeferimento da decisão\n",
      "\n",
      "       A princípio foram modelados brevemente dois rótulos: DEFERIMENTO para in-\n",
      "dicar uma decisão que houve julgamento favorável e INDEFERIMENTO para indicar uma\n",
      "decisão que não houve julgamento favorável. Após, foi iniciada a fase de anotação pelo\n",
      "próprio autor, o qual observou que seria necessária a criação de outro rótulo pois havia\n",
      "documentos que não se encaixavam em nenhum dos casos. Assim, foi criado o rótulo\n",
      "SEM ANÁLISE DE MÉRITO.\n",
      "       Foi necessária a criação desse rótulo pois há acórdãos em que não há análise\n",
      "quanto aos pedidos contidos no recurso devido a algum elemento que prejudique sua\n",
      "apreciação pelos magistrados, conforme esclarecido no Capítulo 2.1.2. Entretanto, es-\n",
      "\f                                                                                         73\n",
      "\n",
      "\n",
      "ses acórdãos sem julgamento de mérito ocorrem em uma minoria de casos. Enfim, foi\n",
      "inevitável o retorno à fase de modelagem para adequação do modelo com o novo rótulo.\n",
      "       Além disso, considerou-se importante a criação do rótulo SEM ANÁLISE DE MÉ-\n",
      "RITO para ser possível verificar o tamanho da distribuição desse tipo de documento na\n",
      "base de dados. Em fases finais de análise quantitativa e cálculo de proporções de julgados\n",
      "deferidos e indeferidos, poderia haver a dúvida em relação a qual classe esse tipo de do-\n",
      "cumento haveria sido classificada, em virtude de não haver sido treinado o classificador\n",
      "com esse tipo de documento previamente. Assim, poderia ser levantado o questionamento\n",
      "se esse tipo de documento não estaria inflando umas das proporções de deferidos ou in-\n",
      "deferidos. Enfim, abaixo é apresentado o modelo criado para essa tarefa de anotação.\n",
      "\n",
      "\n",
      "   • T        =      {Tipo_documento,         DEFERIMENTO,            INDEFERIMENTO,\n",
      "      SEM_ANALISE_MERITO}\n",
      "   • R    =       {Tipo_documento    ::=   DEFERIMENTO          |   INDEFERIMENTO          |\n",
      "      SEM_ANALISE_MERITO}\n",
      "   • I = {DEFERIMENTO = Julgamento favorável ao recorrente, INDEFERIMENTO\n",
      "      = Julgamento desfavorável ao recorrente, SEM_ANALISE_MERITO = Julga-\n",
      "      mento não é favorável nem desfavorável ao recorrente}\n",
      "\n",
      "\n",
      "6.3.3.4 Execução do processo de anotação manual em relação ao deferimento ou indefe-\n",
      "       rimento da decisão\n",
      "\n",
      "       A rotulação dos documentos foi realizada por três pessoas, sendo o autor e dois\n",
      "voluntários bacharéis em Direito. Assim, foram elaboradas planilhas online no aplicativo\n",
      "Google Suite com as decisões para anotação. Constaram uma coluna com as decisões e\n",
      "outra para inserir o rótulo em cada linha respectivamente. A Figura A.8 apresenta foto da\n",
      "tela da planilha com algumas decisões de exemplo. Assim, foram criadas duas planilhas,\n",
      "uma para cada anotador. Em cada planilha foi inserido 250 acórdãos do TRT da 3a Região\n",
      "e 250 acórdãos do TRT da 4a Região. Ou seja, cada voluntário realizou a anotação de 500\n",
      "documentos. Além disso, foi feita cópia de ambas as planilhas para serem anotadas pelo\n",
      "autor da pesquisa. Enfim, houve o total de 1000 documentos anotados por duas pessoas.\n",
      "Cada um dos documentos foi anotado por um dos anotadores voluntários e pelo autor\n",
      "da pesquisa. Cabe salientar que o autor da pesquisa detém conhecimentos jurídicos de\n",
      "nível técnico e mais de 10 anos de experiência profissional na Justiça brasileira, incluindo\n",
      "tempo de trabalho especificamente em varas do trabalho.\n",
      "\f74\n",
      "\n",
      "\n",
      "       Vale ressaltar que a amostra selecionada para a tarefa de anotação inclui apenas\n",
      "decisões em que houve apenas um recorrente, o que tornou a tarefa de anotação mais\n",
      "simples porque havia apenas um recurso para ser apreciado, ou seja, apenas um recurso\n",
      "para ser deferido ou indeferido. Além disso, o processamento final da base de documentos\n",
      "para estimar a tendência de opinião dos magistrados também foi realizado com decisões\n",
      "em que houve apenas um recorrente, conforme exposto na Seção 6.3.2.3.\n",
      "       Por outro lado, houve a preocupação de criar a planilha para os anotadores de\n",
      "modo a facilitar a correta edição do documento. Assim, as áreas do documento que con-\n",
      "tinham as decisões foram bloqueadas para edição, deixando livre para edição apenas a\n",
      "coluna Rótulo. Também houve a aplicação de cores alternadas para o fundo das linhas\n",
      "para facilitar a leitura, visualização e edição.\n",
      "       A seguir foi realizado o desenvolvimento das diretrizes de anotação a qual contém\n",
      "orientações gerais aos anotadores. Tal documento contém uma seção de introdução que\n",
      "expõe resumidamente o objetivo da pesquisa e como funciona o trabalho de anotação de\n",
      "documentos por anotadores voluntários. Após, são apresentados os rótulos com a devida\n",
      "explicação detalhada de como cada um deve ser usado. Além disso, são apresentados\n",
      "exemplos de decisões e o respectivo rótulo considerado correto pelo autor da pesquisa.\n",
      "Por fim, é apresentada uma lista de pontos importantes a serem observados pelos anota-\n",
      "dores. A Figura 6.1 apresenta trecho do documento que pode ser encontrado completo no\n",
      "Apêndice A.4.\n",
      "\n",
      "Figura 6.1: Trecho do documento Diretrizes para anotação manual de documentos jurídi-\n",
      "cos para pesquisa de mestrado de Rhuan Barros\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "6.3.3.5 Avaliação da tarefa de anotação e criação do padrão-ouro\n",
      "\n",
      "       Conforme exposto na Seção 2.4.1, foi realizada a avaliação do nível de concordân-\n",
      "cia entre os rótulos aplicados pelos anotadores. Assim, a Tabela 6.6 apresenta a matriz\n",
      "\f                                                                                     75\n",
      "\n",
      "\n",
      "              Tabela 6.6: Matriz de confusão em relação aos rótulos aplicados\n",
      "                                 P2              P2                 P2\n",
      "                            DEFERIMENTO    INDEFERIMENTO    SEM_ANALISE_MERITO   TOTAL\n",
      "P1      DEFERIMENTO         435            6                1                    442\n",
      "P1     INDEFERIMENTO        4              534              1                    539\n",
      "P1   SEM_ANALISE_MERITO     1              6                12                   19\n",
      "           TOTAL            440            546              14                   1000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Tabela 6.7: Balanceamento das classes da base de dados anotada em relação ao tipo de\n",
      "requerente.\n",
      "                           CLASSE          QUANTIDADE\n",
      "                        RECLAMANTE                      312\n",
      "                        RECLAMADA                       226\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "de confusão em relação aos rótulos aplicados. Aplicando a fórmula Cohen’s Kappa é ob-\n",
      "tido o valor de 0,963 que é considerado alto nível de concordância. Após, foi realizada\n",
      "a adjudicação da base de dados em que o próprio autor resolveu as discordâncias, sendo\n",
      "possível observar algumas instâncias de exemplo no Apêndice A.5.\n",
      "\n",
      "\n",
      "\n",
      "6.3.4 Exploração das bases de dados anotadas manualmente\n",
      "\n",
      "\n",
      "       Nesta fase da pesquisa é realizada novamente uma exploração da base de docu-\n",
      "mentos, entretanto, neste caso é possível obter informações essenciais para as fases se-\n",
      "guintes, pois os documentos receberam anotações. Assim, é possível analisar a frequência\n",
      "das palavras correlacionadas a cada categoria.\n",
      "\n",
      "\n",
      "6.3.4.1 Base de dados anotada manualmente quanto ao tipo de requerente\n",
      "\n",
      "       O processamento da base de dados anotada manualmente quanto ao tipo de re-\n",
      "querente gerou análises quanto ao balanceamento das classes e também em relação às\n",
      "palavras mais comuns. Assim, na Tabela 6.7 e na Figura 6.2 é possível observar o balan-\n",
      "ceamento das classes, sendo que a classe RECLAMADA contém pouco menos instâncias\n",
      "anotadas. Quanto à análise dos unigramas mais comuns em cada classe, é possível ve-\n",
      "rificar que, para a classe RECLAMANTE, sobrenomes comuns no Brasil, como Silva e\n",
      "Santos figuram como mais frequentes. Já para a classe RECLAMADA, as palavras Ltda,\n",
      "Brasil e SA ficam respectivamente em primeiro, segundo e terceiro lugar na lista de mais\n",
      "frequentes.\n",
      "\f76\n",
      "\n",
      "\n",
      "Figura 6.2: Histograma apresentando o balanceamento das classes da base de dados ano-\n",
      "tada em relação ao tipo de reclamante.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Tabela 6.8: Balanceamento das classes da base de dados anotada em relação ao deferi-\n",
      "mento ou não da decisão.\n",
      "                           CLASSE               QUANTIDADE\n",
      "                   INDEFERIMENTO                            539\n",
      "                   DEFERIMENTO                              441\n",
      "                   SEM_ANALISE_MERITO                        20\n",
      "\n",
      "\n",
      "6.3.4.2 Base de dados anotada manualmente quanto ao deferimento ou não da decisão\n",
      "\n",
      "       Foi realizado o processamento e análise da base de dados anotada manualmente\n",
      "para explorar o balanceamento das classes e as palavras mais comuns usadas no campo\n",
      "Dispositivo em função do rótulo recebido separadamente para cada tribunal. Assim,\n",
      "na Tabela 6.8 e na Figura 6.3 é possível verifigiven the text of my work in my mastes degree above create a list of the experiences I have.use the folloing titles to guide the creatio and to group the experiencebusiness analisys, data scraping, data preparation (etl), machine learning modeling, statiscal analisys, dashboards presentationwrite everything in english\n"
     ]
    }
   ],
   "source": [
    "prompt_cheatsheet_formatted = prompt_cheatsheet.format(\n",
    "        TEXT=txt[:int(l*0.5)],        \n",
    "    )\n",
    "\n",
    "print( prompt_cheatsheet_formatted )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm_gemini.generate_content(prompt_cheatsheet_formatted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a breakdown of your experiences based on the text provided, categorized by the requested titles:\n",
      "\n",
      "**Business Analysis:**\n",
      "\n",
      "* **Identifying a Business Need:** You recognized the practical need for lawyers and businesses to understand the tendencies of labor courts in Brazil, particularly regarding which party (employer or employee) they tend to favor in rulings. This understanding can significantly impact settlement negotiations and strategic decision-making in legal cases.\n",
      "* **Defining Objectives and Success Criteria:** You clearly articulated the research question and defined the objective of building a system to classify legal decisions and determine the proportion of rulings favorable to each party. You also established success criteria based on the production of reports with statistically significant results.\n",
      "* **Cost-Benefit Analysis:** You conducted a cost-benefit analysis to demonstrate the financial implications of understanding court tendencies, showcasing how this knowledge can influence settlement decisions and potentially save significant sums of money for both employers and employees.\n",
      "* **Understanding Legal Domain:** Your background and experience as a public servant in the Brazilian labor court system provided crucial domain expertise, allowing you to understand the nuances of legal documents, procedures, and terminology. This expertise informed your research design and interpretation of results.\n",
      "\n",
      "**Data Scraping:**\n",
      "\n",
      "* **Web Scraping with Python and Scrapy:** You developed web scraping robots using Python and the Scrapy library to extract legal documents (acórdãos) from two different court websites. You navigated different website structures, including sitemaps and search pages, to collect the required data.\n",
      "* **Handling Website Limitations:** You demonstrated responsible scraping practices by respecting robots.txt and other website limitations to minimize the impact on the target servers. You also obtained permission via email to use the legal decisions for your research.\n",
      "* **Addressing Data Extraction Challenges:** You encountered and addressed challenges related to HTTP request errors, incomplete data, and PDF processing.  You used XpdfReader to extract text from PDFs but noted issues with character placement, ultimately excluding those documents from the analysis.\n",
      "\n",
      "**Data Preparation (ETL):**\n",
      "\n",
      "* **Data Cleaning:** You cleaned the scraped data by removing instances with errors, irrelevant characters, or insufficient length (less than 150 words). This ensured data quality for subsequent processing and modeling.\n",
      "* **Data Transformation:** You enriched the data by extracting key metadata (publication date, judge, parties involved, etc.) using regular expressions.  You also extracted the \"Dispositivo\" section of the legal documents, focusing on the part containing the judgment outcome.\n",
      "* **Data Reduction and Filtering:** You removed documents with multiple appellants to simplify the classification task and align with the research objective. You also filtered out cases labeled \"SEM_ANALISE_MERITO\" (without merit analysis) as they were not relevant to the core research question.\n",
      "* **Manual Data Annotation:** You meticulously annotated 1000 legal documents manually, creating a gold standard dataset for training and evaluating machine learning models. You developed annotation guidelines and involved two other law graduates in the process, using Cohen's Kappa to measure inter-annotator agreement. You also annotated a separate dataset for classifying the type of appellant (employer or employee).\n",
      "* **Weak Supervision with Snorkel:** You utilized Snorkel, a weak supervision framework, to programmatically label a larger dataset using labeling functions based on keyword presence. You addressed class imbalance in the resulting dataset through undersampling.\n",
      "\n",
      "**Machine Learning Modeling:**\n",
      "\n",
      "* **Text Preprocessing:**  You implemented a text preprocessing pipeline including tokenization (with a Portuguese-specific algorithm), stemming using Spacy, and TF-IDF vectorization.\n",
      "* **Model Selection and Evaluation:**  You experimented with various machine learning algorithms from Scikit-learn (Rocchio classifier, Gradient Boosting Classifier, Naive Bayes, K-NN, SVM, Decision Tree, Random Forest) and selected the best performing models based on the F1-score.  You used a 70/30 train-test split for the gold standard dataset and cross-validation. For the programmatically labeled datasets, you used the entire dataset for training and the gold standard dataset for testing.\n",
      "* **Model Training and Selection:** You trained and selected the SVM model for classifying the type of appellant and the Gradient Boosting model for classifying the judgment outcome.\n",
      "\n",
      "**Statistical Analysis:**\n",
      "\n",
      "* **Hypothesis Testing:** You formulated a null and alternative hypothesis regarding the proportion of rulings favorable to each party. You used the Statsmodels library to perform statistical tests (proportion tests) and calculate effect size and power.\n",
      "* **Sample Size Calculation:** You used Statsmodels to calculate the required sample size for the statistical tests, considering factors like effect size, power, and confidence level.\n",
      "\n",
      "**Dashboards/Presentation:**\n",
      "\n",
      "* **Data Visualization and Reporting:** You created visualizations (graphs and charts) to present the proportions of judgments for each party in each court and appeals chamber.  You compiled reports including statistical test results, effect size, and power.  While the text doesn't explicitly mention a specific dashboarding tool, the generation of graphs suggests a focus on presenting the results visually.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print( response.text )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEXT:\n",
      "\n",
      "car que há desbalanceamento da classe\n",
      "SEM_ANALISE_MERITO, a qual contém apenas 20 instâncias de um total de 1000.\n",
      "Quanto ao texto do campo Dispositivo, foi verificado que a maioria das instâncias contém\n",
      "até 250 palavras nesse campo, conforme Figura 6.4. Além disso, é possível observar na\n",
      "Tabela 6.9 que magistrados escrevem menos quando indeferem um recurso em compara-\n",
      "ção com os recursos deferidos.\n",
      "       Por outro lado, também foi elaborada análise de termos e suas associações em re-\n",
      "lação a cada classe anotada por meio da biblioteca Python Scattertext (KESSLER, 2017).\n",
      "Assim, é possível observar os termos mais associados com cada uma das classes anotadas\n",
      "para ambos os tribunais na Figura 6.5 e nas listas abaixo os termos mais associados para\n",
      "cada uma das classes. Os termos foram selecionados por meio de tokenização realizada\n",
      "utilizando expressões regulares que abrangem características da língua portuguesa.\n",
      "\f                                                                                   77\n",
      "\n",
      "\n",
      "Figura 6.3: Histograma apresentando o balanceamento das classes da base de dados ano-\n",
      "tada em relação ao deferimento ou não da decisão.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "       Figura 6.4: Histograma quantidade de palavras no dispositivo por tribunal\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "   • Termos mais associados com os acórdãos anotados como DEFERIMENTO.\n",
      "\n",
      "        – ’deu lhe’,\n",
      "        – ’dar provimento’,\n",
      "        – ’divergência deu’,\n",
      "        – ’dar’,\n",
      "        – ’unanimidade dar’,\n",
      "        – ’à condenação’,\n",
      "        – ’parcial’,\n",
      "        – ’condenar’,\n",
      "\f78\n",
      "\n",
      "\n",
      "Tabela 6.9: Descrição da base de dados anotada manualmente em função da quantidade\n",
      "de palavras no campo Dispositivo em relação a cada rótulo aplicado em cada tribunal.\n",
      "                                                                     Palavras\n",
      "Tribunal           Rótulo           Contagem de instâncias   Média    Mínimo     25%    50%    75%    Máximo\n",
      "               DEFERIMENTO                            197     248           75    133    161    219     2540\n",
      " TRT3         INDEFERIMENTO                           288     182           43     98    112    133     2743\n",
      "            SEM_ANALISE_MERITO                         15     290           95    103    123    154     1572\n",
      "               DEFERIMENTO                            244     124           34     83    113    149      494\n",
      " TRT4         INDEFERIMENTO                           251      53           35     44     47     50      995\n",
      "            SEM_ANALISE_MERITO                           5     84           64     69     84     90      117\n",
      "\n",
      "\n",
      "\n",
      "            – ’reflexos’,\n",
      "            – ’provimento para’\n",
      "\n",
      "     • Termos mais associados com os acórdãos anotados como INDEFERIMENTO.\n",
      "\n",
      "            – ’divergência negou’,\n",
      "            – ’negou lhe’,\n",
      "            – ’negou’,\n",
      "            – ’negar’,\n",
      "            – ’negar provimento’,\n",
      "            – ’unanimidade negar’,\n",
      "            – ’embargos de’,\n",
      "            – ’de declaração’,\n",
      "            – ’embargos’,\n",
      "            – ’declaração’\n",
      "\n",
      "     • Termos          mais    associados       com          os      acórdãos           anotados       como\n",
      "       SEM_ANALISE_MERITO.\n",
      "\n",
      "            – ’ação de’,\n",
      "            – ’de cobrança’,\n",
      "            – ’cobrança de’,\n",
      "            – ’cobrança’,\n",
      "            – ’comum’,\n",
      "            – ’competência’,\n",
      "            – ’não conheceu’,\n",
      "            – ’estadual’,\n",
      "            – ’justiça comum’,\n",
      "            – ’rel’,\n",
      "\n",
      "\n",
      "           A partir da anotação manual dos documentos e também de sua exploração por\n",
      "\f                                                                                      79\n",
      "\n",
      "\n",
      "Figura 6.5: Gráfico que apresenta os termos mais associados com cada uma das classes\n",
      "anotadas. Mais próximas do canto superior esquerdo encontram-se palavras mais asso-\n",
      "ciadas com o rótulo Deferimento. Já próximas do canto inferior direito encontram-se\n",
      "palavras mais associadas com o rótulo Indeferimento.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "meio de técnicas de mineração de texto, foi possível observar diversos padrões de escrita\n",
      "dos magistrados particulares a sua área de domínio. Especialmente em relação aos recur-\n",
      "sos negados, é comum os magistrados utilizarem as mesmas palavras, como, por exemplo,\n",
      "“negar” e suas variações. Por outro lado, é possível observar que os magistrados têm o\n",
      "hábito de utilizar a palavra “dar” e suas variações para representar o deferimento de um\n",
      "recurso.\n",
      "\n",
      "\n",
      "\n",
      "6.3.5 Anotação automática da base de documentos por meio de Supervisão Fraca\n",
      "\n",
      "\n",
      "       A anotação automática de documentos por meio de Supervisão Fraca permite o\n",
      "desenvolvimento rápido de bases de dados para a utilização em algoritmos de classifi-\n",
      "cação de documentos por meio de Aprendizagem de Máquina Supervisionada, além de\n",
      "que a técnica permite a anotação de grande quantidade de instâncias diretamente. Assim,\n",
      "supôs-se que tal técnica poderia ajudar a mitigar ponto negativo da pesquisa em relação\n",
      "a pequena base de documentos anotada manualmente na Seção 6.3.3. Além disso, a ins-\n",
      "piração para utilização dessa técnica foi obtida em vista de que o autor percebeu durante\n",
      "a fase de anotação manual que muitos termos se repetiam e que isso poderia ser usado\n",
      "a favo da pesquisa. Desse modo, optou-se por avaliar a performance dessa técnica em\n",
      "documentos jurídicos. Enfim, foi utilizado o Snorkel Framework (RATNER et al., 2017)\n",
      "para execução dessa etapa.\n",
      "\f80\n",
      "\n",
      "\n",
      "Tabela 6.10: Lista de funções de rotulação criadas para aplicação automática de rótulos à\n",
      "base de dados.\n",
      "     Função de Rotulação            Palavra-chave                Classificação\n",
      "   lf_negar_provimento          negar provimento          INDEFERIMENTO\n",
      "   lf_rejeitar                  rejeitar                  INDEFERIMENTO\n",
      "   lf_nao_acolher               não acolher               INDEFERIMENTO\n",
      "   lf_manter_decisao            manter decisão            INDEFERIMENTO\n",
      "   lf_julgou_improcedente       julgou improcedente       INDEFERIMENTO\n",
      "   lf_dar_provimento            dar provimento            DEFERIMENTO\n",
      "   lf_dar_parcial_provimento dar parcial provimento DEFERIMENTO\n",
      "   lf_proveu                    proveu                    DEFERIMENTO\n",
      "   lf_parcialmente_proveu       parcialmente proveu       DEFERIMENTO\n",
      "   lf_nulidade_sentenca         nulidade sentença         SEM_ANALISE_MERITO\n",
      "   lf_nao_conhecer              não conhecer              SEM_ANALISE_MERITO\n",
      "   lf_deixar_conhecer           deixar conhecer           SEM_ANALISE_MERITO\n",
      "   lf_prejudicada               prejudicada               SEM_ANALISE_MERITO\n",
      "\n",
      "\n",
      "             Assim, prosseguiu-se com a análise dos termos mais associados às classes anota-\n",
      "das em relação ao deferimento do acórdão na Seção 6.3.4. Desse modo, foi possível ob-\n",
      "servar que existem certos padrões na redação dos documentos pelos magistrados, os quais\n",
      "podem ser explorados por meio da criação de Label Functions do Snorkel. Dessa maneira,\n",
      "a análise dessas informações gerou o desenvolvimento de heurísticas que processam por\n",
      "meio de Regex a presença ou não de certas palavras identificadoras do deferimento ou\n",
      "não do recurso pelo magistrado, conforme pode ser observado pela Tabela 6.10. Impor-\n",
      "tante ressaltar que as palavras-chave são testadas utilizando o seu lemma processadas por\n",
      "meio da biblioteca Spacy 5 . Além disso, há a remoção de stopwords que incluem prono-\n",
      "mes oblíquos átonos os quais muitas vezes se encontram no meio de locuções verbais e\n",
      "poderiam interferir na localização das palavras-chave.\n",
      "             Em vista de que foram desenvolvidas diversas Funções de Rotulação para reali-\n",
      "zar a tarefa de classificação dos documentos, houve a sobreposição de classificação em\n",
      "diversas instâncias, como é possível observar pela coluna Sobreposições da Tabela 6.12,\n",
      "entretanto a maioria delas obteve porcentagens abaixo de 10% o que indica baixa sobre-\n",
      "posição. Além disso, podemos observar que houve aproximadamente 10% de rotulações\n",
      "conflitantes em relação às classes INDEFERIMENTO e DEFERIMENTO, e menos de\n",
      "5% em relação à classe SEM_ANALISE_MERITO, ou seja, nesses casos houve uma\n",
      "anotação indicando ao menos duas classes diferentes. Importante ressaltar que as instân-\n",
      "cias que receberam o rótulo ABSTAIN não entram na contagem de conflitantes. O rótulo\n",
      "ABSTAIN é aplicado quando a função de rotulação não tem conhecimento suficiente para\n",
      "     5\n",
      "         <https://spacy.io/>\n",
      "\f                                                                                        81\n",
      "\n",
      "\n",
      "aplicar um rótulo, conforme explicado na Seção 2.6.5. Por outro lado, é possível observar\n",
      "pela Figura 6.6 que aproximadamente 80% das instâncias receberam um rótulo e que em\n",
      "torno de 15% receberam dois ou mais rótulos.\n",
      "       Após, foi utilizado o algoritmo LabelModel do Snorkel para realizar o processa-\n",
      "mento da matriz contendo todas as classificações pelas Funções de Rotulação de modo\n",
      "gerar um modelo probabilístico a fim de ser usado para processar a base de dados com-\n",
      "pleta e finalmente assinalar um rótulo final a cada instância. Cabe salientar que esse\n",
      "modelo probabilístico desenvolvido não tem capacidade de generalização ao realizar o\n",
      "processamento de instâncias que as Funções de Rotulação também não tiveram capaci-\n",
      "dade de aplicar um rótulo, em vista disso, instâncias que receberam o rótulo ABSTAIN,\n",
      "continuaram recebendo esse rótulo nessa fase de processamento.\n",
      "       Desse modo, o modelo treinado foi aplicado à totalidade 22.946 instâncias da base\n",
      "de documentos disponível, tendo efetivamente aplicado rótulo de INDEFERIMENTO,\n",
      "DEFERIMENTO ou SEM_ANALISE_MERITO a 97,91%, como é possível verificar\n",
      "pela Figura 6.7. Também é possível observar que aproximadamente 2% das instâncias\n",
      "receberam o rótulo ABSTAIN, ou seja, o modelo não aplicou nenhum rótulo. Portanto,\n",
      "a tarefa de anotação automática de documentos por meio de técnica de Supervisão Fraca\n",
      "gerou uma nova base de dados contendo o total de 22.471 instâncias.\n",
      "       Importante considerar que os tribunais avaliados disponibilizam centenas de mi-\n",
      "lhares de decisões online de dezenas de anos passados. Entretanto, por dificuldades téc-\n",
      "nicas, não foram possíveis de serem extraídos. Dessa maneira, em trabalhos futuros, essa\n",
      "totalidade de documentos poderiam ser extraídos e processados por meio do Snorkel Fra-\n",
      "mework o que tenderia a aumentar o nível de acurácia alcançado.\n",
      "       Além disso, é possível observar que o modelo generativo do Snorkel Framework\n",
      "não contém capacidade de generalização o que se traduz na sua incapacidade de rotular\n",
      "instâncias que as Funções de Rotulação não continham conhecimento de domínio sufici-\n",
      "ente para aplicar um rótulo correto e por fim aplicaram o rótulo ABSTAIN, nesse caso,\n",
      "em 2% das instâncias disponíveis. Entretanto, a capacidade de generalização é uma ca-\n",
      "racterística desejada em aplicações prática de modo que o modelo tenha habilidade de se\n",
      "adaptar e rotular instâncias previamente não vistas e oriundas da mesma distribuição.\n",
      "       Assim, essa incapacidade de generalização impede a utilização do modelo ge-\n",
      "nerativo do Snorkel Framework para a classificação final da base de dados da presente\n",
      "pesquisa. Desse modo, na Seção 6.4, foram realizados experimentos para o desenvol-\n",
      "vimento de modelo de Aprendizado de Máquina utilizando algoritmos que contenham a\n",
      "\f82\n",
      "\n",
      "\n",
      "Tabela 6.11: Quadro resumo contendo as bases de dados criadas na presente pesquisa\n",
      "incluindo as quantidades de instâncias por classe.\n",
      "                                                            Quantidade por classe\n",
      "            Base de dados             INDEFERIMENTO     DEFERIMENTO SEM_ANALISE_MERITO     Total\n",
      " Padrão-ouro                                      539              441               20    1.000\n",
      " Anotada automaticamente                       12.000           9.923              548    22.471\n",
      " Anotada automaticamente balanceada               548              548             548     1.644\n",
      "\n",
      "\n",
      "\n",
      "capacidade de generalização. E por fim, na Seção 6.5 foi aplicado o modelo desenvolvido\n",
      "selecionado a totalidade de 22.946 instâncias. O que permitiu a anotação da totalidade de\n",
      "documentos disponíveis.\n",
      "        Ademais, da mesma maneira que ocorreu com a base de dados anotada manu-\n",
      "almente, houve grande desbalanceamento da classe SEM_ANALISE_MERITO. Desse\n",
      "modo, foi aplicada técnica de Under-samplig a fim de serem removidas aleatoriamente\n",
      "instâncias das classes INDEFERIMENTO e DEFERIMENTO para conterem finalmente\n",
      "a mesma quantidade que a classe SEM_ANALISE_MERITO, totalizando 548 instâncias\n",
      "para cada classe. Portanto, a base de dados final balanceada criada programaticamente\n",
      "foi gerada contendo o total de 1.644 instâncias. Enfim, por meio da Tabela 6.11, é pos-\n",
      "sível observar a comparação entre todas as bases de dados criadas na presente pesquisa\n",
      "incluindo as quantidades de instâncias por classe.\n",
      "        A checagem dos documentos anotados automaticamente foi realizada pelo próprio\n",
      "autor pela simples observação de algumas instâncias de modo a verificar erros grotescos.\n",
      "Por outro lado, seria inviável realizar a checagem total, além disso, não faz parte da técnica\n",
      "de Supervisão fraca a realização dessa checagem visto que o objetivo é construir a base\n",
      "automaticamente de maneira menos dispendiosa possível em relação ao tempo necessário\n",
      "e em relação ao custo financeiro. Além disso, a checagem é, de certo modo, realizada ao\n",
      "final da pesquisa por meio do treinamento do modelo utilizando a base de dados criada\n",
      "programaticamente e por fim aplicação desse modelo a base de dados padrão-ouro.\n",
      "\n",
      "\n",
      "\n",
      "6.4 Modelagem\n",
      "\n",
      "\n",
      "        Para a atender ao objetivo de mineração de dados contido na Seção 6.1.4, primei-\n",
      "ramente foi desenvolvido um modelo para classificação dos documentos em relação ao\n",
      "tipo de recorrente. Após, foi desenvolvido um modelo para classificação quanto ao defe-\n",
      "rimento ou indeferimento do dispositivo do acórdão. Em ambos os casos foram utilizadas\n",
      "as respectivas bases de documentos anotadas manualmente conforme exposto na Seção\n",
      "6.3.3. Além disso, para o segundo modelo, foi utilizada também base de documentos\n",
      "\f                                                                                      83\n",
      "\n",
      "\n",
      "Tabela 6.12: Apresenta lista com as Funções de Rotulação aplicadas à base de dados e\n",
      "respectivos dados de cobertura, sobreposições e conflitos.\n",
      "    Função de rotulação           Polaridade       Cobertura   Sobreposições   Conflitos\n",
      " lf_negar_provimento           INDEFERIMENTO        0,489410       0,090125    0,063192\n",
      " lf_rejeitar                   INDEFERIMENTO        0,072823       0,055173    0,033078\n",
      " lf_nao_acolher                INDEFERIMENTO        0,016691       0,000959    0,000567\n",
      " lf_manter_decisao             INDEFERIMENTO        0,007060       0,006755    0,002876\n",
      " lf_julgou_improcedente        INDEFERIMENTO        0,013902       0,011418    0,010198\n",
      " lf_dar_provimento              DEFERIMENTO         0,307548       0,073651    0,068160\n",
      " lf_dar_parcial_provimento      DEFERIMENTO         0,168483       0,037741    0,033819\n",
      " lf_proveu                      DEFERIMENTO         0,019873       0,018260    0,014512\n",
      " lf_parcialmente_proveu         DEFERIMENTO         0,001700       0,001700    0,001525\n",
      " lf_nulidade_sentenca        SEM_ANALISE_MERITO     0,007757       0,007104    0,006406\n",
      " lf_nao_conhecer             SEM_ANALISE_MERITO     0,047372       0,030114    0,029766\n",
      " lf_deixar_conhecer          SEM_ANALISE_MERITO     0,003486       0,002310    0,002048\n",
      " lf_prejudicada              SEM_ANALISE_MERITO     0,020047       0,017999    0,017214\n",
      "\n",
      "Figura 6.6: Gráfico de histograma que apresenta as porcentagens dos rótulos aplicados\n",
      "pela Funções de Rotulação.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "anotada programaticamente conforme Seção 6.3.5.\n",
      "\n",
      "\n",
      "\n",
      "6.4.1 Modelo: classificação do tipo de requerente como empregado ou empresa\n",
      "\n",
      "\n",
      "       A fase de preparação e exploração dos dados das seções anteriores resultou em\n",
      "uma lista contendo nomes de partes recorrentes a qual foi anotada manualmente com um\n",
      "rótulo indicando se a parte é empregado ou empresa. Assim, nesta seção são realizados\n",
      "experimentos para avaliar algoritmos de classificação de texto utilizando a base anotada\n",
      "construída.\n",
      "       A fase de avaliação técnica dos modelos desenvolvidos em relação aos níveis dos\n",
      "resultados apresentados foi realizada por meio das bases de dados desenvolvidas na fase\n",
      "\f84\n",
      "\n",
      "\n",
      "Figura 6.7: Gráfico de histograma que apresenta as porcentagens dos rótulos finais apli-\n",
      "cados pelo modelo desenvolvido.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "de anotação manual. Assim, a base de dados foi dividida em 2 partes, 30% para testes\n",
      "e 70% para treinamento dos modelos. Já essa parte de 70% dos dados foi utilizada para\n",
      "treinamento utilizando técnica de Validação Cruzada em 7 camadas, conforme Figura\n",
      "6.8. As bases de documentos do TRT da 3a e 4a Região foram utilizadas em conjunto para\n",
      "treinamento e testes. Além disso, foram escolhidas as métricas acurácia, F1, revocação e\n",
      "precisão para comparação dos resultados.\n",
      "       O treinamento do modelo necessário para classificar o tipo de requerente sendo\n",
      "empregado ou empresa foi desenvolvido a partir de experimentos realizados utilizando\n",
      "os algoritmos de classificação da biblioteca Scikit Learn. Foram testados os seguintes\n",
      "algoritmos: Rocchio classifier, Gradient Boosting Classifier, Naive Bayes Classifier, K-\n",
      "nearest Neighbor, Support Vector Machine (SVM), Decision Tree, Random Forest.\n",
      "       Não foram utilizados algoritmos de Redes Neurais em vista de que esses algorit-\n",
      "mos necessitam de bases de dados contendo uma grande quantidade de instâncias e muita\n",
      "diversidade de features, o que não seria o caso desta base de treinamento. Por outro lado,\n",
      "de modo a garantir a diversidade de métodos de processamento, foram selecionados al-\n",
      "goritmos que utilizam técnicas probabilísticas, técnicas de distância no espaço vetorial e\n",
      "técnicas de ensemble de árvores de decisões.\n",
      "       Desse modo, os experimentos foram realizados utilizando os dados de requeren-\n",
      "tes anotados manualmente de ambos os tribunais de maneira conjunta, ou seja, a lista de\n",
      "requerentes anotada de ambos os tribunais foi unida em uma estrutura de dados única e\n",
      "preparada para o treinamento. Em relação à extração de features foi utilizada a classe\n",
      "CountVectorizer da biblioteca Scikit Learn para realizar a transformação de todas as pa-\n",
      "\f                                                                                      85\n",
      "\n",
      "\n",
      "Figura 6.8: Ilustração do projeto de teste do classificador de tipo de requerente infor-\n",
      "mando as quantidades específicas de instâncias da base de dados.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "lavras para minúsculas e também o algoritmo padrão dessa classe para realização de to-\n",
      "kenização o qual extrai todas as palavras com dois ou mais caracteres, além de tratar\n",
      "caracteres de pontuação como separadores de palavras.\n",
      "       Após, foi aplicada a classe TfidfTransformer a qual gera uma matriz contendo a\n",
      "representação TF-IDF. Não houve a aplicação de nenhuma técnica de redução de dimen-\n",
      "sionalidade específica, tampouco foi realizado tratamento de stop-words ou extração de\n",
      "Lemma das palavras. Quanto aos algoritmos de classificação, foram utilizados os parâme-\n",
      "tros padrão. Essa configuração mostrou-se satisfatória na fase de avaliação de resultados\n",
      "e por isso foi mantida.\n",
      "       Durante a fase de desenvolvimento, foi utilizada apenas a base reservada de 70%\n",
      "dos dados para a realização de experimentos. Assim, foi utilizada técnica de Validação\n",
      "Cruzada em 7 camadas, sendo calculada a média das sete execuções para avaliar a perfor-\n",
      "mance dos algoritmos. Importante ressaltar que também foram utilizadas as matrizes de\n",
      "confusão para verificação de desempenho.\n",
      "       Após o desenvolvimento, foi utilizada a base de 30% para verificação final de\n",
      "desempenho dos algoritmos. Assim, foi selecionado o algoritmo com melhor valor de\n",
      "\f86\n",
      "\n",
      "\n",
      "F1 para a construção do modelo final a ser utilizado na Seção 6.5 para realização de\n",
      "processamento da base de documentos a fim de se atingir o objetivo de negócio e de\n",
      "mineração de texto. Além disso, a construção desse modelo foi realizada utilizando a\n",
      "totalidade da base de documentos anotada manualmente de modo a utilizar a integralidade\n",
      "de instâncias e de features disponíveis.\n",
      "             A avaliação técnica dos modelos desenvolvidos foi realizada conforme o projeto\n",
      "de teste. Na Tabela 6.13 e na Figura 6.9 são apresentados os valores de acurácia, F1,\n",
      "revocação e precisão, sendo possível observar que o algoritmo Support Vector Machine\n",
      "(SVM) obteve o maior valor de F1 com 96,91%, seguido pelo algoritmo Naive Bayes com\n",
      "95,48%. A Tabela 6.14 apresenta a lista de parâmetros escolhidos para o modelo treinado\n",
      "com o algoritmo Support Vector Machine (SVM). A descrição completa dos parâmetros\n",
      "pode ser encontrada no site oficial 6 .\n",
      "\n",
      "Figura 6.9: Métricas calculadas utilizando a base de 30% reservada previamente para\n",
      "testes do modelo de classificação do tipo de requerente.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "6.4.2 Modelo: classificar a decisão em deferimento ou indeferimento\n",
      "\n",
      "\n",
      "             A fase de preparação e exploração dos dados das seções anteriores resultou em\n",
      "uma base de documentos contendo milhares de decisões judiciais. Assim, foi realizada a\n",
      "anotação manual de 1.000 instâncias desses documentos para compor a base padrão-ouro.\n",
      "Assim, nesta seção são realizados experimentos para avaliar algoritmos de classificação de\n",
      "     6\n",
      "         https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html\n",
      "\f                                                                                 87\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Tabela 6.13: Métricas calculadas utilizando a base de 30% reservada previamente para\n",
      "testes do modelo de classificação do tipo de requerente.\n",
      "            Classificador               Acurácia        F1   Precisão Revocação\n",
      "  Rocchio                                 93,83% 94,95%       93,07%       96,91%\n",
      "  Gradient Boosting                       87,65% 90,29%       85,32%       95,88%\n",
      "  Naive Bayes                             94,44% 95,48%       93,14%       97,94%\n",
      "  K-nearest Neighbor                      90,74% 92,15%       93,62%       90,72%\n",
      "  Support Vector Machine (SVM)            96,30% 96,91% 96,91%             96,91%\n",
      "  Decision Tree                           85,80% 87,43%       93,02%       82,47%\n",
      "  Random Forest                           91,36% 93,07%       89,52%       96,91%\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Tabela 6.14: Parâmetros e argumentos do modelo de aprendizado de máquina treinado\n",
      "utilizando o algoritmo SVM LinearSVC da biblioteca Scikit Learning.\n",
      "                              Parâmetro      Argumento\n",
      "                          C                      1.0\n",
      "                          class_weight          None\n",
      "                          dual                  True\n",
      "                          fit_intercept         True\n",
      "                          intercept_scaling        1\n",
      "                          loss              squared_hinge\n",
      "                          max_iter              1000\n",
      "                          multi_class            ovr\n",
      "                          penalty                 l2\n",
      "                          random_state          None\n",
      "                          tol                      1\n",
      "                          verbose                  0\n",
      "\f88\n",
      "\n",
      "\n",
      "texto utilizando a base anotada construída. Também foi construída base de documentos\n",
      "anotada automaticamente para avaliação de técnica de Supervisão Fraca, de técnica de\n",
      "balanceamento de classes e de algoritmos de classificação.\n",
      "\n",
      "\n",
      "6.4.2.1 Experimento com base de dados criada manualmente padrão-ouro\n",
      "\n",
      "       Inicialmente são realizados experimentos de modelagem de dados utilizando a\n",
      "base padrão-ouro.     Assim é utilizada a base contendo 1.000 instâncias, sendo des-\n",
      "tas 539 da classe INDEFERIMENTO, 441 da classe DEFERIMENTO e 20 da classe\n",
      "SEM_ANALISE_MERITO. Desse modo, é possível observar que há grande desbalance-\n",
      "amento das classes.\n",
      "       A avaliação técnica dos modelos desenvolvidos em relação aos níveis dos resul-\n",
      "tados apresentados foi realizada por meio da base de dados padrão-ouro desenvolvida\n",
      "conforme exposto na Seção 6.3.3. Assim, a base de dados foi dividida em 2 partes, 30%\n",
      "para testes e 70% para treinamento dos modelos. Já essa parte de 70% dos dados foi\n",
      "utilizada para treinamento utilizando técnica de Validação Cruzada em 7 camadas, con-\n",
      "forme Figura 6.10. As bases de documentos do TRT da 3a e 4a Região foram utilizadas\n",
      "em conjunto para treinamento e testes. Além disso, foram escolhidas as métricas acu-\n",
      "rácia, f1, revocação e precisão para comparação dos resultados, sendo que, para as três\n",
      "últimas, foram calculas suas métricas macro e micro por tratar-se de uma tarefa com três\n",
      "classes. Importante ressaltar que também foram utilizadas as matrizes de confusão para\n",
      "verificação de desempenho.\n",
      "       O treinamento dos modelos necessários para classificar o dispositivo da decisão foi\n",
      "desenvolvido a partir de experimentos realizados utilizando os algoritmos de classificação\n",
      "da biblioteca Scikit Learn. Foram testados os seguintes algoritmos: Rocchio classifier,\n",
      "Gradient Boosting Classifier, Naive Bayes Classifier, K-nearest Neighbor, Support Vector\n",
      "Machine (SVM), Decision Tree, Random Forest.\n",
      "       Não foram utilizados algoritmos de Redes Neurais em vista de que esses algorit-\n",
      "mos necessitam de bases de dados contendo uma grande quantidade de instâncias e muita\n",
      "diversidade de features, o que não seria o caso desta base de treinamento. Por outro lado,\n",
      "de modo a garantir a diversidade de métodos de processamento, foram selecionados al-\n",
      "goritmos que utilizam técnicas probabilísticas, técnicas de distância no espaço vetorial e\n",
      "técnicas de ensemble de árvores de decisões.\n",
      "       Desse modo, os experimentos foram realizados utilizando os dados da base\n",
      "padrão-ouro de ambos os tribunais de maneira conjunta, ou seja, a lista de decisões ano-\n",
      "\f                                                                                       89\n",
      "\n",
      "\n",
      "Figura 6.10: Ilustração do projeto de teste do classificador de tipo de requerente infor-\n",
      "mando as quantidades específicas de instâncias da base de dados.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tada de ambos os tribunais foi unida em uma estrutura de dados única e preparada para o\n",
      "treinamento. Em relação à extração de features foi utilizada a classe CountVectorizer da\n",
      "biblioteca Scikit Learn para gerar a matriz de termos e documentos. Em conjunto a essa\n",
      "classe, foi utilizada a biblioteca Spacy7 para processamento do lemma dos termos. Tam-\n",
      "bém foi utilizado código Regex de tokenização personalizado para a língua portuguesa\n",
      "que abrangesse palavras com traços, além da remoção de stop-words.\n",
      "           Após, foi aplicada a classe TfidfTransformer a qual gera uma matriz contendo\n",
      "a representação TF-IDF. Não houve a aplicação de nenhuma técnica de redução de di-\n",
      "mensionalidade específica. Quanto aos algoritmos de classificação, foram utilizados os\n",
      "parâmetros padrão. Essa configuração mostrou-se satisfatória na fase de avaliação de\n",
      "resultados e por isso foi mantida.\n",
      "           Durante a fase de desenvolvimento, foi utilizada apenas a base reservada de 70%\n",
      "dos dados para a realização de experimentos. Assim, foi utilizada técnica de Validação\n",
      "Cruzada em 7 camadas, sendo calculada a média das sete execuções para avaliar a perfor-\n",
      "mance dos algoritmos. Importante ressaltar que também foram utilizadas as matrizes de\n",
      "   7\n",
      "       <https://spacy.io/>\n",
      "\f90\n",
      "\n",
      "\n",
      "Tabela 6.15: Modelos treinados com base padrão-ouro e métricas calculadas utilizando a\n",
      "base de 30% reservada previamente para testes do modelo de classificação do deferimento\n",
      "ou não da decisão.\n",
      "                                            Precisão   Revocação              Precisão   Revocação\n",
      "     Classificador    Acurácia   F1 macro                          F1 micro\n",
      "                                             macro      macro                  micro       micro\n",
      "      Rocchio          82,33%     61,68%     62,55%       77,23%    82,33%     82,33%       82,33%\n",
      " Gradient Boosting     98,33%     90,73%     85,96%      98,84%     98,33%     98,33%      98,33%\n",
      "    Naive Bayes        78,67%     51,56%     55,91%       51,57%    78,67%     78,67%       78,67%\n",
      " K-nearest Neighbor    74,67%     48,33%     53,65%       48,66%    74,67%     74,67%       74,67%\n",
      "       SVM             94,00%     62,97%     62,78%       63,19%    94,00%     94,00%       94,00%\n",
      "   Decision Tree       95,00%     74,82%     74,96%       74,71%    95,00%     95,00%       95,00%\n",
      "   Random Forest       94,67%     63,43%     63,08%       63,79%    94,67%     94,67%       94,67%\n",
      "\n",
      "\n",
      "confusão para verificação de desempenho. Após o desenvolvimento, foi utilizada a base\n",
      "de 30% para verificação final de desempenho dos algoritmos.\n",
      "         Os modelos desenvolvidos foram avaliados conforme o projeto de teste. É possível\n",
      "observar por meio da Tabela 6.15 e da Figura 6.11 que há grande discrepância entre os\n",
      "valores macro e micro. Por outro lado, verificando as matrizes de confusão apresentadas\n",
      "na Seção A.6, é visto que a maioria das instâncias da classe SEM_ANALISE_MERITO\n",
      "não foram classificadas corretamente pelos algoritmos que tiveram as piores performances\n",
      "em relação às métricas macro. Isso se deve ao fato do grande desbalanceamento dessa\n",
      "classe, conforme Figura 6.3.\n",
      "\n",
      "Figura 6.11: Modelos treinados com base padrão-ouro e métricas calculadas utilizando a\n",
      "base de 30% reservada previamente para testes do modelo de classificação do deferimento\n",
      "ou não da decisão.\n",
      "\f                                                                                        91\n",
      "\n",
      "\n",
      "6.4.2.2 Experimento com base de dados criada programaticamente balanceada\n",
      "\n",
      "          Primeiramente é realizada a modelagem dos dados utilizando a base de dados\n",
      "criada automaticamente balanceada. Nesse caso, a base contém 1.644 instâncias, sendo\n",
      "destas 548 da classe INDEFERIMENTO, 548 da classe DEFERIMENTO e 548 da classe\n",
      "SEM_ANALISE_MERITO, estando assim, as classes totalmente niveladas.\n",
      "          A avaliação técnica dos modelos desenvolvidos em relação aos níveis dos resul-\n",
      "tados apresentados foi realizada por meio da base de dados padrão-ouro desenvolvida\n",
      "conforme exposto na Seção 6.3.3. Desse modo, houve o treinamento com a base de da-\n",
      "dos balanceada criada programaticamente e realizado o teste cruzado com a base anotada\n",
      "manualmente. Da mesma maneira, neste caso foram escolhidas as métricas acurácia, f1,\n",
      "revocação e precisão para comparação dos resultados, sendo que, para as três últimas, fo-\n",
      "ram calculadas suas métricas macro e micro por tratar-se de uma tarefa com três classes.\n",
      "Importante ressaltar que também foram utilizadas as matrizes de confusão para verifica-\n",
      "ção de desempenho.\n",
      "          O treinamento dos modelos foi realizado utilizando os algoritmos de classificação\n",
      "da biblioteca Scikit Learn. Foram testados os seguintes algoritmos: Rocchio classifier,\n",
      "Gradient Boosting Classifier, Naive Bayes Classifier, K-nearest Neighbor, Support Vector\n",
      "Machine (SVM), Decision Tree, Random Forest.\n",
      "          Não foram utilizados algoritmos de Redes Neurais em vista de que esses algorit-\n",
      "mos necessitam de bases de dados contendo uma grande quantidade de instâncias e muita\n",
      "diversidade de features, o que não seria o caso desta base de treinamento. Por outro lado,\n",
      "de modo a garantir a diversidade de métodos de processamento, foram selecionados al-\n",
      "goritmos que utilizam técnicas probabilísticas, técnicas de distância no espaço vetorial e\n",
      "técnicas de ensemble de árvores de decisões.\n",
      "          Desse modo, os experimentos foram realizados utilizando a base de dados balan-\n",
      "ceada criada programaticamente, conforme Seção 6.3.5, incluindo os dados de ambos os\n",
      "tribunais de maneira conjunta, ou seja, a lista de decisões anotada de ambos os tribunais\n",
      "foi unida em uma estrutura de dados única e preparada para o treinamento. Em relação à\n",
      "extração de features foi utilizada a classe CountVectorizer da biblioteca Scikit Learn para\n",
      "gerar a matriz de termos e documentos. Em conjunto a essa classe, foi utilizada a bibli-\n",
      "                 8\n",
      "oteca Spacy          para processamento do lemma dos termos. Também foi utilizado código\n",
      "Regex de tokenização personalizado para a língua portuguesa que abrangesse palavras\n",
      "com traços, além da remoção de stop-words. Após, foi aplicada a classe TfidfTransfor-\n",
      "  8\n",
      "      <https://spacy.io/>\n",
      "\f92\n",
      "\n",
      "\n",
      "Tabela 6.16: Modelos treinados utilizando base criada programaticamente balanceada\n",
      "e métricas calculadas utilizando a base de dados padrão-ouro para testes do modelo de\n",
      "classificação do deferimento ou não da decisão.\n",
      "        Classificador           Acurácia   F1 macro    Precisão macro    Revocação macro    F1 micro   Precisão micro   Revocação micro\n",
      "      Rocchio classifier           0,689      0,5658            0,6361             0,7606      0,689            0,689             0,689\n",
      " Gradient Boosting Classifier      0,946      0,8475            0,8049             0,9446      0,946            0,946             0,946\n",
      "         Naive Bayes               0,748      0,6009            0,6401             0,7957      0,748            0,748             0,748\n",
      "     K-nearest Neighbor            0,741      0,5826            0,5963             0,6705      0,741            0,741             0,741\n",
      "Support Vector Machine (SVM)       0,942      0,8179             0,776             0,9271      0,942            0,942             0,942\n",
      "        Decision Tree              0,944      0,8441            0,7977             0,9599      0,944            0,944             0,944\n",
      "       Random Forest               0,956      0,8684            0,8201             0,9692      0,956            0,956             0,956\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "mer a qual gera uma matriz contendo a representação TF-IDF. Não houve a aplicação de\n",
      "nenhuma técnica de redução de dimensionalidade específica. Quanto aos algoritmos de\n",
      "classificação, foram utilizados os parâmetros padrão.\n",
      "          Os modelos desenvolvidos foram avaliados conforme o projeto de teste. Desse\n",
      "modo, os modelos foram treinados utilizando toda a base de dados criada programati-\n",
      "camente balanceada e foram usados para classificar toda a base padrão-ouro. A Tabela\n",
      "6.16 e a Figura 6.12 apresentam as métricas de avaliação. É possível verificar que a\n",
      "performance máxima dos modelos em relação a métrica f1 macro foi inferior ao valor\n",
      "reportado na Seção 6.4.2.1 tendo nenhum classificador alcançado valor maior que 90%.\n",
      "Por outro lado, houve a concentração de algoritmos com média f1 macro entre 80% e\n",
      "90%. Além disso, avaliando as matrizes de confusão presentes na Seção A.7 é possí-\n",
      "vel verificar que todos os algoritmos tiveram classificações corretas em relação à classe\n",
      "SEM_ANALISE_MERITO, diferente do que ocorreu no experimento da Seção 6.4.2.1,\n",
      "o que pode ser considerado um efeito positivo da base de dados balanceada com número\n",
      "maior de instâncias.\n",
      "\n",
      "\n",
      "6.4.2.3 Experimento com base de dados criada programaticamente completa\n",
      "\n",
      "          Neste experimento foi realizada a modelagem dos dados utilizando a base de da-\n",
      "dos criada automaticamente completa. Assim, foi utilizada a base anotada automatica-\n",
      "mente completa contendo 22.471 instâncias, sendo destas 12.000 da classe INDEFERI-\n",
      "MENTO, 9.923 da classe DEFERIMENTO e 548 da classe SEM_ANALISE_MERITO.\n",
      "Desse modo, é possível observar que também há grande desbalanceamento das classes.\n",
      "          Os experimentos realizados para desenvolvimento do modelo para classificar o\n",
      "dispositivo da decisão foram realizados utilizando os algoritmos de classificação da bibli-\n",
      "oteca Scikit Learn. Foram testados os seguintes algoritmos: Rocchio classifier, Gradient\n",
      "Boosting Classifier, Naive Bayes Classifier, K-nearest Neighbor, Support Vector Machine\n",
      "(SVM), Decision Tree, Random Forest.\n",
      "\f                                                                                        93\n",
      "\n",
      "\n",
      "Figura 6.12: Modelos treinados utilizando base criada programaticamente balanceada e\n",
      "métricas calculadas utilizando a base de dados padrão-ouro para testes do modelo de\n",
      "classificação do deferimento ou não da decisão.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "          Não foram utilizados algoritmos de Redes Neurais em vista de que esses algorit-\n",
      "mos necessitam de bases de dados contendo uma grande quantidade de instâncias e muita\n",
      "diversidade de features, o que não seria o caso desta base de treinamento. Por outro lado,\n",
      "de modo a garantir a diversidade de métodos de processamento, foram selecionados al-\n",
      "goritmos que utilizam técnicas probabilísticas, técnicas de distância no espaço vetorial e\n",
      "técnicas de ensemble de árvores de decisões.\n",
      "          Desse modo, os experimentos foram realizados utilizando a base de dados com-\n",
      "pleta criada programaticamente, conforme Seção 6.3.5, incluindo os dados de ambos os\n",
      "tribunais de maneira conjunta, ou seja, a lista de decisões anotada de ambos os tribunais\n",
      "foi unida em uma estrutura de dados única e preparada para o treinamento. Em relação a\n",
      "extração de features foi utilizada a classe CountVectorizer da biblioteca Scikit Learn para\n",
      "gerar a matriz de termos e documentos. Em conjunto a essa classe, foi utilizada a bibli-\n",
      "                 9\n",
      "oteca Spacy          para processamento do lemma dos termos. Também foi utilizado código\n",
      "Regex de tokenização personalizado para a língua portuguesa que abrangesse palavras\n",
      "com traços, além da remoção de stop-words.\n",
      "          Após, foi aplicada a classe TfidfTransformer a qual gera uma matriz contendo\n",
      "\n",
      "  9\n",
      "      <https://spacy.io/>\n",
      "\f94\n",
      "\n",
      "\n",
      "Tabela 6.17: Modelos treinados utilizando base criada programaticamente completa e\n",
      "métricas calculadas utilizando a base de dados padrão-ouro para testes do modelo de\n",
      "classificação do deferimento ou não da decisão.\n",
      "        Classificador           Acurácia   F1 macro    Precisão macro    Revocação macro    F1 micro   Precisão micro   Revocação micro\n",
      "      Rocchio classifier           0,721       0,584            0,6306             0,7813      0,721            0,721             0,721\n",
      " Gradient Boosting Classifier      0,954      0,9248            0,9053             0,9504      0,954            0,954             0,954\n",
      "         Naive Bayes               0,846      0,5673            0,5721             0,5696      0,846            0,846             0,846\n",
      "     K-nearest Neighbor            0,806      0,5648            0,7378              0,552      0,806            0,806             0,806\n",
      "Support Vector Machine (SVM)       0,961      0,9157            0,9237             0,9083      0,961            0,961             0,961\n",
      "        Decision Tree              0,951      0,9168            0,8936             0,9484      0,951            0,951             0,951\n",
      "        Random Forest               0,96      0,9179            0,9137             0,9231       0,96             0,96              0,96\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "a representação TF-IDF. Não houve a aplicação de nenhuma técnica de redução de di-\n",
      "mensionalidade específica. Quanto aos algoritmos de classificação, foram utilizados os\n",
      "parâmetros padrão. Essa configuração mostrou-se satisfatória na fase de avaliação de\n",
      "resultados e por isso foi mantida.\n",
      "           Os modelos desenvolvidos foram avaliados conforme o projeto de teste. Desse\n",
      "modo, os modelos foram treinados utilizando toda a base de dados criada programatica-\n",
      "mente e foram usados para classificar toda a base padrão-ouro. A Tabela 6.17 e a Figura\n",
      "6.13 apresentam as métricas de avaliação. É possível verificar que houve quatro modelos\n",
      "que obtiveram performance máxima em relação a métrica f1 macro superiores aos valores\n",
      "reportados na Seção 6.4.2.1 e na Seção 6.4.2.2.\n",
      "           Além disso, avaliando as matrizes de confusão presentes na Seção 6.4.2.1 é pos-\n",
      "sível verificar que alguns algoritmos não obtiveram classificações em relação à classe\n",
      "SEM_ANALISE_MERITO o que resultou em métricas f1 macro em torno de 60%. En-\n",
      "fim, o modelo que obteve a melhor média f1 macro, a saber, Gradient Boosting, foi se-\n",
      "lecionado para realizar a classificação final de toda a base de documentos para análise\n",
      "na Seção 6.5. A Tabela 6.18 apresenta a lista de parâmetros escolhidos para o modelo\n",
      "treinado com o algoritmo Gradient Boosting. A descrição completa dos parâmetros pode\n",
      "ser encontrada no site oficial 10 .\n",
      "\n",
      "\n",
      "\n",
      "6.5 Avaliação de resultados\n",
      "\n",
      "\n",
      "           O processo de mineração de dados textuais de decisões judiciais elaborado resul-\n",
      "tou no desenvolvimento de dois modelos baseados em aprendizado de máquina super-\n",
      "visionado e na sua utilização para o processamento de 22.946 decisões judiciais, sendo\n",
      "12.071 do TRT da 4a Região e 10.875 do TRT da 3a Região. Com a utilização desses mo-\n",
      "delos, os objetivos de mineração foram atingidos que eram classificar automaticamente\n",
      "\n",
      "  10\n",
      "       https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html\n",
      "\f                                                                                       95\n",
      "\n",
      "\n",
      "Figura 6.13: Modelos treinados utilizando base criada programaticamente completa e\n",
      "métricas calculadas utilizando a base de dados padrão-ouro para testes do modelo de\n",
      "classificação do deferimento ou não da decisão.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "os acórdãos judiciais em relação ao deferimento ou não e classificar automaticamente o\n",
      "requerente do recurso em relação a ser empresa ou a ser empregado. Cabe salientar que,\n",
      "após a aplicação dos modelos de classificação, todas as instâncias que receberam o ró-\n",
      "tulo SEM_ANALISE_MERITO foram removidas da análise, pois não interessavam aos\n",
      "objetivos de negócio e de mineração de texto.\n",
      "       Desse modo, foi possível atender também ao objetivo de negócio para verificar a\n",
      "validade da hipótese por meio de teste estatístico se seria possível que os tribunais ava-\n",
      "liados e suas turmas recursais julguem favoravelmente proporção maior de recursos para\n",
      "uma das partes do que para outra. Assim, também são apresentadas a conclusão e a inter-\n",
      "pretação dos testes estatísticos de proporção, força e efeito. Após, foram desenvolvidos\n",
      "relatórios com gráficos para apresentar os resultados obtidos com o processamento dos\n",
      "documentos.\n",
      "\f96\n",
      "\n",
      "\n",
      "Tabela 6.18: Parâmetros e argumentos do modelo de aprendizado de máquina treinado\n",
      "utilizando o algoritmo Gradient Boosting da biblioteca Scikit Learning.\n",
      "                               Parâmetro            Argumento\n",
      "                       ccp_alpha                         0.0\n",
      "                       criterion                   friedman_mse\n",
      "                       init                             None\n",
      "                       learning_rate                     0.1\n",
      "                       loss                           deviance\n",
      "                       max_depth                          3\n",
      "                       max_features                     None\n",
      "                       max_leaf_nodes                   None\n",
      "                       min_impurity_decrease             0.0\n",
      "                       min_samples_leaf                   1\n",
      "                       min_samples_split                  2\n",
      "                       min_weight_fraction_leaf          0.0\n",
      "                       n_estimators                      100\n",
      "                       n_iter_no_change                 None\n",
      "                       random_state                      1.0\n",
      "                       subsample                       0.0001\n",
      "                       tol                               0.1\n",
      "                       validation_fraction               0.1\n",
      "                       verbose                            0\n",
      "                       warm_start                       False\n",
      "\n",
      "\n",
      "\n",
      "6.5.1 TRT da 4a Região - avaliação geral\n",
      "\n",
      "\n",
      "       Na Figura 6.14 é possível observar a porcentagem da quantidade de recursos de-\n",
      "feridos e indeferidos no TRT da 4a Região em relação ao recorrente ser empresa ou em-\n",
      "pregado. Assim, é possível verificar que 50% dos recursos impetrados pelos empregados\n",
      "foram deferidos ou parcialmente deferidos. Além disso, também é possível verificar que,\n",
      "dos recursos impetrados pelas empresas, 39% foram julgados deferidos ou parcialmente\n",
      "deferidos. Por outro lado, fica evidente a diferença de 12% na quantidade de recursos\n",
      "deferidos ou parcialmente deferidos quando o recorrente são os empregados. Importante\n",
      "frisar que essa média leva em consideração amostra dos acórdãos proferidos por todas as\n",
      "Turmas Recursais do tribunal em conjunto.\n",
      "       Nessa amostra foram processados 11.351 acórdãos, sendo 9.398 recursos da parte\n",
      "empregado e 1.953 recursos da parte empresa. A parte empresa recorreu aproximada-\n",
      "mente 4 vezes menos do que a parte empregado. Além disso, em relação aos testes esta-\n",
      "tísticos aplicados, foi obtido P-value de 0%, ou seja, há grande confiança de que existe\n",
      "diferença estatística entre a proporção de deferimentos para empregado e para empresa.\n",
      "\f                                                                                                             97\n",
      "\n",
      "\n",
      "Figura 6.14: Porcentagem de deferimento de recursos em relação ao recorrente ser em-\n",
      "presa e empregado no Tribunal Regional do Trabalho da 4a Região.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Tabela 6.19: Porcentagem de deferimento de recursos em relação ao recorrente ser em-\n",
      "presa e empregado das Turmas Recursais do Tribunal Regional do Trabalho da 4a Região.\n",
      "             TURMA        TOTAL DE                 PVALUE                   POWER                    EFFECT\n",
      "TRIBUNAL                             PVALUE                      POWER                  EFFECT\n",
      "            RECURSAL     PROCESSOS                 INTERP.                  INTERP.                  INTERP.\n",
      "   TRT4       1a Turma      1.639    0,7172   NÃO HÁ DIFERENÇA   0,0863   INACEITÁVEL   0,0217   INSIGNIFICANTE\n",
      "   TRT4       2a Turma      1.704       0       HÁ DIFERENÇA        1      ACEITÁVEL    0,5267        MÉDIA\n",
      "   TRT4       3a Turma      1.832       0       HÁ DIFERENÇA        1      ACEITÁVEL    0,4853      PEQUENA\n",
      "   TRT4       4a Turma      1.800    0,0343     HÁ DIFERENÇA     0,9575    ACEITÁVEL    0,1343   INSIGNIFICANTE\n",
      "   TRT4       5a Turma      1.504    0,0003     HÁ DIFERENÇA     0,9999    ACEITÁVEL    0,2355      PEQUENA\n",
      "   TRT4       6a Turma      1.171    0,1741   NÃO HÁ DIFERENÇA    0,638   INACEITÁVEL   0,1051   INSIGNIFICANTE\n",
      "   TRT4       7a Turma       825     0,1687   NÃO HÁ DIFERENÇA   0,6817   INACEITÁVEL   0,1307   INSIGNIFICANTE\n",
      "   TRT4       8a Turma       448     0,0032     HÁ DIFERENÇA     0,9988    ACEITÁVEL     0,366      PEQUENA\n",
      "   TRT4       9a Turma       131     0,1106   NÃO HÁ DIFERENÇA   0,8029    ACEITÁVEL    0,3813      PEQUENA\n",
      "   TRT4      10a Turma       115     0,0752   NÃO HÁ DIFERENÇA   0,7266   INACEITÁVEL   0,3892      PEQUENA\n",
      "   TRT4      11a Turma       182     0,3001   NÃO HÁ DIFERENÇA   0,4141   INACEITÁVEL   0,2038      PEQUENA\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Em relação ao nível de efeito estatístico em função da tabela Cohen’s, foi obtido o índice\n",
      "de 22,11%, ou seja, o nível de efeito estatístico da diferença de proporções é pequeno.\n",
      "Quanto à força do teste estatístico, foi obtido o 100%, ou seja, foi alcançado nível aceitá-\n",
      "vel de força estatística e há risco baixo de não haver diferença entre as proporções.\n",
      "\n",
      "\n",
      "\n",
      "6.5.2 TRT da 4a Região - avaliação das Turmas Recursais\n",
      "\n",
      "\n",
      "          Em relação a dados individuais de cada uma das Turmas Recursais do TRT da 4a\n",
      "Região, Figura 6.15, é possível verificar que as Turmas Recursais 2a , 3a , 5a , 8a , 9a e 11a\n",
      "apresentaram proporção parecida com a do tribunal para empregados. Por outro lado, a\n",
      "Figura 6.16 apresenta a distribuição das proporções de deferimentos das turmas recursais.\n",
      "Além disso, na Tabela 6.19 são apresentados os dados em relação aos testes estatísticos\n",
      "aplicados, como o P-Value, Power e Effect. Assim, é possível verificar que há diversas\n",
      "turmas recursais que o Power está abaixo de 0,8, o que ocorre devido à pouca quantidade\n",
      "de dados para análise, entretanto é possível superar essa limitação pela ingestão de mais\n",
      "observações em trabalhos futuros.\n",
      "\f98\n",
      "\n",
      "\n",
      "Figura 6.15: Porcentagem de deferimento de recursos em relação ao recorrente ser em-\n",
      "presa e empregado das Turmas Recursais do Tribunal Regional do Trabalho da 4a Região.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "6.5.3 TRT da 3a Região - avaliação geral\n",
      "\n",
      "\n",
      "       Na Figura 6.17 é possível observar a porcentagem da quantidade de recursos defe-\n",
      "ridos e indeferidos no TRT da 3a Região em relação ao recorrente ser empresa ou empre-\n",
      "gado. Assim, é possível verificar que 41,31% dos recursos impetrados pelos empregados\n",
      "foram deferidos ou parcialmente deferidos. Além disso, também é possível verificar que,\n",
      "dos recursos impetrados pelas empresas, 39,07% foram julgados deferidos ou parcial-\n",
      "mente deferidos. Fica evidente a diferença de 2,24% na quantidade de recursos deferidos\n",
      "ou parcialmente deferidos quando o recorrente são os empregados. Importante frisar que\n",
      "essa média leva em consideração amostra dos acórdãos proferidos por todas as Turmas\n",
      "Recursais do tribunal em conjunto.\n",
      "       Nessa amostra foram processados 10.477 acórdãos, sendo 7.349 recursos da parte\n",
      "\f                                                                                        99\n",
      "\n",
      "\n",
      "Figura 6.16: Distribuição da porcentagem de deferimento de recursos em relação ao recor-\n",
      "rente ser empresa e empregado das Turmas Recursais do Tribunal Regional do Trabalho\n",
      "da 4a Região.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Figura 6.17: Porcentagem de deferimento de recursos em relação ao recorrente ser em-\n",
      "presa e empregado no Tribunal Regional do Trabalho da 3a Região.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "empregado e 3.128 recursos da parte empresa. Nessa amostra a parte empresa recorreu\n",
      "aproximadamente 2 vezes menos do que a parte empregado. Além disso, em relação aos\n",
      "testes estatísticos aplicados, foi obtido P-value de 3,19%, ou seja, há grande confiança\n",
      "de que existe diferença estatística entre a proporção de deferimentos para empregado e\n",
      "para empresa. Em relação ao nível de efeito estatístico em função da tabela Cohen’s, foi\n",
      "obtido o índice de 4,58%, ou seja, o nível de efeito estatístico da diferença de proporções\n",
      "é insignificante. Quanto à força do teste estatístico, foi obtido o 79,28%, ou seja, foi\n",
      "alcançado nível abaixo do aceitável de força estatística e há risco de não haver diferença\n",
      "\f100\n",
      "\n",
      "\n",
      "Tabela 6.20: Porcentagem de deferimento de recursos em relação ao recorrente ser em-\n",
      "presa e empregado das Turmas Recursais do Tribunal Regional do Trabalho da 3a Região.\n",
      "            TURMA        TOTAL DE                 PVALUE                     POWER                     EFFECT\n",
      "TRIBUNAL                            PVALUE                      POWER                    EFFECT\n",
      "           RECURSAL     PROCESSOS             INTERPRETACAO              INTERPRETAÇÃO            INTERPRETACAO\n",
      "  TRT3       1a Turma      1058        0       HÁ DIFERENÇA        1        ACEITÁVEL    0,3749       PEQUENA\n",
      "  TRT3       2a Turma       906     0,4009   NÃO HÁ DIFERENÇA   0,1789     INACEITÁVEL   0,0591    INSIGNIFICANTE\n",
      "  TRT3       3a Turma       938     0,1047   NÃO HÁ DIFERENÇA   0,5978     INACEITÁVEL   0,1193    INSIGNIFICANTE\n",
      "  TRT3       4a Turma       931     0,0014     HÁ DIFERENÇA     0,9803      ACEITÁVEL    0,2245       PEQUENA\n",
      "  TRT3       5a Turma       889     0,3495   NÃO HÁ DIFERENÇA   0,2372     INACEITÁVEL   0,0692    INSIGNIFICANTE\n",
      "  TRT3       6a Turma       973     0,0116     HÁ DIFERENÇA     0,9142      ACEITÁVEL    0,1788    INSIGNIFICANTE\n",
      "  TRT3       7a Turma      1025        0       HÁ DIFERENÇA        1        ACEITÁVEL    0,4839       PEQUENA\n",
      "  TRT3       8a Turma       850     0,0762   NÃO HÁ DIFERENÇA   0,6205     INACEITÁVEL   0,1321    INSIGNIFICANTE\n",
      "  TRT3       9a Turma      1016        0       HÁ DIFERENÇA        1        ACEITÁVEL    0,5803         MÉDIA\n",
      "  TRT3      10a Turma       957     0,0394     HÁ DIFERENÇA      0,747     INACEITÁVEL   0,1443    INSIGNIFICANTE\n",
      "  TRT3      11a Turma       934        0       HÁ DIFERENÇA        1        ACEITÁVEL    0,3518       PEQUENA\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "entre as proporções. A saber, o nível de força estatística considerado aceitável é de 80%.\n",
      "\n",
      "\n",
      "\n",
      "6.5.4 TRT da 3a Região - avaliação das Turmas Recursais\n",
      "\n",
      "\n",
      "         Em relação a dados individuais de cada uma das Turmas Recursais do TRT da\n",
      "3a Região, Figura 6.18, é possível verificar que as Turmas Recursais 1a , 4a , 7a , 8a e 11a\n",
      "apresentaram proporção de deferimentos maior para empregados. Por outro lado, 6 das\n",
      "11 Turmas Recursais apresentaram proporção de deferimentos maior para empresas. A\n",
      "Figura 6.19 apresenta a distribuição das proporções de deferimentos das turmas recursais.\n",
      "Além disso, na Tabela 6.20 são apresentados os dados em relação aos testes estatísticos\n",
      "aplicados, como o P-Value, Power e Effect. Assim, é possível verificar que há diversas\n",
      "turmas recursais que o Power está abaixo de 0,8, o que ocorre devido à pouca quantidade\n",
      "de dados para análise, entretanto é possível superar essa limitação pela ingestão de mais\n",
      "observações em trabalhos futuros.\n",
      "\n",
      "\n",
      "\n",
      "6.6 Aplicação\n",
      "\n",
      "\n",
      "         A presente pesquisa não necessita da realização de deployment dos modelos de-\n",
      "senvolvidos em nenhuma infraestrutura de processamento de dados para serem utilizados.\n",
      "Entretanto, é importante ressaltar algumas considerações em relação a futuras utilizações\n",
      "dos modelos desenvolvidos. Assim, ambos os modelos desenvolvidos assumem que os\n",
      "documentos estejam redigidos em língua portuguesa formal, ou seja, sem erros comuns\n",
      "de digitação. Além disso, seria interessante o monitoramento dos textos das decisões de\n",
      "modo à manutenção da qualidade das previsões, pois os níveis de acurácia dos modelos\n",
      "desenvolvidos dependem necessariamente de que os dados ingeridos estejam em níveis\n",
      "\f                                                                                    101\n",
      "\n",
      "\n",
      "Figura 6.18: Porcentagem de deferimento de recursos em relação ao recorrente ser em-\n",
      "presa e empregado das Turmas Recursais do Tribunal Regional do Trabalho da 3a Região.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "de qualidade previstos.\n",
      "\n",
      "\n",
      "\n",
      "6.7 Limitações\n",
      "\n",
      "\n",
      "       Os experimentos da presente pesquisam apresentaram certas limitações, como por\n",
      "exemplo, a utilização do formato de redação dos documentos processados. Assim, o\n",
      "algoritmo de aprendizado de máquina desenvolvido levou em consideração padrões de\n",
      "formatação e redação específicos ao corpus jurídico dos Tribunais avaliados. Além disso,\n",
      "não é possível afirmar com certeza que outros tribunais sigam os mesmos padrões, pois\n",
      "não foi realizado experimento de análise de documentos dos demais tribunais brasileiros.\n",
      "Entretanto, essas informações contextuais dos documentos podem ser consideradas úteis\n",
      "\f102\n",
      "\n",
      "\n",
      "Figura 6.19: Distribuição da porcentagem de deferimento de recursos em relação ao recor-\n",
      "rente ser empresa e empregado das Turmas Recursais do Tribunal Regional do Trabalho\n",
      "da 3a Região.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "para os algoritmos, pois elas mimicam a forma como os usuários, advogados e praticantes\n",
      "da atividade jurídica, leem os documentos.\n",
      "       Entretanto, não era objetivo da pesquisa, em um primeiro momento, o desenvolvi-\n",
      "mento de um algoritmo que processasse documentos de diversos formatos de redação de\n",
      "diversos tribunais diferentes. Desse modo, a padronização de redação dos documentos foi\n",
      "explorada a fim de se alcançar maior otimização do algoritmo. Por outro lado, mesmo em\n",
      "áreas devidamente estabelecidas, como a mineração de sentimentos, é possível encontrar\n",
      "algoritmos desenvolvidos especificamente para certos nichos, como é o caso dos micro-\n",
      "blogs, como o Twitter, que implicam desafios particulares devido a especificidades dos\n",
      "documentos encontrados (LIPPI; TORRONI, 2016).\n",
      "       Além disso, foi realizado o processamento de acórdãos judiciais em que houve\n",
      "apenas uma das partes recorrente. Desse modo, todos os documentos em que havia a\n",
      "apreciação de mais de um recurso foram removidos da base de dados. Entretanto, foi\n",
      "considerado que tal filtragem não apresentou prejuízos aos experimentos, visto que havia\n",
      "grande quantidade de documentos disponíveis para análise de acordo com técnicas de\n",
      "definição de amostra estatística, conforme Seção 6.2.1.2.\n",
      "       Outro fator que pode ser considerado uma limitação da pesquisa é o tamanho da\n",
      "\f                                                                                       103\n",
      "\n",
      "\n",
      "base de dados padrão-ouro desenvolvido na Seção 6.3.3. Entretanto, essa questão foi\n",
      "mitiga por meio da aplicação de técnica de Supervisão Fraca a qual permitiu explorar a\n",
      "grande quantidade de documentos disponíveis para o treinamento dos modelos desenvol-\n",
      "vidos na pesquisa, conforme Seção 6.3.5. Cabe salientar também as limitações impostas\n",
      "pelas próprias técnicas de Aprendizado de Máquinas utilizadas na pesquisa, como, por\n",
      "exemplo, o viés ou a tendência inserida pelo algoritmo, que, para desenvolver um mo-\n",
      "delo, precisa realizar suposições e generalizações.\n",
      "\n",
      "\n",
      "\n",
      "6.8 Resumo do Capítulo\n",
      "\n",
      "\n",
      "       Neste capítulo é apresentada a validação experimental completa da pesquisa de\n",
      "acordo com as metodologias propostas. Assim, iniciou-se pela elucidação dos elementos\n",
      "fundamentais do estudo que nortearam todas as fases seguintes por meio da Seção Com-\n",
      "preensão do negócio. Nessa seção foram definidos os objetivos principais da validação\n",
      "experimental no contexto de negócio e de mineração de dados.\n",
      "       Após, na Seção Compreensão dos dados, iniciou-se a execução prática da pesquisa\n",
      "por meio da coleta dos dados da internet e da exploração inicial dos documentos obti-\n",
      "dos. Essa fase trouxe resultados positivos para a pesquisa pois permitiu aferir a qualidade\n",
      "dos dados como também permitiu analisar o conteúdo dos documentos. Essa análise do\n",
      "conteúdo proporcionou inspiração positiva para o desenvolvimento de uma técnica para\n",
      "reduzir o tamanho dos documentos, a qual foi implementada na fase seguinte da pesquisa.\n",
      "       Já na fase da Seção Preparação dos dados houve a impressão de grande esforço\n",
      "para a preparação da melhor maneira possível de toda base de documentos para ser utili-\n",
      "zada na fase de modelagem de dados. Assim, primeiramente foi realizada a devida lim-\n",
      "peza de caracteres e documentos que não atingiam a qualidade mínima para a pesquisa.\n",
      "Após, foram aplicadas as transformações nos documentos idealizadas na fase anterior da\n",
      "pesquisa. Assim, foram extraídos apenas os dispositivos das decisões judiciais. É nos\n",
      "dispositivos do documento que contém as features necessárias para que os algoritmos de\n",
      "modelagem possam classificar corretamente as instâncias.\n",
      "       Ainda na fase de preparação dos dados, na Seção 6.3.3, houve a criação da base de\n",
      "documentos padrão-ouro, a qual foi desenvolvida não apenas com esforço do autor, como\n",
      "também de duas pessoas bacharéis em Direito. Dessa maneira, a base foi utilizada para a\n",
      "realização de testes dos modelos de Aprendizado de Máquina Supervisionado desenvol-\n",
      "vidos, como também para análise exploratório dos documentos, mas neste caso, fazendo\n",
      "\f104\n",
      "\n",
      "\n",
      "a análise cruzada com os rótulos das instâncias. Essa análise permitiu-se inferir featu-\n",
      "res que viabilizaram a criação de Funções de Rotulação utilizando o Snorkel Framework\n",
      "para aplicação de técnica de Supervisão Fraca, para criar uma base de documentos para\n",
      "treinamento muito maior do que a base padrão-ouro.\n",
      "       Na sequência, a Seção Modelagem apresenta a execução de quatro experimentos\n",
      "de modelagem de dados por meio de algoritmos de Aprendizado de Máquina Supervisio-\n",
      "nado. Assim, primeiramente foram avaliados diversos algoritmos para o desenvolvimento\n",
      "de um modelo para realizar a classificação dos documentos em relação ao tipo de parte\n",
      "requerente no processo, sendo ela empregado ou empresa. Nesse caso, o algoritmo que\n",
      "apresentou a melhor performance e foi escolhido foi o Support Vector Machine (SVM).\n",
      "Em relação aos outros três experimentos realizados nessa seção, em ambos foram avalia-\n",
      "dos diversos algoritmos para o desenvolvimento de um modelo para realizar a classifica-\n",
      "ção dos documentos em relação ao deferimento ou não do recurso impetrado. Entretanto,\n",
      "o que diferencia é a base de documentos utilizada. Desse modo, no segundo experimento\n",
      "os algoritmos foram treinados utilizando a base de dados padrão-ouro a qual continha\n",
      "1.000 instâncias para treinamento, mas as suas classes estavam muito desbalanceadas.\n",
      "No terceiro experimento foi avaliado o treinamento dos mesmos algoritmos utilizando a\n",
      "base de documentos criada automaticamente contendo 1.644 instâncias, mas nesse caso\n",
      "totalmente balanceada. Por último, foi realizado experimento de treinamento utilizando\n",
      "a base de documentos criada automaticamente contendo a totalidade das instâncias ano-\n",
      "tadas de 22.471, mas nesse caso muito desbalanceada para uma das classes. Enfim, foi\n",
      "realizada a avaliação técnica dos modelos desenvolvidos e selecionado o modelo criado\n",
      "com o algoritmo Gradient Boosting para a classificação efetiva dos documentos.\n",
      "       Por fim, na Seção Avaliação de resultados, foi realizada a classificação de 22.946\n",
      "documentos com os modelos desenvolvidos, foram aplicados os testes estatísticos de\n",
      "acordo com a metodologia escolhida e por fim foram gerados diversos gráficos demons-\n",
      "trando as proporções de julgamentos encontrados na amostra selecionada. Enfim, foi\n",
      "possível identificar diferença estatística em ambos os tribunais com proporção maior de\n",
      "julgamentos para empregados, por outro lado, também foi observado que há turmas recur-\n",
      "sais que divergem da média geral de cada tribunal apresentando, assim, proporção maior\n",
      "de julgamentos para empresas. Também é possível verificar na Seção 6.7 o conjunto de\n",
      "limitações encontradas para a presente pesquisa de maneira detalhada.\n",
      "\f                                                                                       105\n",
      "\n",
      "\n",
      "7 DISCUSSÃO DE RESULTADOS\n",
      "\n",
      "\n",
      "       A presente pesquisa desenvolveu processo de Ciência de Dados para a classifica-\n",
      "ção automática de decisões judiciais em relação ao beneficiário do julgamento ser em-\n",
      "pregado ou empresa de modo a quantificar a proporção de julgamentos favorável a cada\n",
      "parte. Assim, foi possível responder a questão de pesquisa: Seria possível que os tri-\n",
      "bunais avaliados e suas turmas recursais julguem favoravelmente proporção signifi-\n",
      "cativamente maior de recursos para uma das partes do que para outra em média?\n",
      "Enfim, foi possível verificar diferença de proporção estatística significante em relação ao\n",
      "Tribunal Regional do Trabalho da 3 e 4a Região. Cabe ressaltar que a diferença de pro-\n",
      "porção encontrada nos dados do TRT da 4a Região foi de 12% a mais para empregados e,\n",
      "nos dados do TRT da 3a Região, a diferença foi de 2% a mais para empregados.\n",
      "       Por outro lado, os dados sugerem haver também diferenças estatísticas de propor-\n",
      "ção se forem analisadas individualmente as Turmas Recursais que compõem cada tribu-\n",
      "nal. Em relação ao TRT da 4a Região, é possível verificar que 6 das 11 Turmas Recursais\n",
      "acompanham a média geral do tribunal tendo maior proporção de julgados favoráveis a\n",
      "empregados, sendo que a 2a , 3a e 8a Turmas Recursais apresentam mais de 2 desvios pa-\n",
      "drão de diferença. Por outro lado, em relação ao TRT da 3a Região, também é possível\n",
      "verificar diferenças estatísticas de proporção. Entretanto, neste caso, menos da metade\n",
      "das Turmas Recursais acompanharam a média geral do tribunal. Assim, 5 das 11 Turmas\n",
      "Recursais apresentaram proporção de deferimentos maior para empregados, tendo 3 delas\n",
      "diferença maior que 2 desvios-padrão. Em contrapartida, 6 das 11 Turmas Recursais apre-\n",
      "sentaram proporção de deferimentos maior para empresas, tendo apenas 1 delas diferença\n",
      "maior que 3 desvios-padrão.\n",
      "       Enfim, as médias gerais dos tribunais analisados e também as médias especificas\n",
      "de diversas Turmas Recursais contribuíram para suportar a hipótese levantada de que há\n",
      "órgãos judiciais que julgam proporção consideravelmente maior para uma das partes do\n",
      "que para outra. Desse modo, a quantidade de dados extraídos em relação aos tribunais\n",
      "como um todo se mostrou satisfatória para alcançar o nível de força desejado de 80%.\n",
      "Entretanto, em relação às Turmas Recursais individualmente, menos da metade das aná-\n",
      "lises obtiveram nível de força abaixo de 80%, como é possível ser observado pela Tabela\n",
      "6.19 e 6.20, constando, assim, como uma limitação da presente pesquisa.\n",
      "       Além da análise quantitativa das decisões judiciais processadas automaticamente,\n",
      "também foi realizado experimento para avaliar a efetividade de técnica de Supervisão\n",
      "\f106\n",
      "\n",
      "\n",
      "Fraca de modo a aumentar a quantidade de documentos anotados utilizados no treina-\n",
      "mento dos modelos de Aprendizado de Máquina. Assim, a técnica se mostrou satisfató-\n",
      "ria, pois permitiu a anotação automática de mais de 22 mil documentos, ou seja, aumen-\n",
      "tando a base de treinamento em mais de 22 vezes. O presente resultado foi alcançado\n",
      "considerando que os magistrados empregam no dia-a-dia estilo de escrita padronizado e\n",
      "preferencialmente as mesmas palavras-chave em certos trechos dos documentos, ou, até\n",
      "mesmo, reutilizam modelos de documentos alterando apenas nomes de pessoas sendo pro-\n",
      "cessadas por exemplo. Por um lado, essa característica específica da base de documentos\n",
      "processada pode ser considerada positiva, pois permitiu a construção rápida de funções\n",
      "de rotulação as quais possibilitaram a anotação automática da base de documentos para\n",
      "treinamento. Entretanto, por outro lado, essa característica de padronização dos docu-\n",
      "mentos pode imprimir desafios, pois muitas das instâncias anotadas automaticamente não\n",
      "apresentam grande variação de features o que pode impactar determinados algoritmos.\n",
      "\f                                                                                     107\n",
      "\n",
      "\n",
      "8 CONCLUSÕES\n",
      "\n",
      "\n",
      "       Esta pesquisa teve por objetivo principal utilizar métodos computacionais automá-\n",
      "ticos para responder a questão de pesquisa se Seria possível que os tribunais avaliados e\n",
      "suas turmas recursais julguem favoravelmente proporção significativamente maior\n",
      "de recursos para uma das partes do que para outra em média? Assim, foi executada\n",
      "pesquisa de descoberta de conhecimento em base de dados de acordo com a metodologia\n",
      "Crisp-dm (CHAPMAN et al., 2000) que incluiu o processamento por meio de Algoritmo\n",
      "de Aprendizado de Máquina e PLN de mais de 20 mil decisões judiciais de modo a re-\n",
      "alizar estudo quantitativo e estatístico da base de decisões. Os resultados indicaram que\n",
      "realmente há tribunais e turmas recursais que apresentam diferença significante de pro-\n",
      "porção de julgamentos favorável para empregados e empresas e vice-versa.\n",
      "       Além disso, também foram atingidos os objetivos específicos que constituíam na\n",
      "análise exploratória dos documentos coletadas na Web, o que resultou em conhecimento\n",
      "sobre a frequência das palavras utilizadas pelos magistrados, como também no conheci-\n",
      "mento sobre a padronização dos documentos. Igualmente foi desenvolvida base padrão-\n",
      "ouro para treinamento de algoritmos de Aprendizado de Máquina o que pode ser consi-\n",
      "derado um dos produtos da pesquisa.\n",
      "       Por outro lado, foi realizada também a experimentação da utilização de técnica de\n",
      "Supervisão Fraca para o desenvolvimento de base de treinamento criada automaticamente\n",
      "por meio da expansão dos dados, a qual apresentou resultados satisfatórios. Além disso,\n",
      "como trabalho futuro poderia ser considerada a elaboração de funções de rotulação que\n",
      "sejam mais flexíveis as palavras-chave utilizadas para classificar os documentos. Nesse\n",
      "caso, poderiam ser utilizadas Embeddings de modo a localizar expressões semelhantes\n",
      "às utilizadas na presente pesquisa para classificar documentos. Entretanto, considera-se\n",
      "satisfatório o experimento pois preencheu uma lacuna dos trabalhos relacionados pois\n",
      "não havia sido encontrado nenhum experimento utilizando técnica de Supervisão Fraca\n",
      "aplicada a documentos jurídicos até o momento.\n",
      "       De modo a permitir uma análise mais aprofundada e confiável dos resultados,\n",
      "propõe-se como sugestão que estudos futuros obtenham mais dados na fase de extração\n",
      "da amostra de documentos para considerar também a proporção de julgamento em relação\n",
      "a cada turma recursal, como também cada magistrado na função de relator. Essa conside-\n",
      "ração poderia permitir análises segmentadas por magistrado na função de relator de modo\n",
      "a viabilizar a análise da seguinte hipótese: Relatores diferentes (dentro de uma mesma\n",
      "\f108\n",
      "\n",
      "\n",
      "turma recursal) influenciam a proporção de julgamentos favoráveis a cada uma das\n",
      "partes, ou seja, há correlação entre o relator e a proporção de julgamentos de uma\n",
      "turma recursal.\n",
      "           Enfim, a presente pesquisa buscou trazer novos dados a discussões presentes na\n",
      "sociedade sobre a questão do viés na Justiça, principalmente, na Justiça do Trabalho.\n",
      "Assim, considerando que a pesquisa de Salama, Carlotti e Yeung (2018) encontrou resul-\n",
      "tados que sugerem que, a nível de primeiro grau de jurisdição na Justiça do Trabalho, há\n",
      "uma proporção muito maior de julgamentos favoráveis a empregados, os dados da pre-\n",
      "sente pesquisa sugerem a confirmação dessa proporção a nível de segundo grau, apesar de\n",
      "haver algumas turmas recursais que realizam a correção dessa distorção. A fim de facilitar\n",
      "a reprodução da pesquisa, foi disponibilizado online na plataforma Github o código-fonte\n",
      "do projeto1 .\n",
      "given the text of my work in my mastes degree above create a list of the experiences I have.use the folloing titles to guide the creatio and to group the experiencebusiness analisys, data scraping, data preparation (etl), machine learning modeling, statiscal analisys, dashboards presentationwrite everything in english\n"
     ]
    }
   ],
   "source": [
    "prompt_cheatsheet_formatted = prompt_cheatsheet.format(\n",
    "        TEXT=txt[int(l*0.5):],\n",
    "    )\n",
    "\n",
    "print( prompt_cheatsheet_formatted )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "response2 = llm_gemini.generate_content(prompt_cheatsheet_formatted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a breakdown of your Master's work experiences based on the provided text:\n",
      "\n",
      "**Business Analysis:**\n",
      "\n",
      "* **Defined business objectives:**  Clearly articulated the business goal of investigating potential bias in judicial rulings within labor courts, focusing on differences in favorable outcomes for employers versus employees.\n",
      "* **Formulated research questions:** Translated the business objective into a testable research question:  \"Is there a statistically significant difference in the proportion of favorable rulings for employers versus employees within specific labor courts and their respective appeal panels?\"\n",
      "* **Hypothesis development:** Proposed a hypothesis that certain judicial bodies might consistently rule in favor of one party over the other.\n",
      "* **Stakeholder analysis (implied):**  The research implicitly addresses the concerns of various stakeholders in the legal system, including employers, employees, and legal professionals, regarding fairness and impartiality.\n",
      "\n",
      "**Data Scraping:**\n",
      "\n",
      "* **Web scraping of legal documents:** Extracted a large dataset (over 20,000 judicial decisions) from online sources related to the targeted labor courts (TRT 3rd and 4th regions).\n",
      "* **Data acquisition challenges:**  Experienced and documented technical difficulties encountered during web scraping, limiting the scope of data collection from historical archives.\n",
      "\n",
      "**Data Preparation (ETL):**\n",
      "\n",
      "* **Data cleaning:** Performed data cleaning procedures to address formatting inconsistencies, remove irrelevant characters, and handle missing data.\n",
      "* **Data transformation:**  Extracted relevant text sections (judicial rulings) from the larger legal documents.\n",
      "* **Feature engineering:**  Used tokenization, lemmatization, and TF-IDF representation to convert text data into numerical features suitable for machine learning models.\n",
      "* **Data reduction:** Implemented a technique to reduce the size of documents by focusing on key sections.\n",
      "* **Manual data annotation:** Created a \"gold standard\" dataset of 1,000 manually labeled documents (with assistance from legal professionals) to train and evaluate machine learning models. This included categorizing cases by outcome (favorable to employee or employer) and by the type of appellant.\n",
      "* **Weak Supervision:** Applied weak supervision techniques using the Snorkel framework to automatically label a larger dataset (22,000+ documents) based on predefined heuristics and keyword patterns.\n",
      "* **Data balancing:** Addressed class imbalance issues in the datasets using undersampling techniques to ensure equal representation of different outcome categories.\n",
      "\n",
      "**Machine Learning Modeling:**\n",
      "\n",
      "* **Model selection and training:** Experimented with various machine learning algorithms (Rocchio classifier, Gradient Boosting, Naive Bayes, K-Nearest Neighbors, SVM, Decision Tree, Random Forest) for text classification tasks.\n",
      "* **Model evaluation and tuning:** Used cross-validation and performance metrics (accuracy, F1-score, precision, recall) to evaluate and compare different models.\n",
      "* **Hyperparameter tuning (implied):** While not explicitly stated, the selection of a final model likely involved some degree of hyperparameter tuning, even if default parameters were ultimately deemed sufficient.\n",
      "* **Model deployment (considered):** Discussed considerations for future deployment and maintenance of the models, including the importance of data quality monitoring.\n",
      "\n",
      "**Statistical Analysis:**\n",
      "\n",
      "* **Hypothesis testing:** Conducted statistical tests (p-value, effect size, power analysis) to determine the significance of differences in the proportion of favorable rulings for employers versus employees.\n",
      "* **Statistical interpretation:**  Interpreted the results of statistical tests and drew conclusions based on the observed significance levels and effect sizes.\n",
      "\n",
      "**Dashboards & Presentation:**\n",
      "\n",
      "* **Data visualization:** Created charts and graphs to visualize the proportions of favorable rulings for each party and to illustrate the distribution of outcomes across different judicial bodies.\n",
      "* **Results communication:** Clearly presented the research findings, including the limitations of the study, in a structured and understandable manner.\n",
      "* **Report generation:** Compiled the results and analysis into a comprehensive research report.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print( response2.text )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_cheatsheet = (\n",
    "    \"TEXT:\\n\\n\"\n",
    "    \"{TEXT}\"\n",
    "    \"I want to create the text for the experience of my likedin profile.\\n\"\n",
    "    \"given the summary of my work in my mastes degree above create the text for the experience section.\\n\"\n",
    "    \"use the folloing titles to guide the creatio and to group the experience\\n\"\n",
    "    \"business analisys, data scraping, data preparation (etl), machine learning modeling, statiscal analisys, dashboards presentation\\n\"\n",
    "    \"write everything in english\\n\"\n",
    "    \"also, consider the folloing guidelines to create the text\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "guidelines = r\"\"\"\n",
    "Writing a strong experience section for your LinkedIn profile can significantly boost your professional appeal. Here are some key tips and examples to make each entry stand out:\n",
    "\n",
    "1. Use a Clear and Relevant Job Title\n",
    "Use the exact title of your role. If it’s non-standard or doesn’t convey your responsibilities, consider adding a brief clarifier, like “Software Engineer – Machine Learning” instead of just “Engineer.”\n",
    "2. Start with an Overview (2-3 Sentences)\n",
    "Summarize your role and key responsibilities. This should highlight the scope of your role and any unique expertise you bring.\n",
    "Example: \"As a Data Scientist at XYZ Corp, I analyze large datasets to develop predictive models that support customer segmentation and targeted marketing strategies, helping to drive a 20% increase in customer retention.\"\n",
    "\n",
    "3. Highlight Key Achievements and Metrics\n",
    "Quantify your impact with numbers where possible (e.g., \"increased sales by 30%,\" \"managed a $1M project\"). This makes your achievements more credible and memorable.\n",
    "Example: \"Led a cross-functional team to optimize the supply chain, reducing costs by 15% and improving delivery speed by 25% across three regions.\"\n",
    "\n",
    "4. Use Bullet Points for Readability\n",
    "Bullet points make it easy for viewers to scan your experience. Start each bullet with an action verb (e.g., \"Developed,\" \"Implemented,\" \"Managed\").\n",
    "Example:\n",
    "\n",
    "Developed and deployed a machine learning model for fraud detection, reducing false positives by 40%.\n",
    "Collaborated with stakeholders across engineering and product teams to align on project goals and ensure timely delivery.\n",
    "5. Include Keywords for SEO\n",
    "Use industry-relevant keywords and skills to improve the chances of your profile appearing in LinkedIn search results. For instance, in machine learning, you might include terms like “Python,” “data analysis,” “neural networks,” or “NLP.”\n",
    "6. Showcase Impact on the Organization\n",
    "Emphasize how your work positively affected your company. This could include revenue growth, process improvements, customer satisfaction, or product success.\n",
    "Example: \"Developed an automated data pipeline that reduced reporting time by 50%, enabling faster decision-making for the executive team.\"\n",
    "\n",
    "7. Mention Projects or Initiatives\n",
    "If you worked on noteworthy projects, include a short description with the project's goal and outcome.\n",
    "Example: \"Spearheaded a project to launch a chatbot that automated 30% of customer service inquiries, improving user experience and reducing wait times by 40%.\"\n",
    "\n",
    "8. Use First-Person Language (Optional)\n",
    "You can use either first-person or implied first-person style, depending on your preference and the tone of your profile.\n",
    "9. Tailor Each Experience to Align with Your Career Goals\n",
    "Emphasize aspects of your experience that align with the roles you're targeting. If you’re aiming for machine learning positions, focus on ML projects and technical skills.\n",
    "Example Format for LinkedIn Experience Section\n",
    "Role Title | Company Name | Dates of Employment Location (optional)\n",
    "\n",
    "Brief overview of the role (1-2 sentences).\n",
    "Highlight 1: Key achievement, ideally with a metric. Example: \"Improved user engagement by 25% by implementing personalized recommendation algorithms.\"\n",
    "Highlight 2: Significant responsibility or project that showcases a specific skill. Example: \"Managed end-to-end deployment of a fraud detection model, resulting in a 40% reduction in fraudulent transactions.\"\n",
    "Highlight 3: Additional achievement, focusing on impact. Example: \"Collaborated with marketing and product teams to leverage predictive analytics, increasing customer conversion rates by 15%.\"\n",
    "Each entry should be concise yet showcase your strengths, achievements, and impact, giving potential employers a clear picture of what you bring to the table.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TEXT:\\n\\n{TEXT}I want to create the text for the experience of my likedin profile.\\ngiven the summary of my work in my mastes degree above create the text for the experience section.\\nuse the folloing titles to guide the creatio and to group the experience\\nbusiness analisys, data scraping, data preparation (etl), machine learning modeling, statiscal analisys, dashboards presentation\\nwrite everything in english\\nalso, consider the folloing guidelines to create the text\\n\\nWriting a strong experience section for your LinkedIn profile can significantly boost your professional appeal. Here are some key tips and examples to make each entry stand out:\\n\\n1. Use a Clear and Relevant Job Title\\nUse the exact title of your role. If it’s non-standard or doesn’t convey your responsibilities, consider adding a brief clarifier, like “Software Engineer – Machine Learning” instead of just “Engineer.”\\n2. Start with an Overview (2-3 Sentences)\\nSummarize your role and key responsibilities. This should highlight the scope of your role and any unique expertise you bring.\\nExample: \"As a Data Scientist at XYZ Corp, I analyze large datasets to develop predictive models that support customer segmentation and targeted marketing strategies, helping to drive a 20% increase in customer retention.\"\\n\\n3. Highlight Key Achievements and Metrics\\nQuantify your impact with numbers where possible (e.g., \"increased sales by 30%,\" \"managed a $1M project\"). This makes your achievements more credible and memorable.\\nExample: \"Led a cross-functional team to optimize the supply chain, reducing costs by 15% and improving delivery speed by 25% across three regions.\"\\n\\n4. Use Bullet Points for Readability\\nBullet points make it easy for viewers to scan your experience. Start each bullet with an action verb (e.g., \"Developed,\" \"Implemented,\" \"Managed\").\\nExample:\\n\\nDeveloped and deployed a machine learning model for fraud detection, reducing false positives by 40%.\\nCollaborated with stakeholders across engineering and product teams to align on project goals and ensure timely delivery.\\n5. Include Keywords for SEO\\nUse industry-relevant keywords and skills to improve the chances of your profile appearing in LinkedIn search results. For instance, in machine learning, you might include terms like “Python,” “data analysis,” “neural networks,” or “NLP.”\\n6. Showcase Impact on the Organization\\nEmphasize how your work positively affected your company. This could include revenue growth, process improvements, customer satisfaction, or product success.\\nExample: \"Developed an automated data pipeline that reduced reporting time by 50%, enabling faster decision-making for the executive team.\"\\n\\n7. Mention Projects or Initiatives\\nIf you worked on noteworthy projects, include a short description with the project\\'s goal and outcome.\\nExample: \"Spearheaded a project to launch a chatbot that automated 30% of customer service inquiries, improving user experience and reducing wait times by 40%.\"\\n\\n8. Use First-Person Language (Optional)\\nYou can use either first-person or implied first-person style, depending on your preference and the tone of your profile.\\n9. Tailor Each Experience to Align with Your Career Goals\\nEmphasize aspects of your experience that align with the roles you\\'re targeting. If you’re aiming for machine learning positions, focus on ML projects and technical skills.\\nExample Format for LinkedIn Experience Section\\nRole Title | Company Name | Dates of Employment Location (optional)\\n\\nBrief overview of the role (1-2 sentences).\\nHighlight 1: Key achievement, ideally with a metric. Example: \"Improved user engagement by 25% by implementing personalized recommendation algorithms.\"\\nHighlight 2: Significant responsibility or project that showcases a specific skill. Example: \"Managed end-to-end deployment of a fraud detection model, resulting in a 40% reduction in fraudulent transactions.\"\\nHighlight 3: Additional achievement, focusing on impact. Example: \"Collaborated with marketing and product teams to leverage predictive analytics, increasing customer conversion rates by 15%.\"\\nEach entry should be concise yet showcase your strengths, achievements, and impact, giving potential employers a clear picture of what you bring to the table.\\n'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_cheatsheet = prompt_cheatsheet + guidelines\n",
    "prompt_cheatsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEXT:\n",
      "\n",
      "Here's a breakdown of your experiences based on the text provided, categorized by the requested titles:\n",
      "\n",
      "**Business Analysis:**\n",
      "\n",
      "* **Identifying a Business Need:** You recognized the practical need for lawyers and businesses to understand the tendencies of labor courts in Brazil, particularly regarding which party (employer or employee) they tend to favor in rulings. This understanding can significantly impact settlement negotiations and strategic decision-making in legal cases.\n",
      "* **Defining Objectives and Success Criteria:** You clearly articulated the research question and defined the objective of building a system to classify legal decisions and determine the proportion of rulings favorable to each party. You also established success criteria based on the production of reports with statistically significant results.\n",
      "* **Cost-Benefit Analysis:** You conducted a cost-benefit analysis to demonstrate the financial implications of understanding court tendencies, showcasing how this knowledge can influence settlement decisions and potentially save significant sums of money for both employers and employees.\n",
      "* **Understanding Legal Domain:** Your background and experience as a public servant in the Brazilian labor court system provided crucial domain expertise, allowing you to understand the nuances of legal documents, procedures, and terminology. This expertise informed your research design and interpretation of results.\n",
      "\n",
      "**Data Scraping:**\n",
      "\n",
      "* **Web Scraping with Python and Scrapy:** You developed web scraping robots using Python and the Scrapy library to extract legal documents (acórdãos) from two different court websites. You navigated different website structures, including sitemaps and search pages, to collect the required data.\n",
      "* **Handling Website Limitations:** You demonstrated responsible scraping practices by respecting robots.txt and other website limitations to minimize the impact on the target servers. You also obtained permission via email to use the legal decisions for your research.\n",
      "* **Addressing Data Extraction Challenges:** You encountered and addressed challenges related to HTTP request errors, incomplete data, and PDF processing.  You used XpdfReader to extract text from PDFs but noted issues with character placement, ultimately excluding those documents from the analysis.\n",
      "\n",
      "**Data Preparation (ETL):**\n",
      "\n",
      "* **Data Cleaning:** You cleaned the scraped data by removing instances with errors, irrelevant characters, or insufficient length (less than 150 words). This ensured data quality for subsequent processing and modeling.\n",
      "* **Data Transformation:** You enriched the data by extracting key metadata (publication date, judge, parties involved, etc.) using regular expressions.  You also extracted the \"Dispositivo\" section of the legal documents, focusing on the part containing the judgment outcome.\n",
      "* **Data Reduction and Filtering:** You removed documents with multiple appellants to simplify the classification task and align with the research objective. You also filtered out cases labeled \"SEM_ANALISE_MERITO\" (without merit analysis) as they were not relevant to the core research question.\n",
      "* **Manual Data Annotation:** You meticulously annotated 1000 legal documents manually, creating a gold standard dataset for training and evaluating machine learning models. You developed annotation guidelines and involved two other law graduates in the process, using Cohen's Kappa to measure inter-annotator agreement. You also annotated a separate dataset for classifying the type of appellant (employer or employee).\n",
      "* **Weak Supervision with Snorkel:** You utilized Snorkel, a weak supervision framework, to programmatically label a larger dataset using labeling functions based on keyword presence. You addressed class imbalance in the resulting dataset through undersampling.\n",
      "\n",
      "**Machine Learning Modeling:**\n",
      "\n",
      "* **Text Preprocessing:**  You implemented a text preprocessing pipeline including tokenization (with a Portuguese-specific algorithm), stemming using Spacy, and TF-IDF vectorization.\n",
      "* **Model Selection and Evaluation:**  You experimented with various machine learning algorithms from Scikit-learn (Rocchio classifier, Gradient Boosting Classifier, Naive Bayes, K-NN, SVM, Decision Tree, Random Forest) and selected the best performing models based on the F1-score.  You used a 70/30 train-test split for the gold standard dataset and cross-validation. For the programmatically labeled datasets, you used the entire dataset for training and the gold standard dataset for testing.\n",
      "* **Model Training and Selection:** You trained and selected the SVM model for classifying the type of appellant and the Gradient Boosting model for classifying the judgment outcome.\n",
      "\n",
      "**Statistical Analysis:**\n",
      "\n",
      "* **Hypothesis Testing:** You formulated a null and alternative hypothesis regarding the proportion of rulings favorable to each party. You used the Statsmodels library to perform statistical tests (proportion tests) and calculate effect size and power.\n",
      "* **Sample Size Calculation:** You used Statsmodels to calculate the required sample size for the statistical tests, considering factors like effect size, power, and confidence level.\n",
      "\n",
      "**Dashboards/Presentation:**\n",
      "\n",
      "* **Data Visualization and Reporting:** You created visualizations (graphs and charts) to present the proportions of judgments for each party in each court and appeals chamber.  You compiled reports including statistical test results, effect size, and power.  While the text doesn't explicitly mention a specific dashboarding tool, the generation of graphs suggests a focus on presenting the results visually.\n",
      "Here's a breakdown of your Master's work experiences based on the provided text:\n",
      "\n",
      "**Business Analysis:**\n",
      "\n",
      "* **Defined business objectives:**  Clearly articulated the business goal of investigating potential bias in judicial rulings within labor courts, focusing on differences in favorable outcomes for employers versus employees.\n",
      "* **Formulated research questions:** Translated the business objective into a testable research question:  \"Is there a statistically significant difference in the proportion of favorable rulings for employers versus employees within specific labor courts and their respective appeal panels?\"\n",
      "* **Hypothesis development:** Proposed a hypothesis that certain judicial bodies might consistently rule in favor of one party over the other.\n",
      "* **Stakeholder analysis (implied):**  The research implicitly addresses the concerns of various stakeholders in the legal system, including employers, employees, and legal professionals, regarding fairness and impartiality.\n",
      "\n",
      "**Data Scraping:**\n",
      "\n",
      "* **Web scraping of legal documents:** Extracted a large dataset (over 20,000 judicial decisions) from online sources related to the targeted labor courts (TRT 3rd and 4th regions).\n",
      "* **Data acquisition challenges:**  Experienced and documented technical difficulties encountered during web scraping, limiting the scope of data collection from historical archives.\n",
      "\n",
      "**Data Preparation (ETL):**\n",
      "\n",
      "* **Data cleaning:** Performed data cleaning procedures to address formatting inconsistencies, remove irrelevant characters, and handle missing data.\n",
      "* **Data transformation:**  Extracted relevant text sections (judicial rulings) from the larger legal documents.\n",
      "* **Feature engineering:**  Used tokenization, lemmatization, and TF-IDF representation to convert text data into numerical features suitable for machine learning models.\n",
      "* **Data reduction:** Implemented a technique to reduce the size of documents by focusing on key sections.\n",
      "* **Manual data annotation:** Created a \"gold standard\" dataset of 1,000 manually labeled documents (with assistance from legal professionals) to train and evaluate machine learning models. This included categorizing cases by outcome (favorable to employee or employer) and by the type of appellant.\n",
      "* **Weak Supervision:** Applied weak supervision techniques using the Snorkel framework to automatically label a larger dataset (22,000+ documents) based on predefined heuristics and keyword patterns.\n",
      "* **Data balancing:** Addressed class imbalance issues in the datasets using undersampling techniques to ensure equal representation of different outcome categories.\n",
      "\n",
      "**Machine Learning Modeling:**\n",
      "\n",
      "* **Model selection and training:** Experimented with various machine learning algorithms (Rocchio classifier, Gradient Boosting, Naive Bayes, K-Nearest Neighbors, SVM, Decision Tree, Random Forest) for text classification tasks.\n",
      "* **Model evaluation and tuning:** Used cross-validation and performance metrics (accuracy, F1-score, precision, recall) to evaluate and compare different models.\n",
      "* **Hyperparameter tuning (implied):** While not explicitly stated, the selection of a final model likely involved some degree of hyperparameter tuning, even if default parameters were ultimately deemed sufficient.\n",
      "* **Model deployment (considered):** Discussed considerations for future deployment and maintenance of the models, including the importance of data quality monitoring.\n",
      "\n",
      "**Statistical Analysis:**\n",
      "\n",
      "* **Hypothesis testing:** Conducted statistical tests (p-value, effect size, power analysis) to determine the significance of differences in the proportion of favorable rulings for employers versus employees.\n",
      "* **Statistical interpretation:**  Interpreted the results of statistical tests and drew conclusions based on the observed significance levels and effect sizes.\n",
      "\n",
      "**Dashboards & Presentation:**\n",
      "\n",
      "* **Data visualization:** Created charts and graphs to visualize the proportions of favorable rulings for each party and to illustrate the distribution of outcomes across different judicial bodies.\n",
      "* **Results communication:** Clearly presented the research findings, including the limitations of the study, in a structured and understandable manner.\n",
      "* **Report generation:** Compiled the results and analysis into a comprehensive research report.\n",
      "I want to create the text for the experience of my likedin profile.\n",
      "given the summary of my work in my mastes degree above create the text for the experience section.\n",
      "use the folloing titles to guide the creatio and to group the experience\n",
      "business analisys, data scraping, data preparation (etl), machine learning modeling, statiscal analisys, dashboards presentation\n",
      "write everything in english\n",
      "also, consider the folloing guidelines to create the text\n",
      "\n",
      "Writing a strong experience section for your LinkedIn profile can significantly boost your professional appeal. Here are some key tips and examples to make each entry stand out:\n",
      "\n",
      "1. Use a Clear and Relevant Job Title\n",
      "Use the exact title of your role. If it’s non-standard or doesn’t convey your responsibilities, consider adding a brief clarifier, like “Software Engineer – Machine Learning” instead of just “Engineer.”\n",
      "2. Start with an Overview (2-3 Sentences)\n",
      "Summarize your role and key responsibilities. This should highlight the scope of your role and any unique expertise you bring.\n",
      "Example: \"As a Data Scientist at XYZ Corp, I analyze large datasets to develop predictive models that support customer segmentation and targeted marketing strategies, helping to drive a 20% increase in customer retention.\"\n",
      "\n",
      "3. Highlight Key Achievements and Metrics\n",
      "Quantify your impact with numbers where possible (e.g., \"increased sales by 30%,\" \"managed a $1M project\"). This makes your achievements more credible and memorable.\n",
      "Example: \"Led a cross-functional team to optimize the supply chain, reducing costs by 15% and improving delivery speed by 25% across three regions.\"\n",
      "\n",
      "4. Use Bullet Points for Readability\n",
      "Bullet points make it easy for viewers to scan your experience. Start each bullet with an action verb (e.g., \"Developed,\" \"Implemented,\" \"Managed\").\n",
      "Example:\n",
      "\n",
      "Developed and deployed a machine learning model for fraud detection, reducing false positives by 40%.\n",
      "Collaborated with stakeholders across engineering and product teams to align on project goals and ensure timely delivery.\n",
      "5. Include Keywords for SEO\n",
      "Use industry-relevant keywords and skills to improve the chances of your profile appearing in LinkedIn search results. For instance, in machine learning, you might include terms like “Python,” “data analysis,” “neural networks,” or “NLP.”\n",
      "6. Showcase Impact on the Organization\n",
      "Emphasize how your work positively affected your company. This could include revenue growth, process improvements, customer satisfaction, or product success.\n",
      "Example: \"Developed an automated data pipeline that reduced reporting time by 50%, enabling faster decision-making for the executive team.\"\n",
      "\n",
      "7. Mention Projects or Initiatives\n",
      "If you worked on noteworthy projects, include a short description with the project's goal and outcome.\n",
      "Example: \"Spearheaded a project to launch a chatbot that automated 30% of customer service inquiries, improving user experience and reducing wait times by 40%.\"\n",
      "\n",
      "8. Use First-Person Language (Optional)\n",
      "You can use either first-person or implied first-person style, depending on your preference and the tone of your profile.\n",
      "9. Tailor Each Experience to Align with Your Career Goals\n",
      "Emphasize aspects of your experience that align with the roles you're targeting. If you’re aiming for machine learning positions, focus on ML projects and technical skills.\n",
      "Example Format for LinkedIn Experience Section\n",
      "Role Title | Company Name | Dates of Employment Location (optional)\n",
      "\n",
      "Brief overview of the role (1-2 sentences).\n",
      "Highlight 1: Key achievement, ideally with a metric. Example: \"Improved user engagement by 25% by implementing personalized recommendation algorithms.\"\n",
      "Highlight 2: Significant responsibility or project that showcases a specific skill. Example: \"Managed end-to-end deployment of a fraud detection model, resulting in a 40% reduction in fraudulent transactions.\"\n",
      "Highlight 3: Additional achievement, focusing on impact. Example: \"Collaborated with marketing and product teams to leverage predictive analytics, increasing customer conversion rates by 15%.\"\n",
      "Each entry should be concise yet showcase your strengths, achievements, and impact, giving potential employers a clear picture of what you bring to the table.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt_cheatsheet_formatted = prompt_cheatsheet.format(\n",
    "        TEXT=response.text + response2.text\n",
    "    )\n",
    "\n",
    "print( prompt_cheatsheet_formatted )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "response3 = llm_gemini.generate_content(prompt_cheatsheet_formatted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Master's Thesis Project | [University Name] | [Start Date] - [End Date]**\n",
      "\n",
      "Developed a machine learning model to analyze Brazilian labor court rulings and identify potential biases in judgments favoring employers versus employees. This research culminated in a master's thesis and involved extensive data collection, processing, modeling, and statistical analysis.\n",
      "\n",
      "**Business Analysis:**\n",
      "\n",
      "* Defined the business objective of investigating potential bias in labor court rulings, translating it into a testable research question focused on the proportion of favorable outcomes for employers and employees.\n",
      "* Developed hypotheses regarding potential systemic biases within specific courts and appeal panels.\n",
      "* Considered the impact of research findings on stakeholders including employers, employees, and legal professionals.\n",
      "\n",
      "**Data Scraping:**\n",
      "\n",
      "* Collected over 20,000 legal decisions (acórdãos) from the TRT 3rd and 4th region websites using Python and Scrapy, navigating diverse website structures and overcoming technical limitations.\n",
      "* Implemented responsible scraping practices, respecting robots.txt and obtaining necessary permissions for data usage.\n",
      "\n",
      "**Data Preparation (ETL):**\n",
      "\n",
      "* Cleaned and preprocessed the scraped data, removing irrelevant characters and entries with errors, focusing on the \"Dispositivo\" section containing the judgment outcome.\n",
      "* Transformed data by extracting key metadata (publication date, judge, parties involved) using regular expressions.\n",
      "* Manually annotated 1,000 documents to create a gold standard dataset for model training and evaluation, achieving high inter-annotator agreement (Cohen's Kappa).\n",
      "* Used Snorkel to programmatically label a larger dataset (22,000+ documents) based on keyword heuristics, addressing class imbalance with undersampling techniques.\n",
      "\n",
      "**Machine Learning Modeling:**\n",
      "\n",
      "* Trained and evaluated various machine learning models (SVM, Gradient Boosting, Naive Bayes, K-NN, Decision Tree, Random Forest) for classifying judgment outcomes and appellant types, using TF-IDF vectorization and a Portuguese-specific tokenizer.\n",
      "* Selected the best performing models (SVM for appellant type, Gradient Boosting for judgment outcome) based on F1-score using cross-validation and a 70/30 train-test split.\n",
      "* Considered future model deployment and maintenance, emphasizing data quality monitoring.\n",
      "\n",
      "**Statistical Analysis:**\n",
      "\n",
      "* Performed hypothesis testing (proportion tests) using Statsmodels to determine the statistical significance of differences in favorable rulings for employers versus employees, calculating effect size and power.\n",
      "* Determined the necessary sample size for statistically significant results, considering effect size, power, and confidence level.\n",
      "\n",
      "**Dashboards & Presentation:**\n",
      "\n",
      "* Created visualizations (charts and graphs) to present the proportions of favorable rulings for each party across different courts and appeal panels.\n",
      "* Compiled a comprehensive research report detailing methodology, findings, and limitations, effectively communicating the results through clear visualizations and statistical analysis.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print( response3.text )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
